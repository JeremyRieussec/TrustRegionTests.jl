{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noted-delicious",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{String,1}:\n",
       " \"@\"\n",
       " \"@v#.#\"\n",
       " \"@stdlib\"\n",
       " \"C://Users//jerem//OneDrive//Desktop//GitHub//Code//FinalCode\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For using package modified in local repo \n",
    "using Pkg\n",
    "\n",
    "push!(LOAD_PATH, \"C://Users//jerem//OneDrive//Desktop//GitHub//Code//FinalCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valued-alberta",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Geraldine [c0fffcf4-b2fb-46e8-8a34-03ca56aefa66]\n",
      "└ @ Base loading.jl:1278\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:halfπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:logπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:fourπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:log2π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:fourinvπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:quartπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:log4π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:sqrtπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:inv2π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:sqrt2π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:inv4π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:invsqrt2}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:loghalf}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:sqrt4π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:sqrthalfπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:twoinvπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:logtwo}) in module IrrationalConstants at irrationals.jl:173 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:sqrt3}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:invsqrt2π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:sqrt2}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{Base.MPFR.BigFloat}, Base.Irrational{:invπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:halfπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:logπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:fourπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:log2π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:fourinvπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:quartπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:log4π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:sqrtπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:inv2π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:sqrt2π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:inv4π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:invsqrt2}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:loghalf}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:sqrt4π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:sqrthalfπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoinvπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:logtwo}) in module IrrationalConstants at irrationals.jl:173 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:sqrt3}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:invsqrt2π}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:sqrt2}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:invπ}) in module IrrationalConstants at irrationals.jl:180 overwritten in module StatsFuns at irrationals.jl:180.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:invsqrt2π}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:halfπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:logπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:fourπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:log2π}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:fourinvπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:quartπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:log4π}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:sqrtπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:inv2π}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:sqrt2π}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:inv4π}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:invsqrt2}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:loghalf}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:sqrt4π}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:sqrthalfπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:twoinvπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:logtwo}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:sqrt3}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:invπ}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float64})(Base.Irrational{:sqrt2}) in module IrrationalConstants at irrationals.jl:189 overwritten in module StatsFuns at irrationals.jl:189.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:invsqrt2π}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:halfπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:logπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:fourπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:log2π}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:fourinvπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:quartπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:log4π}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:sqrtπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:inv2π}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:sqrt2π}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:inv4π}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:invsqrt2}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:loghalf}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:sqrt4π}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:sqrthalfπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:twoinvπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:logtwo}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:sqrt3}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:invπ}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{Float32})(Base.Irrational{:sqrt2}) in module IrrationalConstants at irrationals.jl:190 overwritten in module StatsFuns at irrationals.jl:190.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Package Geraldine does not have Pkg in its dependencies:\n",
      "│ - If you have Geraldine checked out for development and have\n",
      "│   added Pkg as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with Geraldine\n",
      "└ Loading Pkg into Geraldine from project dependency, future warnings for Geraldine are suppressed.\n",
      "WARNING: Method definition computeF(Array{T, 1} where T, Geraldine.NoVariance{T} where T, Sofia.AbstractStochasticModel{U} where U<:Sofia.IsUpdatable) in module Geraldine at C:\\Users\\jerem\\OneDrive\\Desktop\\GitHub\\Code\\FinalCode\\Geraldine\\src\\SecondOrder\\BTR\\UpdateAndInitialize.jl:83 overwritten at C:\\Users\\jerem\\OneDrive\\Desktop\\GitHub\\Code\\FinalCode\\Geraldine\\src\\SecondOrder\\InexactRestoration\\main.jl:268.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition computeF##kw(Any, typeof(Geraldine.computeF), Array{T, 1} where T, Geraldine.NoVariance{T} where T, Sofia.AbstractStochasticModel{U} where U<:Sofia.IsUpdatable) in module Geraldine at C:\\Users\\jerem\\OneDrive\\Desktop\\GitHub\\Code\\FinalCode\\Geraldine\\src\\SecondOrder\\BTR\\UpdateAndInitialize.jl:83 overwritten at C:\\Users\\jerem\\OneDrive\\Desktop\\GitHub\\Code\\FinalCode\\Geraldine\\src\\SecondOrder\\InexactRestoration\\main.jl:268.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition computeF_cand(Array{T, 1} where T, Geraldine.NoVariance{T} where T, Sofia.AbstractStochasticModel{U} where U<:Sofia.IsUpdatable) in module Geraldine at C:\\Users\\jerem\\OneDrive\\Desktop\\GitHub\\Code\\FinalCode\\Geraldine\\src\\SecondOrder\\BTR\\UpdateAndInitialize.jl:204 overwritten at C:\\Users\\jerem\\OneDrive\\Desktop\\GitHub\\Code\\FinalCode\\Geraldine\\src\\SecondOrder\\InexactRestoration\\main.jl:303.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition computeF_cand##kw(Any, typeof(Geraldine.computeF_cand), Array{T, 1} where T, Geraldine.NoVariance{T} where T, Sofia.AbstractStochasticModel{U} where U<:Sofia.IsUpdatable) in module Geraldine at C:\\Users\\jerem\\OneDrive\\Desktop\\GitHub\\Code\\FinalCode\\Geraldine\\src\\SecondOrder\\BTR\\UpdateAndInitialize.jl:204 overwritten at C:\\Users\\jerem\\OneDrive\\Desktop\\GitHub\\Code\\FinalCode\\Geraldine\\src\\SecondOrder\\InexactRestoration\\main.jl:303.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Plots.GRBackend()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ForwardDiff, Plots, Statistics, LinearAlgebra, OnlineStats, Distributions, Random, CUDA, CSV, DataFrames\n",
    "\n",
    "using Sofia, Amlet, Geraldine \n",
    "\n",
    "using LaTeXStrings\n",
    "\n",
    "# Backend\n",
    "gr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expressed-angle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plotting_with_CI (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plotting_with_CI(all_f::AbstractArray, mo::AbstractStochasticModel, param::AbstractArray, \n",
    "                            sampleSizes::AbstractArray{Int, 1}, \n",
    "                            label::String, \n",
    "                            level::Float64 = 0.95 )\n",
    "    p = plot(all_f, xlabel=string(\"Iteration \", \"k\"), ylabel=\"f_Nk\", label=label)\n",
    "    nbIter = length(all_f)\n",
    "    z_α = quantile(Normal(), level)\n",
    "    l_CI = []\n",
    "    h_CI = []\n",
    "    sigmaCI = []\n",
    "    for i in 1:nbIter\n",
    "        N = sampleSizes[i]\n",
    "        fH = all_f[i]\n",
    "        \n",
    "        fs = Amlet.Fs(param[i], mo, sample=1:Nobs(mo))\n",
    "        sigmaH = std(fs, mean = fH, corrected = false)        \n",
    "\n",
    "        lH = fH - z_α*sigmaH/sqrt(N)\n",
    "        sH = fH + z_α*sigmaH/sqrt(N)\n",
    "        append!(l_CI, lH)\n",
    "        append!(h_CI , sH)\n",
    "        append!(sigmaCI, sigmaH)\n",
    "    end\n",
    "    plot!(p, l_CI, line=:dash, label = string(label, \" l_CI\"))\n",
    "    plot!(p, h_CI, line=:dash, label =  string(label, \" h_CI\"))\n",
    "    return p, l_CI, h_CI, sigmaCI\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "academic-school",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×1000000 Array{Float64,2}:\n",
       " -1.2901     -0.556754    1.98221    …   0.410988   -0.0455642   0.144539\n",
       " -0.0865376  -1.15663    -0.0896379      0.240582   -0.83081    -1.01057\n",
       "  0.828676    0.669947   -0.545892       0.359285   -0.949432    0.194817\n",
       "  0.692623    0.544988    0.278066       0.0818093   0.630993    0.0321351\n",
       "  0.542648    1.91776    -0.2806         0.0560473   0.183985    0.650876\n",
       "  0.551048   -0.949378    1.88543    …  -0.683507   -0.352263    0.24246\n",
       " -2.77743    -1.01552    -0.21733        0.221212    0.0018654  -0.909351\n",
       "  0.941436    2.11387    -0.814578      -1.36644    -0.197864    0.77417\n",
       " -1.30456     0.108521    1.12582        0.0751183   1.94209     0.99989\n",
       "  2.80003     0.924443   -0.228625       0.696057    0.640926    1.0595\n",
       " -2.07495    -0.958865    0.556299   …  -0.708704   -0.159924    1.93214\n",
       " -0.0815898  -1.59641     0.551785       0.373754    0.974861    1.39963\n",
       " -0.048656   -0.341504    1.30419       -2.26233    -2.0069      1.78852\n",
       "  ⋮                                  ⋱                          \n",
       " -0.272816   -1.10112    -0.328446      -0.394989   -0.538441   -0.0827876\n",
       " -1.69455    -0.257428   -0.173963      -0.501699    0.416977   -1.54621\n",
       " -0.51874    -0.488411    0.845588   …  -0.173768    1.36617    -0.905641\n",
       " -0.628197    0.661117   -0.0683582      1.85138    -1.83279     0.434071\n",
       "  1.35766    -0.15778     0.277708      -0.383125   -1.07355     0.0799594\n",
       "  1.35161    -0.0845441   0.503739       0.201756   -0.760872   -0.470781\n",
       "  1.78607     1.53081    -0.893112      -0.76183    -0.9427      0.720969\n",
       " -0.816512   -0.766528   -1.23132    …   1.1009     -0.693295   -1.37893\n",
       "  0.0734542  -0.162674    0.444049      -2.59171    -1.63442     0.751478\n",
       " -1.08628    -2.65483    -1.18501       -0.23662    -0.275587   -0.250455\n",
       "  0.0596859   0.705736    0.08139       -1.11375     0.354864   -1.36564\n",
       " -1.13796    -1.10126    -1.01558       -0.794276   -1.17081    -2.09731"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data generator file\n",
    "path = \"../Data/\"\n",
    "include(string(path, \"dataGenerator.jl\"))\n",
    "\n",
    "# setting population characteristics\n",
    "n_alt = 5    # number of alternatives\n",
    "N_dim = 10   # parameter dimension\n",
    "N_ind = 1_000_000    # number of individuals -- population size \n",
    "\n",
    "# generation\n",
    "df_pop = genLogitPop(N_dim, n_alt, N_ind)\n",
    "\n",
    "# conversion to matrix\n",
    "data = Array(Array(df_pop)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sealed-express",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amlet.LogitModel{NotUpdatable,Amlet.LinedObs}(Amlet.LogitUtility{Amlet.Linear}(Amlet.LinearUtilityForLogitModelWithCodeWellEncapsulated.u, Amlet.LinearUtilityForLogitModelWithCodeWellEncapsulated.grad, Amlet.LinearUtilityForLogitModelWithCodeWellEncapsulated.H), Amlet.LinedObs([-1.2900985484213743 -0.5567542019556669 … -0.045564205943013456 0.14453904766760606; -0.08653756583613678 -1.1566316399922312 … -0.8308099654632476 -1.0105740273749657; … ; 0.059685877054742466 0.7057364151832236 … 0.354864118877229 -1.3656406804400998; -1.1379594312708283 -1.101261699617055 … -1.1708141793657585 -2.0973098765203866], 5), #undef)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amletdata = Amlet.LinedObs(data, n_alt);\n",
    "\n",
    "# creating Linear Logit model from Lined data\n",
    "mo = Amlet.LogitModel(Amletdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technological-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point depart\n",
    "x0 = zeros(N_dim)\n",
    "\n",
    "# for accumulator\n",
    "xstar = Array{Float64}(genFibbomod(length(x0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "plastic-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "verbose = false\n",
    "\n",
    "IterMax = 100\n",
    "TMax = 300.0\n",
    "\n",
    "epsOptimisation = 10^(-6)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = IterMax, TMax = TMax, eps_g = epsOptimisation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "biological-phase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Any[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_plots = []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liked-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomSampling(100, 1000000, #undef)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################### Accumulator ######################\n",
    "Accum_1st(xstar::Vector = [0.0, 1, 1, 2, 3, 5, 8, 13, 21, 34]) = Accumulator(Value(), Iter(), NGrad(), Times(), DistTo(xstar), Geraldine.Param())\n",
    "\n",
    "\n",
    "sizeBatch = 100\n",
    "sam = RandomSampling(;N = sizeBatch, NMax=Nobs(mo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "behind-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm of type : AdamConstStep{Float64}\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 19  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 20  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 21  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 22  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 23  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 24  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 25  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 26  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 27  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 28  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 29  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 30  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 31  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 32  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 33  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 34  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 35  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 36  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 37  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 38  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 39  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 40  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 41  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 42  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 43  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 44  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 45  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 46  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 47  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 48  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 49  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 50  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 51  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 52  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 53  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 54  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 55  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 56  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 57  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 58  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 59  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 60  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 61  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 62  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 63  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 64  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 65  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 66  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 67  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 68  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 69  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 70  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 71  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 72  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 73  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 74  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 75  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 76  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 77  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 78  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 79  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 80  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 81  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 82  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 83  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 84  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 85  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 86  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 87  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 88  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 89  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 90  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 91  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 92  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 93  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 94  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 95  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 96  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 97  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 98  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 99  and  max = 100\n",
      "Nmax reached ? \n",
      "k = 100  and  max = 100\n",
      "nmaxReached\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "                            # Test Adam\n",
    "\n",
    "# definition state\n",
    "state = AdamState(copy(x0), sam)\n",
    "# Parameters\n",
    "α_adam = 0.01\n",
    "β_1 = 0.9\n",
    "β_2 = 0.999\n",
    "# Algo definition\n",
    "algo = AdamConstStep(α_adam, β_1, β_2)\n",
    "# Creation test\n",
    "accAdam = Accum_1st(xstar)\n",
    "\n",
    "state, accumulatorAdam = algo(mo, state ; sp = sp, accumulator = accAdam, verbose = verbose)\n",
    "\n",
    "resultAdam = Geraldine.structToDict(accumulatorAdam)\n",
    "\n",
    "paramAdam = resultAdam[:ParamAccumulator]\n",
    "fAdam = resultAdam[:ValueAccumulator];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "light-teens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip4200\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip4200)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4201\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip4200)\" d=\"\n",
       "M242.516 1425.62 L2352.76 1425.62 L2352.76 47.2441 L242.516 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4202\">\n",
       "    <rect x=\"242\" y=\"47\" width=\"2111\" height=\"1379\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  282.332,1425.62 282.332,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  780.03,1425.62 780.03,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1277.73,1425.62 1277.73,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1775.43,1425.62 1775.43,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2273.12,1425.62 2273.12,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,1192.19 2352.76,1192.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,870.485 2352.76,870.485 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,548.783 2352.76,548.783 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,227.08 2352.76,227.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,1425.62 2352.76,1425.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,1425.62 242.516,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  282.332,1425.62 282.332,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  780.03,1425.62 780.03,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1277.73,1425.62 1277.73,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1775.43,1425.62 1775.43,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2273.12,1425.62 2273.12,1409.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,1192.19 267.839,1192.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,870.485 267.839,870.485 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,548.783 267.839,548.783 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,227.08 267.839,227.08 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 282.332, 1479.62)\" x=\"282.332\" y=\"1479.62\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 780.03, 1479.62)\" x=\"780.03\" y=\"1479.62\">25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1277.73, 1479.62)\" x=\"1277.73\" y=\"1479.62\">50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1775.43, 1479.62)\" x=\"1775.43\" y=\"1479.62\">75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2273.12, 1479.62)\" x=\"2273.12\" y=\"1479.62\">100</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 1209.69)\" x=\"218.516\" y=\"1209.69\">0.75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 887.985)\" x=\"218.516\" y=\"887.985\">1.00</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 566.283)\" x=\"218.516\" y=\"566.283\">1.25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 244.58)\" x=\"218.516\" y=\"244.58\">1.50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1297.64, 1559.48)\" x=\"1297.64\" y=\"1559.48\">Iteration k</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 89.2861, 736.431)\" x=\"89.2861\" y=\"736.431\">f_Nk</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  302.24,86.2547 322.148,115.241 342.056,139.032 361.964,180.58 381.872,208.205 401.78,217.252 421.688,253.764 441.596,242.116 461.504,296.332 481.411,341.2 \n",
       "  501.319,332.134 521.227,371.031 541.135,405.527 561.043,417.341 580.951,440.277 600.859,417.602 620.767,437.422 640.675,479.666 660.583,542.981 680.491,516.539 \n",
       "  700.399,535.755 720.306,591.951 740.214,572.244 760.122,607.665 780.03,617.796 799.938,632.288 819.846,617.757 839.754,682.054 859.662,703.23 879.57,739.289 \n",
       "  899.478,630.11 919.386,720.061 939.294,725.909 959.202,717.816 979.109,723.207 999.017,809.759 1018.93,797.679 1038.83,805.558 1058.74,826.421 1078.65,802.354 \n",
       "  1098.56,815.297 1118.46,824.618 1138.37,872.666 1158.28,780.354 1178.19,822.113 1198.1,906.085 1218,849.332 1237.91,823.646 1257.82,904.291 1277.73,950.347 \n",
       "  1297.64,980.934 1317.54,930.163 1337.45,947.648 1357.36,991.439 1377.27,988.366 1397.18,955.349 1417.08,993.223 1436.99,950.679 1456.9,1102 1476.81,1062.46 \n",
       "  1496.72,975.355 1516.62,994.811 1536.53,1083.34 1556.44,1093.21 1576.35,945.199 1596.25,1034.62 1616.16,1068.16 1636.07,1050.23 1655.98,1033.65 1675.89,1059.96 \n",
       "  1695.79,995.627 1715.7,1096.09 1735.61,1142.9 1755.52,1081.56 1775.43,1138.12 1795.33,1133.44 1815.24,1114.45 1835.15,1109.49 1855.06,1080.41 1874.97,1166.22 \n",
       "  1894.87,1207.52 1914.78,1155.11 1934.69,1145.53 1954.6,1152.4 1974.51,1119.34 1994.41,1185.7 2014.32,1193.47 2034.23,1310.3 2054.14,1242.62 2074.05,1202.36 \n",
       "  2093.95,1233.78 2113.86,1133.53 2133.77,1190.55 2153.68,1166.86 2173.58,1272.71 2193.49,1278.89 2213.4,1238.43 2233.31,1212.54 2253.22,1250.45 2273.12,1110.35 \n",
       "  2293.03,1288.07 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" stroke-dasharray=\"16, 10\" points=\"\n",
       "  302.24,86.2547 322.148,120.361 342.056,147.311 361.964,191.95 381.872,222.631 401.78,234.766 421.688,274.048 441.596,265.701 461.504,321.599 481.411,368.948 \n",
       "  501.319,361.99 521.227,402.866 541.135,439.465 561.043,453.184 580.951,478.186 600.859,457.804 620.767,479.443 640.675,523.101 660.583,588.393 680.491,563.149 \n",
       "  700.399,583.829 720.306,641.68 740.214,623.142 760.122,660.012 780.03,671.42 799.938,687.211 819.846,674.032 839.754,739.452 859.662,761.817 879.57,799.414 \n",
       "  899.478,691.762 919.386,781.617 939.294,788.388 959.202,781.318 979.109,787.625 999.017,875.166 1018.93,863.458 1038.83,871.897 1058.74,893.367 1078.65,869.744 \n",
       "  1098.56,883.137 1118.46,892.856 1138.37,941.353 1158.28,850.483 1178.19,891.737 1198.1,975.672 1218,919.357 1237.91,894.688 1257.82,974.337 1277.73,1020.66 \n",
       "  1297.64,1051.69 1317.54,1000.51 1337.45,1018.11 1357.36,1062.26 1377.27,1059.23 1397.18,1026.37 1417.08,1064.41 1436.99,1022.33 1456.9,1175.58 1476.81,1134.84 \n",
       "  1496.72,1047.7 1516.62,1067.28 1536.53,1156.47 1556.44,1166.57 1576.35,1019.91 1596.25,1107.77 1616.16,1141.43 1636.07,1123.64 1655.98,1107.41 1675.89,1133.58 \n",
       "  1695.79,1070.67 1715.7,1169.69 1735.61,1216.91 1755.52,1155.32 1775.43,1211.95 1795.33,1207.18 1815.24,1188.14 1835.15,1183.25 1855.06,1154.63 1874.97,1240.02 \n",
       "  1894.87,1281.91 1914.78,1228.84 1934.69,1219.31 1954.6,1226.15 1974.51,1193.44 1994.41,1259.32 2014.32,1267.01 2034.23,1386.61 2054.14,1316.55 2074.05,1275.83 \n",
       "  2093.95,1307.53 2113.86,1208.01 2133.77,1264.16 2153.68,1240.78 2173.58,1346.72 2193.49,1352.94 2213.4,1312 2233.31,1286.19 2253.22,1324.12 2273.12,1187.1 \n",
       "  2293.03,1362.07 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4202)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" stroke-dasharray=\"16, 10\" points=\"\n",
       "  302.24,86.2547 322.148,110.121 342.056,130.753 361.964,169.21 381.872,193.778 401.78,199.738 421.688,233.481 441.596,218.53 461.504,271.066 481.411,313.452 \n",
       "  501.319,302.278 521.227,339.196 541.135,371.588 561.043,381.498 580.951,402.368 600.859,377.399 620.767,395.401 640.675,436.232 660.583,497.568 680.491,469.93 \n",
       "  700.399,487.681 720.306,542.221 740.214,521.346 760.122,555.318 780.03,564.172 799.938,577.365 819.846,561.482 839.754,624.656 859.662,644.643 879.57,679.164 \n",
       "  899.478,568.457 919.386,658.505 939.294,663.429 959.202,654.313 979.109,658.789 999.017,744.352 1018.93,731.9 1038.83,739.219 1058.74,759.475 1078.65,734.963 \n",
       "  1098.56,747.457 1118.46,756.38 1138.37,803.979 1158.28,710.225 1178.19,752.488 1198.1,836.498 1218,779.307 1237.91,752.604 1257.82,834.245 1277.73,880.034 \n",
       "  1297.64,910.181 1317.54,859.819 1337.45,877.189 1357.36,920.614 1377.27,917.499 1397.18,884.324 1417.08,922.037 1436.99,879.027 1456.9,1028.43 1476.81,990.088 \n",
       "  1496.72,903.012 1516.62,922.345 1536.53,1010.22 1556.44,1019.85 1576.35,870.489 1596.25,961.467 1616.16,994.882 1636.07,976.828 1655.98,959.881 1675.89,986.342 \n",
       "  1695.79,920.584 1715.7,1022.49 1735.61,1068.89 1755.52,1007.81 1775.43,1064.28 1795.33,1059.7 1815.24,1040.75 1835.15,1035.72 1855.06,1006.18 1874.97,1092.43 \n",
       "  1894.87,1133.13 1914.78,1081.39 1934.69,1071.76 1954.6,1078.66 1974.51,1045.24 1994.41,1112.09 2014.32,1119.94 2034.23,1233.98 2054.14,1168.68 2074.05,1128.89 \n",
       "  2093.95,1160.02 2113.86,1059.05 2133.77,1116.95 2153.68,1092.94 2173.58,1198.69 2193.49,1204.84 2213.4,1164.87 2233.31,1138.88 2253.22,1176.78 2273.12,1033.59 \n",
       "  2293.03,1214.08 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip4200)\" d=\"\n",
       "M1799.99 372.684 L2280.76 372.684 L2280.76 130.764 L1799.99 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1799.99,372.684 2280.76,372.684 2280.76,130.764 1799.99,130.764 1799.99,372.684 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1823.99,191.244 1967.99,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1991.99, 208.744)\" x=\"1991.99\" y=\"208.744\">Adam</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" stroke-dasharray=\"16, 10\" points=\"\n",
       "  1823.99,251.724 1967.99,251.724 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1991.99, 269.224)\" x=\"1991.99\" y=\"269.224\">Adam l_CI</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4200)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" stroke-dasharray=\"16, 10\" points=\"\n",
       "  1823.99,312.204 1967.99,312.204 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1991.99, 329.704)\" x=\"1991.99\" y=\"329.704\">Adam h_CI</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, _ = plotting_with_CI(fAdam, mo, paramAdam, ones(Int, length(fAdam))*sizeBatch, \"Adam\")\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "faced-temperature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip1800\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip1800)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip1801\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip1800)\" d=\"\n",
       "M153.898 1487.47 L2352.76 1487.47 L2352.76 47.2441 L153.898 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip1802\">\n",
       "    <rect x=\"153\" y=\"47\" width=\"2200\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  195.386,1487.47 195.386,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  713.984,1487.47 713.984,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1232.58,1487.47 1232.58,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1751.18,1487.47 1751.18,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2269.78,1487.47 2269.78,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,1244.19 2352.76,1244.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,958.516 2352.76,958.516 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,672.84 2352.76,672.84 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,387.163 2352.76,387.163 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,101.486 2352.76,101.486 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,1487.47 153.898,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  195.386,1487.47 195.386,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  713.984,1487.47 713.984,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1232.58,1487.47 1232.58,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1751.18,1487.47 1751.18,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2269.78,1487.47 2269.78,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,1244.19 180.284,1244.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,958.516 180.284,958.516 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,672.84 180.284,672.84 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,387.163 180.284,387.163 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,101.486 180.284,101.486 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 195.386, 1541.47)\" x=\"195.386\" y=\"1541.47\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 713.984, 1541.47)\" x=\"713.984\" y=\"1541.47\">25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1232.58, 1541.47)\" x=\"1232.58\" y=\"1541.47\">50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1751.18, 1541.47)\" x=\"1751.18\" y=\"1541.47\">75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2269.78, 1541.47)\" x=\"2269.78\" y=\"1541.47\">100</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 1261.69)\" x=\"129.898\" y=\"1261.69\">0.8</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 976.016)\" x=\"129.898\" y=\"976.016\">1.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 690.34)\" x=\"129.898\" y=\"690.34\">1.2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 404.663)\" x=\"129.898\" y=\"404.663\">1.4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 118.986)\" x=\"129.898\" y=\"118.986\">1.6</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip1802)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  216.13,88.0053 236.874,120.18 257.618,146.589 278.362,192.708 299.106,223.372 319.85,233.415 340.593,273.944 361.337,261.014 382.081,321.196 402.825,370.999 \n",
       "  423.569,360.936 444.313,404.112 465.057,442.403 485.801,455.518 506.545,480.977 527.289,455.807 548.033,477.807 568.777,524.7 589.521,594.98 610.265,565.629 \n",
       "  631.009,586.959 651.753,649.338 672.497,627.462 693.24,666.781 713.984,678.026 734.728,694.113 755.472,677.983 776.216,749.354 796.96,772.859 817.704,812.886 \n",
       "  838.448,691.695 859.192,791.542 879.936,798.033 900.68,789.05 921.424,795.035 942.168,891.109 962.912,877.7 983.656,886.445 1004.4,909.604 1025.14,882.889 \n",
       "  1045.89,897.256 1066.63,907.603 1087.38,960.937 1108.12,858.468 1128.86,904.822 1149.61,998.032 1170.35,935.036 1191.1,906.524 1211.84,996.041 1232.58,1047.16 \n",
       "  1253.33,1081.12 1274.07,1024.76 1294.81,1044.17 1315.56,1092.78 1336.3,1089.37 1357.05,1052.72 1377.79,1094.76 1398.53,1047.53 1419.28,1215.51 1440.02,1171.62 \n",
       "  1460.77,1074.92 1481.51,1096.52 1502.25,1194.79 1523,1205.74 1543.74,1041.45 1564.49,1140.71 1585.23,1177.94 1605.97,1158.04 1626.72,1139.63 1647.46,1168.84 \n",
       "  1668.21,1097.43 1688.95,1208.95 1709.69,1260.9 1730.44,1192.82 1751.18,1255.59 1771.93,1250.4 1792.67,1229.32 1813.41,1223.81 1834.16,1191.53 1854.9,1286.79 \n",
       "  1875.65,1332.63 1896.39,1274.46 1917.13,1263.82 1937.88,1271.45 1958.62,1234.75 1979.36,1308.41 2000.11,1317.04 2020.85,1446.71 2041.6,1371.59 2062.34,1326.91 \n",
       "  2083.08,1361.77 2103.83,1250.5 2124.57,1313.8 2145.32,1287.5 2166.06,1404.99 2186.8,1411.86 2207.55,1366.95 2228.29,1338.2 2249.04,1380.28 2269.78,1224.77 \n",
       "  2290.52,1422.05 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip1800)\" d=\"\n",
       "M2016.69 251.724 L2280.76 251.724 L2280.76 130.764 L2016.69 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2016.69,251.724 2280.76,251.724 2280.76,130.764 2016.69,130.764 2016.69,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip1800)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2040.69,191.244 2184.69,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip1800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2208.69, 208.744)\" x=\"2208.69\" y=\"208.744\">k</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(fAdam, label = \"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bound-block",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip2200\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip2200)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip2201\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip2200)\" d=\"\n",
       "M180.66 1487.47 L2352.76 1487.47 L2352.76 47.2441 L180.66 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip2202\">\n",
       "    <rect x=\"180\" y=\"47\" width=\"2173\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  221.643,1487.47 221.643,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  733.93,1487.47 733.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1246.22,1487.47 1246.22,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1758.5,1487.47 1758.5,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2270.79,1487.47 2270.79,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  180.66,1392.25 2352.76,1392.25 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  180.66,1182.48 2352.76,1182.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  180.66,972.712 2352.76,972.712 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  180.66,762.941 2352.76,762.941 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  180.66,553.17 2352.76,553.17 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  180.66,343.398 2352.76,343.398 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  180.66,343.398 2352.76,343.398 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,1487.47 180.66,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  221.643,1487.47 221.643,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  733.93,1487.47 733.93,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1246.22,1487.47 1246.22,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1758.5,1487.47 1758.5,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2270.79,1487.47 2270.79,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,1392.25 206.725,1392.25 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,1182.48 206.725,1182.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,972.712 206.725,972.712 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,762.941 206.725,762.941 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,553.17 206.725,553.17 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,343.398 206.725,343.398 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  180.66,343.398 206.725,343.398 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 221.643, 1541.47)\" x=\"221.643\" y=\"1541.47\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 733.93, 1541.47)\" x=\"733.93\" y=\"1541.47\">25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1246.22, 1541.47)\" x=\"1246.22\" y=\"1541.47\">50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1758.5, 1541.47)\" x=\"1758.5\" y=\"1541.47\">75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2270.79, 1541.47)\" x=\"2270.79\" y=\"1541.47\">100</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 156.66, 1409.75)\" x=\"156.66\" y=\"1409.75\">42.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 156.66, 1199.98)\" x=\"156.66\" y=\"1199.98\">42.2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 156.66, 990.212)\" x=\"156.66\" y=\"990.212\">42.4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 156.66, 780.441)\" x=\"156.66\" y=\"780.441\">42.6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 156.66, 570.67)\" x=\"156.66\" y=\"570.67\">42.8</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 156.66, 360.898)\" x=\"156.66\" y=\"360.898\">43.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 156.66, 360.898)\" x=\"156.66\" y=\"360.898\">43.0</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip2202)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.135,88.0053 262.626,108.372 283.118,128.698 303.609,148.709 324.101,169.059 344.592,189.472 365.084,209.426 385.575,229.415 406.066,248.635 426.558,267.791 \n",
       "  447.049,287.019 467.541,305.966 488.032,324.899 508.524,343.72 529.015,362.365 549.507,380.883 569.998,399.128 590.49,417.046 610.981,434.862 631.473,452.71 \n",
       "  651.964,470.321 672.456,487.701 692.947,505.064 713.438,522.449 733.93,539.712 754.421,556.781 774.913,573.7 795.404,590.336 815.896,606.793 836.387,623.228 \n",
       "  856.879,639.647 877.37,655.632 897.862,671.454 918.353,687.106 938.845,702.544 959.336,717.725 979.828,732.894 1000.32,747.818 1020.81,762.501 1041.3,777.105 \n",
       "  1061.79,791.508 1082.28,805.651 1102.78,819.589 1123.27,833.499 1143.76,846.989 1164.25,860.285 1184.74,873.538 1205.23,886.564 1225.73,899.152 1246.22,911.556 \n",
       "  1266.71,923.938 1287.2,936.259 1307.69,948.515 1328.18,960.665 1348.67,972.895 1369.17,985.114 1389.66,997.173 1410.15,1009.12 1430.64,1020.93 1451.13,1032.77 \n",
       "  1471.62,1044.73 1492.11,1056.57 1512.61,1068.14 1533.1,1079.51 1553.59,1090.98 1574.08,1102.1 1594.57,1113.18 1615.06,1124.29 1635.55,1135.5 1656.05,1146.28 \n",
       "  1676.54,1157.04 1697.03,1167.47 1717.52,1178.01 1738.01,1188.54 1758.5,1198.94 1778.99,1209.24 1799.49,1219.61 1819.98,1229.89 1840.47,1239.95 1860.96,1249.85 \n",
       "  1881.45,1259.85 1901.94,1269.81 1922.44,1279.67 1942.93,1289.21 1963.42,1298.65 1983.91,1307.97 2004.4,1317.19 2024.89,1326.52 2045.38,1335.97 2065.88,1345.66 \n",
       "  2086.37,1355.4 2106.86,1364.97 2127.35,1374.12 2147.84,1383.26 2168.33,1392.31 2188.82,1401.43 2209.32,1410.74 2229.81,1419.88 2250.3,1429 2270.79,1438 \n",
       "  2291.28,1446.71 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip2200)\" d=\"\n",
       "M1989.93 251.724 L2280.76 251.724 L2280.76 130.764 L1989.93 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.93,251.724 2280.76,251.724 2280.76,130.764 1989.93,130.764 1989.93,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2200)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.93,191.244 2157.93,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip2200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2181.93, 208.744)\" x=\"2181.93\" y=\"208.744\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(resultAdam[:DistTo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "federal-scientist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geraldine.BasicTrustRegionWithCoeff{Float64}(0.01, 0.8, 0.5, 0.9, 1.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "TYPE = Float64\n",
    "\n",
    "#####################################################################################\n",
    "# Optimisation\n",
    "verbose = true\n",
    "\n",
    "IterMax = 20 # Nombre iterations maximales\n",
    "TMax = 1800.0 # Temps max en secondes\n",
    "epsilonOptimisation = 10^(-4) # Precision norme gradient\n",
    "\n",
    "# Sampling init\n",
    "N0 = 100\n",
    "NMin = 50\n",
    "increment = 1;\n",
    "\n",
    "# subSampling\n",
    "coeff_bhhh = 0.25\n",
    "maxBhhh = 10000\n",
    "subSampling = ConstantCoeffSubSampling(maxBhhh, coeff_bhhh)\n",
    "\n",
    "#btrCoeffs = Geraldine.BTRDefaults() # avec 4*‖s‖\n",
    "btrCoeffs = Geraldine.BTRCoeffs() # avec expension de γ_3 pour iteration tres reussie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regulated-intent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accum_2nd_sHs (generic function with 2 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accum_2nd_full(xstar::Vector = [0.0, 1, 1, 2, 3, 5, 8, 13, 21, 34]) = Accumulator(Value(), Iter(),\n",
    "                FieldAccumulator{Float64}(:fcand), Delta(), Times(), SamplingSizeAccumulator(), DistTo(xstar),\n",
    "                FieldAccumulator{Float64}(:mu), \n",
    "                FieldAccumulator{Float64}(:ρ), NStep(), FieldAccumulator{Float64}(:iterCG), IsAcceptedAccumulator(), Param())\n",
    "\n",
    "Accum_2nd_tv(xstar::Vector = [0.0, 1, 1, 2, 3, 5, 8, 13, 21, 34]) = Accumulator(Value(), Iter(),\n",
    "                FieldAccumulator{Float64}(:fcand), Delta(), Times(), SamplingSizeAccumulator(), DistTo(xstar),\n",
    "                FieldAccumulator{Float64}(:mu), FieldAccumulator{Float64}(:sHs) ,\n",
    "                FieldAccumulator{Float64}(:ρ),  FieldAccumulator{Float64}(:iterCG), IsAcceptedAccumulator(), Param())\n",
    "\n",
    "Accum_2nd_sHs(xstar::Vector = [0.0, 1, 1, 2, 3, 5, 8, 13, 21, 34]) = Accumulator(Value(), Iter(),\n",
    "                FieldAccumulator{Float64}(:fcand), Delta(), Times(), SamplingSizeAccumulator(), DistTo(xstar),\n",
    "                FieldAccumulator{Float64}(:mu),  FieldAccumulator{Float64}(:sHs) ,\n",
    "                FieldAccumulator{Float64}(:ρ),  FieldAccumulator{Float64}(:iterCG), IsAcceptedAccumulator(), Param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "going-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "initializeSampling Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}! Ind / Com RN\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 6.558213896903102\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.200849827111758 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 20\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.4428481838777785\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 100\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 51\n",
      "- Decrease !! with 49\n",
      "New sample size = 51\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 6.49373275352858\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.5410954787334759\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1631560626761939 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 20\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.9530577737483247\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 51\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 54\n",
      "- Increase !! with 3\n",
      "New sample size = 54\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 6.06627104069964\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.4377334262713222\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.094683379886385 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 20\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.9392384758566833\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 54\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 57\n",
      "- Increase !! with 3\n",
      "New sample size = 57\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 5.449014425368291\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.3036127588123727\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.9553498498285495 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 20\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.7393887540134255\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 57\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 67\n",
      "- Increase !! with 10\n",
      "New sample size = 67\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 4.95285442641441\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.153215854787753\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.7646346998377753 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 20\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.4555259930651518\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 67\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 95\n",
      "- Increase !! with 28\n",
      "New sample size = 95\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 4.052869727698654\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.9389066129069721\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.5907508220359342 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 20\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.2205444877606434\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 95\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 130\n",
      "- Increase !! with 35\n",
      "New sample size = 130\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 2.876793058460035\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.7036708810789002\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.4029758650098921 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 20\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.05334048578539561\n",
      "κ = 0.00337624508221649\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 130\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 197\n",
      "- Increase !! with 67\n",
      "New sample size = 197\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 1.9948624876820178\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.4352699893859678\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.20805321805623403 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 20\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.012660033031912111\n",
      "κ = 0.006526909659283819\n",
      "κ = 0.004902252943813499\n",
      "κ = 0.0001702806448355799\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 197\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Increase !! with 316\n",
      "New sample size = 513\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 1.1082660203164643\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.25632080440124433\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.10161255078563913 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 20\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0018278200272450007\n",
      "κ = 0.0003946711747639134\n",
      "κ = 0.0007200146113042091\n",
      "κ = 0.0006136286674097441\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 513\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 1193\n",
      "- Increase !! with 680\n",
      "New sample size = 1193\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.7450711983156092\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.16989233943550328\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.06357564234087257 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 20\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0005829283408952769\n",
      "κ = 5.199237213712163e-5\n",
      "κ = 5.74822243895443e-5\n",
      "κ = 0.0002072939728557313\n",
      "κ = 1.1137016280200348e-5\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1193\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 2049\n",
      "- Increase !! with 856\n",
      "New sample size = 2049\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.5612806021754685\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.11691934151833797\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.031402902032402244 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 20\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00012428299635682723\n",
      "κ = 5.108686353600663e-6\n",
      "κ = 6.511026348545522e-6\n",
      "κ = 9.963635734263727e-5\n",
      "κ = 4.62734520069898e-6\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2049\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 6325\n",
      "- Increase !! with 4276\n",
      "New sample size = 6325\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.41330094621417574\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.08358940509552017\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.018064470808003878 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 20\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.7084585615313956e-5\n",
      "κ = 3.9028052778323626e-7\n",
      "κ = 8.725676564039929e-7\n",
      "κ = 2.5691283725888943e-5\n",
      "κ = 1.3170984145146475e-6\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 6325\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 14073\n",
      "- Increase !! with 7748\n",
      "New sample size = 14073\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.3207018311353502\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.06272847259163\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0053290273996510935 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 20\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.4545733519550021e-6\n",
      "κ = 3.9187779954344047e-8\n",
      "κ = 9.18490364144999e-8\n",
      "κ = 6.885308728924039e-6\n",
      "κ = 1.1408621295570027e-7\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 14073\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 125477\n",
      "- Increase !! with 111404\n",
      "New sample size = 125477\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.25733572858988674\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.049828469196777796\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0025199588045455804 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 20\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.71042025928645e-7\n",
      "κ = 2.1699785384714853e-9\n",
      "κ = 1.9103801169860324e-8\n",
      "κ = 8.868433276822437e-7\n",
      "κ = 7.042611527719189e-9\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 125477\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 450268\n",
      "- Increase !! with 324791\n",
      "New sample size = 450268\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.24355913546353286\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.04537940658258341\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00183952433358518 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 20\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0751237628567478e-7\n",
      "κ = 6.384821445928866e-10\n",
      "κ = 1.2097194857308152e-10\n",
      "κ = 1.9743428652011325e-7\n",
      "κ = 1.318545184386944e-8\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 450268\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 799744\n",
      "- Increase !! with 349476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 799744\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.24215009294933504\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.04471667965894383\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0005998734232161014 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 20\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.460519520074272e-9\n",
      "κ = 4.825840938359995e-11\n",
      "κ = 2.5824492326139367e-12\n",
      "κ = 5.745048052621151e-10\n",
      "κ = 1.5932260787757617e-9\n",
      "κ = 1.5503686659325038e-11\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 799744\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 1000000\n",
      "- Increase !! with 200256\n",
      "New sample size = 1000000\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.24092863989429178\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.04459711707926041\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0002468562168202777 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 20\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.7694376824115688e-9\n",
      "κ = 1.1337149984270919e-11\n",
      "κ = 9.257841859754483e-14\n",
      "κ = 3.429161039922082e-14\n",
      "κ = 6.974142397085251e-11\n",
      "κ = 3.215179852657157e-12\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1000000\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 1000000\n",
      "New sample size = 1000000\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.2409145015605578\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.044595599780094135\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 3.0455241859041376e-5 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 20\n",
      "\n",
      "Iteration 17 -> 18\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.627590756411537e-11\n",
      "κ = 2.97846390009552e-13\n",
      "κ = 1.7037297400149227e-15\n",
      "κ = 8.679439565338649e-17\n",
      "κ = 7.61106746977037e-15\n",
      "κ = 1.9340728199303112e-13\n",
      "κ = 2.6066262976317684e-15\n",
      "TCG stoped on iteration 7\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1000000\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 1000000\n",
      "New sample size = 1000000\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.24091322006929614\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.044595581496875106\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 3.7365717370772297e-6 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 20\n",
      "\n",
      "Iteration 18 -> 19\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.6016717238733903e-13\n",
      "κ = 3.915532967720548e-15\n",
      "κ = 7.229233836896774e-17\n",
      "κ = 8.856139231960512e-19\n",
      "κ = 4.530387927911372e-19\n",
      "κ = 5.543021557883495e-16\n",
      "κ = 4.4978990989326315e-17\n",
      "TCG stoped on iteration 7\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.NormTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1000000\n",
      "potentialSampleSize for Norm Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 1000000\n",
      "New sample size = 1000000\n",
      "Compute gradient for Gradient Var !!!\n",
      "var = 0.2409131609372972\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.044595581236420594\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 4.256186080667697e-7 and ϵ = 1.0000000000000004e-6\n",
      "isFirstOrderOptimal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 9 entries:\n",
       "  :IsAcceptedAccumulator              => Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n",
       "  :DeltaAccumulator                   => [0.120085, 0.180127, 0.270191, 0.40528…\n",
       "  Symbol(\"FieldAccumulator{Float64}\") => [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.…\n",
       "  :DistTo                             => [43.2435, 43.1859, 43.1027, 42.978, 42…\n",
       "  :ParamAccumulator                   => Array{T,1} where T[[0.0, 0.0, 0.0, 0.0…\n",
       "  :ValueAccumulator                   => [1.60944, 1.5411, 1.43773, 1.30361, 1.…\n",
       "  :SamplingSizeAccumulator            => ([100, 51, 54, 57, 67, 95, 130, 197, 5…\n",
       "  :Times                              => [0.0, 0.438876, 0.694368, 0.947701, 1.…\n",
       "  :IterAccumulator                    => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,…"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "##############################################################################\n",
    "                                # Test Full function / gradient / Hessian\n",
    "\n",
    "# Hessian\n",
    "Hessian = Geraldine.UncomputedHessian{TYPE}\n",
    "\n",
    "smoothing = Geraldine.NoSmoothing()\n",
    "\n",
    "varStrategy = Geraldine.GradientVar{Float64}(smoothing)\n",
    "\n",
    "# --- Sampling\n",
    "samplingStrategy = samplingStrategy = Geraldine.NormTestSampling{Geraldine.IndComRN}(Sofia.Nobs(mo), 0.3, varStrategy, \n",
    "                                                                    NMin = NMin, N0=N0, \n",
    "                                                                    increment=increment, \n",
    "                                                                    subSampling=subSampling)\n",
    "\n",
    "\n",
    "# BTR\n",
    "accBtr =  Accum_2nd_full(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = IterMax, TMax = TMax, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian,  sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorHESfull = btr(mo, copy(x0) , samplingStrategy, accumulator = accBtr, verbose = verbose)\n",
    "\n",
    "# Collecting results\n",
    " resultHESfull = Geraldine.structToDict(accumulatorHESfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "backed-finland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip2600\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip2600)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip2601\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip2600)\" d=\"\n",
       "M341.234 1487.47 L2352.76 1487.47 L2352.76 47.2441 L341.234 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip2602\">\n",
       "    <rect x=\"341\" y=\"47\" width=\"2013\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  565.605,1487.47 565.605,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  844.673,1487.47 844.673,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1123.74,1487.47 1123.74,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1402.81,1487.47 1402.81,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1681.88,1487.47 1681.88,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1960.94,1487.47 1960.94,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2240.01,1487.47 2240.01,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,1446.71 2352.76,1446.71 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,1107.04 2352.76,1107.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,767.359 2352.76,767.359 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,427.682 2352.76,427.682 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,88.0053 2352.76,88.0053 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,1487.47 341.234,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  565.605,1487.47 565.605,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  844.673,1487.47 844.673,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1123.74,1487.47 1123.74,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1402.81,1487.47 1402.81,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1681.88,1487.47 1681.88,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1960.94,1487.47 1960.94,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2240.01,1487.47 2240.01,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,1446.71 365.373,1446.71 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,1107.04 365.373,1107.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,767.359 365.373,767.359 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,427.682 365.373,427.682 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,88.0053 365.373,88.0053 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 565.605, 1541.47)\" x=\"565.605\" y=\"1541.47\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 844.673, 1541.47)\" x=\"844.673\" y=\"1541.47\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1123.74, 1541.47)\" x=\"1123.74\" y=\"1541.47\">7.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1402.81, 1541.47)\" x=\"1402.81\" y=\"1541.47\">10.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1681.88, 1541.47)\" x=\"1681.88\" y=\"1541.47\">12.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1960.94, 1541.47)\" x=\"1960.94\" y=\"1541.47\">15.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2240.01, 1541.47)\" x=\"2240.01\" y=\"1541.47\">17.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 1464.21)\" x=\"317.234\" y=\"1464.21\">1000000.00</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 1124.54)\" x=\"317.234\" y=\"1124.54\">1000000.25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 784.859)\" x=\"317.234\" y=\"784.859\">1000000.50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 445.182)\" x=\"317.234\" y=\"445.182\">1000000.75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 105.505)\" x=\"317.234\" y=\"105.505\">1000001.00</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip2602)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  398.164,1446.71 509.791,1446.71 621.419,1446.71 733.046,1446.71 844.673,1446.71 956.3,1446.71 1067.93,1446.71 1179.55,1446.71 1291.18,1446.71 1402.81,1446.71 \n",
       "  1514.44,1446.71 1626.06,1446.71 1737.69,1446.71 1849.32,1446.71 1960.94,1446.71 2072.57,1446.71 2184.2,1446.71 2295.83,1446.71 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip2600)\" d=\"\n",
       "M1989.93 251.724 L2280.76 251.724 L2280.76 130.764 L1989.93 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.93,251.724 2280.76,251.724 2280.76,130.764 1989.93,130.764 1989.93,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip2600)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.93,191.244 2157.93,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip2600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2181.93, 208.744)\" x=\"2181.93\" y=\"208.744\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(resultHESfull[:SamplingSizeAccumulator][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "headed-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip3000\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip3000)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3001\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip3000)\" d=\"\n",
       "M140.517 1487.47 L2352.76 1487.47 L2352.76 47.2441 L140.517 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3002\">\n",
       "    <rect x=\"140\" y=\"47\" width=\"2213\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  387.276,1487.47 387.276,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  694.19,1487.47 694.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1001.1,1487.47 1001.1,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1308.02,1487.47 1308.02,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1614.93,1487.47 1614.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1921.85,1487.47 1921.85,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2228.76,1487.47 2228.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,1447.18 2352.76,1447.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,1132.87 2352.76,1132.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,818.566 2352.76,818.566 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,504.258 2352.76,504.258 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,189.951 2352.76,189.951 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,1487.47 140.517,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  387.276,1487.47 387.276,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  694.19,1487.47 694.19,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1001.1,1487.47 1001.1,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1308.02,1487.47 1308.02,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1614.93,1487.47 1614.93,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1921.85,1487.47 1921.85,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2228.76,1487.47 2228.76,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,1447.18 167.064,1447.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,1132.87 167.064,1132.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,818.566 167.064,818.566 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,504.258 167.064,504.258 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,189.951 167.064,189.951 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 387.276, 1541.47)\" x=\"387.276\" y=\"1541.47\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 694.19, 1541.47)\" x=\"694.19\" y=\"1541.47\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1001.1, 1541.47)\" x=\"1001.1\" y=\"1541.47\">7.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1308.02, 1541.47)\" x=\"1308.02\" y=\"1541.47\">10.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1614.93, 1541.47)\" x=\"1614.93\" y=\"1541.47\">12.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1921.85, 1541.47)\" x=\"1921.85\" y=\"1541.47\">15.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2228.76, 1541.47)\" x=\"2228.76\" y=\"1541.47\">17.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 1464.68)\" x=\"116.517\" y=\"1464.68\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 1150.37)\" x=\"116.517\" y=\"1150.37\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 836.066)\" x=\"116.517\" y=\"836.066\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 521.758)\" x=\"116.517\" y=\"521.758\">30</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 207.451)\" x=\"116.517\" y=\"207.451\">40</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3002)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  203.127,88.0053 325.893,89.8326 448.659,92.5735 571.425,96.6849 694.19,102.852 816.956,112.102 939.722,125.978 1062.49,160.722 1185.25,204.791 1308.02,266.022 \n",
       "  1430.79,353.803 1553.55,480.012 1676.32,657.179 1799.08,889.455 1921.85,1149.38 2044.61,1356.02 2167.38,1438.26 2290.15,1446.71 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3000)\" d=\"\n",
       "M1989.93 251.724 L2280.76 251.724 L2280.76 130.764 L1989.93 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.93,251.724 2280.76,251.724 2280.76,130.764 1989.93,130.764 1989.93,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3000)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.93,191.244 2157.93,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3000)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2181.93, 208.744)\" x=\"2181.93\" y=\"208.744\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(resultHESfull[:DistTo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qualified-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "initializeSampling Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}! Ind / Com RN\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.41124439743883057\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.200849827111758 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 20\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.100129752668133\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 100\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 50\n",
      "- Decrease !! with 50\n",
      "New sample size = 50\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.36587139559146487\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.5424166830225048\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1302717562335973 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 20\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0971735810894627\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 50\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 51\n",
      "- Increase !! with 1\n",
      "New sample size = 51\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.2535563747110712\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.4476712432285948\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.0309280084065542 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 20\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.064710100949991\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 51\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 52\n",
      "- Increase !! with 1\n",
      "New sample size = 52\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.13962140655755226\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.3194973134986192\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.907908812294641 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 20\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.7978568942777418\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 52\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 53\n",
      "- Increase !! with 1\n",
      "New sample size = 53\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.05785410268513444\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.1526961393213184\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.7566890159397232 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 20\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.3892554952480013\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 53\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 54\n",
      "- Increase !! with 1\n",
      "New sample size = 54\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.015304123938937864\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.946002422137703\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.5767948524210293 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 20\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.2082565466525158\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 54\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 55\n",
      "- Increase !! with 1\n",
      "New sample size = 55\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.0026997816110003892\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.727136810167434\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.38252455652171247 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 20\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.049763270975291846\n",
      "κ = 0.021993412323943654\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 55\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 56\n",
      "- Increase !! with 1\n",
      "New sample size = 56\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.0013865072593760967\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.4321971148055579\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.15762386225540848 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 20\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0035876199736965954\n",
      "κ = 0.009128145649384651\n",
      "κ = 0.0011012553655664172\n",
      "κ = 0.0005648134078055153\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 57\n",
      "- Increase !! with 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 57\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.000306055390506107\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.28723718922871105\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0849777156659413 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 20\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0009161096725345475\n",
      "κ = 0.0007956033831281524\n",
      "κ = 0.002160312375175607\n",
      "κ = 0.0012804209912693973\n",
      "TCG on border\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 57\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 58\n",
      "- Increase !! with 1\n",
      "New sample size = 58\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.00288321358625418\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.22813241078726965\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.14379839953158066 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 20\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.005683306907556591\n",
      "κ = 0.001194519280313938\n",
      "κ = 0.00021700760773824202\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.22813241078726965\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.14379839953158066 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 20\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.005683306907556591\n",
      "κ = 0.001194519280313938\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 58\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 59\n",
      "- Increase !! with 1\n",
      "New sample size = 59\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.0023754945925900787\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.18766860400896496\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.12485834975312317 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 20\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.007998689400410382\n",
      "κ = 0.00032571771174010576\n",
      "κ = 0.00011189142053336055\n",
      "κ = 0.0002952436669091818\n",
      "TCG on border\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 59\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 60\n",
      "- Increase !! with 1\n",
      "New sample size = 60\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.0023818251301204185\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.18324223585527655\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.12706094832163456 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 20\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0033050553714489717\n",
      "κ = 0.0021380733586759603\n",
      "κ = 0.0008051756502180094\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 60\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 61\n",
      "- Increase !! with 1\n",
      "New sample size = 61\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.0007983443983251924\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.1547816784429471\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.07590609132947376 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 20\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.000636177008878901\n",
      "κ = 0.00018491596988536968\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.1547816784429471\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.07590609132947376 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 20\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.000636177008878901\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 61\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 66\n",
      "- Increase !! with 5\n",
      "New sample size = 66\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 5.6470635872959145e-5\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.13676418816990893\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03593418639925598 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 20\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0001219629446748653\n",
      "κ = 0.0006856882934648666\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 66\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 92\n",
      "- Increase !! with 26\n",
      "New sample size = 92\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 0.00113655658194039\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.1392904015820782\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.08130844606432255 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 20\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.002108566793967274\n",
      "κ = 0.0006502426657075683\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 92\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 71\n",
      "- Decrease !! with 21\n",
      "New sample size = 71\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 2.2361296107150238e-5\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.13584141177615233\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.029965175556772933 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 20\n",
      "\n",
      "Iteration 17 -> 18\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.378020186635992e-5\n",
      "κ = 0.00018494924615850757\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.InnerProductTestSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 71\n",
      "potentialSampleSize for Inner Product Test Sampling\n",
      "Default smoothing --> Nothing done\n",
      "New size = 76\n",
      "- Increase !! with 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 76\n",
      "Compute gradient for Gradient Dot Product Var !!!\n",
      "var = 7.761650812330805e-5\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.12475484120963123\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.028039022027333806 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 20\n",
      "\n",
      "Iteration 18 -> 19\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.045492367462885e-5\n",
      "κ = 9.15091451131871e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.12475484120963123\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.028039022027333806 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 19  and  max = 20\n",
      "\n",
      "Iteration 19 -> 20\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.045492367462885e-5\n",
      "κ = 9.15091451131871e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 20\n",
      "0.12475484120963123\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.028039022027333806 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 20  and  max = 20\n",
      "nmaxReached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 9 entries:\n",
       "  :IsAcceptedAccumulator              => Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, …\n",
       "  :DeltaAccumulator                   => [0.120085, 0.180127, 0.270191, 0.40528…\n",
       "  Symbol(\"FieldAccumulator{Float64}\") => [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.…\n",
       "  :DistTo                             => [43.2435, 43.1859, 43.1024, 42.9764, 4…\n",
       "  :ParamAccumulator                   => Array{T,1} where T[[0.0, 0.0, 0.0, 0.0…\n",
       "  :ValueAccumulator                   => [1.60944, 1.54242, 1.44767, 1.3195, 1.…\n",
       "  :SamplingSizeAccumulator            => ([100, 50, 51, 52, 53, 54, 55, 56, 57,…\n",
       "  :Times                              => [0.0, 0.181773, 0.384779, 0.735773, 0.…\n",
       "  :IterAccumulator                    => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9  …  11, …"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "##############################################################################\n",
    "                                # Test Full function / gradient / Hessian\n",
    "\n",
    "# Hessian\n",
    "Hessian = Geraldine.UncomputedHessian{TYPE}\n",
    "\n",
    "smoothing = Geraldine.NoSmoothing()\n",
    "\n",
    "varStrategy = Geraldine.GradientDotProductVar{Float64}(smoothing)\n",
    "\n",
    "\n",
    "# --- Sampling\n",
    "samplingStrategy = samplingStrategy = Geraldine.InnerProductTestSampling{Geraldine.IndComRN}(Sofia.Nobs(mo), varStrategy, \n",
    "                                                                    NMin = NMin, N0=N0, \n",
    "                                                                    increment=increment, \n",
    "                                                                    subSampling=subSampling)\n",
    "# BTR\n",
    "accBtr =  Accum_2nd_full(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = IterMax, TMax = TMax, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian,  sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorHESfull = btr(mo, copy(x0) , samplingStrategy, accumulator = accBtr, verbose = verbose)\n",
    "\n",
    "# Collecting results\n",
    " resultHESfull = Geraldine.structToDict(accumulatorHESfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "thousand-attribute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip3400\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3401\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M341.234 1487.47 L2352.76 1487.47 L2352.76 47.2441 L341.234 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3402\">\n",
       "    <rect x=\"341\" y=\"47\" width=\"2013\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  565.605,1487.47 565.605,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  844.673,1487.47 844.673,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1123.74,1487.47 1123.74,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1402.81,1487.47 1402.81,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1681.88,1487.47 1681.88,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1960.94,1487.47 1960.94,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2240.01,1487.47 2240.01,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,1446.71 2352.76,1446.71 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,1107.04 2352.76,1107.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,767.359 2352.76,767.359 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,427.682 2352.76,427.682 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  341.234,88.0053 2352.76,88.0053 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,1487.47 341.234,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  565.605,1487.47 565.605,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  844.673,1487.47 844.673,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1123.74,1487.47 1123.74,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1402.81,1487.47 1402.81,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1681.88,1487.47 1681.88,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1960.94,1487.47 1960.94,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2240.01,1487.47 2240.01,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,1446.71 365.373,1446.71 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,1107.04 365.373,1107.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,767.359 365.373,767.359 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,427.682 365.373,427.682 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  341.234,88.0053 365.373,88.0053 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 565.605, 1541.47)\" x=\"565.605\" y=\"1541.47\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 844.673, 1541.47)\" x=\"844.673\" y=\"1541.47\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1123.74, 1541.47)\" x=\"1123.74\" y=\"1541.47\">7.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1402.81, 1541.47)\" x=\"1402.81\" y=\"1541.47\">10.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1681.88, 1541.47)\" x=\"1681.88\" y=\"1541.47\">12.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1960.94, 1541.47)\" x=\"1960.94\" y=\"1541.47\">15.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2240.01, 1541.47)\" x=\"2240.01\" y=\"1541.47\">17.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 1464.21)\" x=\"317.234\" y=\"1464.21\">1000000.00</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 1124.54)\" x=\"317.234\" y=\"1124.54\">1000000.25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 784.859)\" x=\"317.234\" y=\"784.859\">1000000.50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 445.182)\" x=\"317.234\" y=\"445.182\">1000000.75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 317.234, 105.505)\" x=\"317.234\" y=\"105.505\">1000001.00</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  398.164,1446.71 509.791,1446.71 621.419,1446.71 733.046,1446.71 844.673,1446.71 956.3,1446.71 1067.93,1446.71 1179.55,1446.71 1291.18,1446.71 1402.81,1446.71 \n",
       "  1514.44,1446.71 1626.06,1446.71 1737.69,1446.71 1849.32,1446.71 1960.94,1446.71 2072.57,1446.71 2184.2,1446.71 2295.83,1446.71 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M1989.93 251.724 L2280.76 251.724 L2280.76 130.764 L1989.93 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.93,251.724 2280.76,251.724 2280.76,130.764 1989.93,130.764 1989.93,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.93,191.244 2157.93,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2181.93, 208.744)\" x=\"2181.93\" y=\"208.744\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(resultHESfull[:SamplingSizeAccumulator][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "unlike-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip3800\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip3800)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3801\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip3800)\" d=\"\n",
       "M140.517 1487.47 L2352.76 1487.47 L2352.76 47.2441 L140.517 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3802\">\n",
       "    <rect x=\"140\" y=\"47\" width=\"2213\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  387.276,1487.47 387.276,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  694.19,1487.47 694.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1001.1,1487.47 1001.1,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1308.02,1487.47 1308.02,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1614.93,1487.47 1614.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1921.85,1487.47 1921.85,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2228.76,1487.47 2228.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,1447.18 2352.76,1447.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,1132.87 2352.76,1132.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,818.566 2352.76,818.566 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,504.258 2352.76,504.258 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.517,189.951 2352.76,189.951 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,1487.47 140.517,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  387.276,1487.47 387.276,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  694.19,1487.47 694.19,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1001.1,1487.47 1001.1,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1308.02,1487.47 1308.02,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1614.93,1487.47 1614.93,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1921.85,1487.47 1921.85,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2228.76,1487.47 2228.76,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,1447.18 167.064,1447.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,1132.87 167.064,1132.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,818.566 167.064,818.566 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,504.258 167.064,504.258 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.517,189.951 167.064,189.951 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 387.276, 1541.47)\" x=\"387.276\" y=\"1541.47\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 694.19, 1541.47)\" x=\"694.19\" y=\"1541.47\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1001.1, 1541.47)\" x=\"1001.1\" y=\"1541.47\">7.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1308.02, 1541.47)\" x=\"1308.02\" y=\"1541.47\">10.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1614.93, 1541.47)\" x=\"1614.93\" y=\"1541.47\">12.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1921.85, 1541.47)\" x=\"1921.85\" y=\"1541.47\">15.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2228.76, 1541.47)\" x=\"2228.76\" y=\"1541.47\">17.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 1464.68)\" x=\"116.517\" y=\"1464.68\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 1150.37)\" x=\"116.517\" y=\"1150.37\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 836.066)\" x=\"116.517\" y=\"836.066\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 521.758)\" x=\"116.517\" y=\"521.758\">30</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 116.517, 207.451)\" x=\"116.517\" y=\"207.451\">40</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3802)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  203.127,88.0053 325.893,89.8326 448.659,92.5735 571.425,96.6849 694.19,102.852 816.956,112.102 939.722,125.978 1062.49,160.722 1185.25,204.791 1308.02,266.022 \n",
       "  1430.79,353.803 1553.55,480.012 1676.32,657.179 1799.08,889.455 1921.85,1149.38 2044.61,1356.02 2167.38,1438.26 2290.15,1446.71 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3800)\" d=\"\n",
       "M1989.93 251.724 L2280.76 251.724 L2280.76 130.764 L1989.93 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.93,251.724 2280.76,251.724 2280.76,130.764 1989.93,130.764 1989.93,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3800)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.93,191.244 2157.93,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2181.93, 208.744)\" x=\"2181.93\" y=\"208.744\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(resultHESfull[:DistTo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-cologne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "administrative-suite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.NoSampling\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1627290165465178 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 20\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.081137872430489\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.543191967079469\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.116267637620475 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 20\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.9945019335861105\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.4488745591462684\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.0469819100445752 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 20\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.8656605536745865\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.3186155480644743\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.9452028559236315 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 20\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.6824627783310411\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.1474897576998688\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.8012349277292069 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 20\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.44870763079026094\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.9401187514822373\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.6144983050198326 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 20\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.21374069693431572\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.7172980671096796\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.40941687847778896 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 20\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.06208339041468925\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.4240074485856072\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.16665064016800873 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 20\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.003300968866422061\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.27012427217549406\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.07132240067688392 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 20\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00018623474599297575\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.17811615409964568\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.031071665011813885 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 20\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.1110900929155016e-5\n",
      "κ = 0.00010401396659527582\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.12062912448161744\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.013559401635955329 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 20\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κ = 6.455864689880502e-7\n",
      "κ = 3.490124157271726e-5\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.08461798341733323\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0058718591355537905 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 20\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.779833257307775e-8\n",
      "κ = 1.2652539252438884e-5\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.06287450189810757\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0024789045046330156 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 20\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.361867395515734e-9\n",
      "κ = 7.277080297527688e-6\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.05103970235898414\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0009824449165734 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 20\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.0448710064016815e-10\n",
      "κ = 2.3197878002968393e-6\n",
      "κ = 5.398915872259895e-10\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.045980074164531724\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00033413388806586756 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 20\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.1995983195398384e-11\n",
      "κ = 1.2761627830611593e-7\n",
      "κ = 3.9123775522191954e-10\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.044704257880206155\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 7.792444992225936e-5 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 20\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.8919479771215534e-12\n",
      "κ = 1.3717182184652282e-9\n",
      "κ = 1.20847403993816e-10\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.044596582135783824\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 7.053064483333193e-6 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 20\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.8351133616966863e-14\n",
      "κ = 2.557359125551262e-12\n",
      "κ = 1.8151102502624787e-12\n",
      "κ = 5.955917292145394e-17\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.04459558133260795\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 7.022145977569114e-8 and ϵ = 1.0000000000000004e-6\n",
      "isFirstOrderOptimal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 9 entries:\n",
       "  :IsAcceptedAccumulator              => Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n",
       "  :DeltaAccumulator                   => [0.116273, 0.174409, 0.261614, 0.39242…\n",
       "  Symbol(\"FieldAccumulator{Float64}\") => [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.…\n",
       "  :DistTo                             => [43.2435, 43.1854, 43.0982, 42.9673, 4…\n",
       "  :ParamAccumulator                   => Array{T,1} where T[[0.0, 0.0, 0.0, 0.0…\n",
       "  :ValueAccumulator                   => [1.60944, 1.54319, 1.44887, 1.31862, 1…\n",
       "  :SamplingSizeAccumulator            => ([1000000, 1000000, 1000000, 1000000, …\n",
       "  :Times                              => [0.0, 31.2768, 62.0005, 119.084, 151.4…\n",
       "  :IterAccumulator                    => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,…"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "                                # Test Full function / gradient / Hessian\n",
    "\n",
    "accumulator = Accum_2nd_tv(xstar)\n",
    "# Hessian\n",
    "Hessian = Geraldine.UncomputedHessian{TYPE}\n",
    "\n",
    "# --- Sampling\n",
    "subSampling = Geraldine.FullHessian()\n",
    "samplingStrategy = Geraldine.NoSampling(Nobs(mo), subSampling=subSampling)\n",
    "\n",
    "# BTR\n",
    "accBtr =  Accum_2nd_full(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = IterMax, TMax = TMax, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian,  sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorHESfull = btr(mo, copy(x0) , samplingStrategy, accumulator = accBtr, verbose = verbose)\n",
    "\n",
    "# Collecting results\n",
    " resultHESfull = Geraldine.structToDict(accumulatorHESfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "functioning-forest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.NoSampling\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1627290165465178 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 20\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.069134605507795\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.543191967079469\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.116267637620475 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 20\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.9915360711320138\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.4488745591462684\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.0469819100445752 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 20\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.8678784096224132\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.3186155480644743\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.9452028559236315 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 20\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.6805597877886825\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.1474897576998688\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.8012349277292069 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 20\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.44946951151481074\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.9401187514822373\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.6144983050198326 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 20\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.21429602874385553\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.7172980671096796\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.40941687847778896 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 20\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.061817004232368425\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.42321495692223154\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.1660857582936959 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 20\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00327713621878837\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.27007811503217694\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.07129871889646541 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 20\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00018763465967506517\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.17860835826177762\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03124789925978029 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 20\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.138650947747738e-5\n",
      "κ = 0.00010741901047223721\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.1211783356851881\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.013748947684582678 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 20\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TCG classic \n",
      "κ = 8.733876096272802e-7\n",
      "κ = 0.00014001473447828247\n",
      "κ = 9.404005640888534e-7\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.08521869556862192\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006204707911189832 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 20\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.796562392927814e-7\n",
      "κ = 4.654745524037572e-6\n",
      "κ = 5.100044983224024e-6\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.0632287538977804\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002985970791756756 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 20\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6925566216182205e-7\n",
      "κ = 3.575030245255779e-8\n",
      "κ = 1.1542811864806965e-5\n",
      "κ = 4.9417265879479186e-8\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.051181908645305696\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0011722653213146685 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 20\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.716441921451717e-8\n",
      "κ = 2.4903306086133132e-9\n",
      "κ = 2.689571303897467e-6\n",
      "κ = 8.788740787355e-9\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.04601243443274369\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0007071424566878128 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 20\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2867823663956286e-8\n",
      "κ = 1.2895380370884527e-10\n",
      "κ = 1.4200087342889738e-8\n",
      "κ = 1.7911517257712628e-7\n",
      "κ = 5.80212513687251e-10\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.04470150435641157\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0004405211423028979 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 20\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.019390076739838e-9\n",
      "κ = 7.307792025912377e-11\n",
      "κ = 4.899693876268857e-12\n",
      "κ = 1.3770041927987119e-8\n",
      "κ = 7.618492565774382e-10\n",
      "κ = 4.680576189208156e-12\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.04459729365530684\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00020102311111357338 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 20\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.078932980780541e-9\n",
      "κ = 1.112096424583346e-11\n",
      "κ = 8.698826617468684e-14\n",
      "κ = 5.879410977761985e-13\n",
      "κ = 1.7813228888321255e-10\n",
      "κ = 3.277908436830085e-12\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.044595588382809255\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.3993058540555432e-5 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 20\n",
      "\n",
      "Iteration 17 -> 18\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.141222238828575e-12\n",
      "κ = 3.272917886659616e-14\n",
      "κ = 2.1337719340052364e-16\n",
      "κ = 3.510812073930275e-15\n",
      "κ = 6.746526032108005e-13\n",
      "κ = 3.282277120550043e-15\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.044595581258025714\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1051764696500767e-6 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 20\n",
      "\n",
      "Iteration 18 -> 19\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.7251397086997113e-14\n",
      "κ = 2.911114592680321e-16\n",
      "κ = 3.637703989128228e-19\n",
      "κ = 2.8587505540867597e-19\n",
      "κ = 2.857894030003877e-16\n",
      "κ = 1.9991663275896003e-17\n",
      "κ = 1.2162873741659738e-19\n",
      "TCG stoped on iteration 7\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.04459558123406474\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 2.5011525772956437e-7 and ϵ = 1.0000000000000004e-6\n",
      "isFirstOrderOptimal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 9 entries:\n",
       "  :IsAcceptedAccumulator              => Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n",
       "  :DeltaAccumulator                   => [0.116273, 0.174409, 0.261614, 0.39242…\n",
       "  Symbol(\"FieldAccumulator{Float64}\") => [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.…\n",
       "  :DistTo                             => [43.2435, 43.1854, 43.0982, 42.9673, 4…\n",
       "  :ParamAccumulator                   => Array{T,1} where T[[0.0, 0.0, 0.0, 0.0…\n",
       "  :ValueAccumulator                   => [1.60944, 1.54319, 1.44887, 1.31862, 1…\n",
       "  :SamplingSizeAccumulator            => ([1000000, 1000000, 1000000, 1000000, …\n",
       "  :Times                              => [0.0, 9.54347, 16.7506, 23.8713, 31.03…\n",
       "  :IterAccumulator                    => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,…"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "                                # Test Full function / gradient \n",
    "                                #   Sub-sampled Hessian\n",
    "\n",
    "accumulator = Accum_2nd_tv(xstar)\n",
    "# Hessian\n",
    "Hessian = Geraldine.UncomputedHessian{TYPE}\n",
    "\n",
    "# --- Sampling\n",
    "subSampling = ConstantCoeffSubSampling(maxBhhh, coeff_bhhh)\n",
    "\n",
    "samplingStrategy = Geraldine.NoSampling(Nobs(mo), subSampling=subSampling)\n",
    "\n",
    "# BTR\n",
    "accBtr =  Accum_2nd_full(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = IterMax, TMax = TMax, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian,  sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorHES_sub = btr(mo, copy(x0) , samplingStrategy, accumulator = accBtr, verbose = verbose)\n",
    "\n",
    " # Collecting results\n",
    " resultHES_sub = Geraldine.structToDict(accumulatorHES_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "employed-stanley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "initializeSampling Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}! Ind / Com RN\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.200849827111758 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 20\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6000449377730672\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 100\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 75\n",
      "- Decrease !! with 25\n",
      "New sample size = 75\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.540299000427953\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1327979648809414 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 20\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.063118513055132\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 75\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56\n",
      "- Decrease !! with 19\n",
      "New sample size = 56\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.4454861047163265\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.0348444149780436 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 20\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0933357293487187\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 52\n",
      "- Decrease !! with 4\n",
      "New sample size = 52\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.306532061693366\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.9490574121508961 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 20\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.5044951834123301\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 52\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 53\n",
      "- Increase !! with 1\n",
      "New sample size = 53\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.128209344562061\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.7997070799189503 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 20\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.3835766303193032\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 53\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 54\n",
      "- Increase !! with 1\n",
      "New sample size = 54\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.9125554209128793\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.6103848901412694 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 20\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.21655065018192923\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 54\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 55\n",
      "- Increase !! with 1\n",
      "New sample size = 55\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.6773043455294396\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.4063302483277261 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 20\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.06181730352850999\n",
      "κ = 0.025477265351871607\n",
      "κ = 0.006336013370748718\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 55\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56\n",
      "- Increase !! with 1\n",
      "New sample size = 56\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.3830769436013889\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.23575124140683304 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 20\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.01719379133567589\n",
      "κ = 0.0031264357287295423\n",
      "κ = 0.0005066471215504684\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 57\n",
      "- Increase !! with 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 57\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.2154766014550316\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.14517988151605463 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 20\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.008673577099382008\n",
      "κ = 0.002255578999246556\n",
      "κ = 0.0005930107471568075\n",
      "κ = 0.0003477083328884318\n",
      "κ = 0.0006716716230501233\n",
      "κ = 0.00041316927451714595\n",
      "κ = 8.028030960602116e-5\n",
      "TCG stoped on iteration 7\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 57\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 58\n",
      "- Increase !! with 1\n",
      "New sample size = 58\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.12944780515846774\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.09525847977666616 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 20\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0012803794250074293\n",
      "κ = 0.0012010956535551984\n",
      "κ = 0.0018002165218924042\n",
      "κ = 0.0005208163319191169\n",
      "κ = 6.08180569459585e-5\n",
      "κ = 2.60032684323803e-5\n",
      "κ = 5.384365157066524e-6\n",
      "TCG stoped on iteration 7\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.12944780515846774\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.09525847977666616 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 20\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0012803794250074293\n",
      "κ = 0.0012010956535551984\n",
      "κ = 0.0018002165218924042\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.12944780515846774\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.09525847977666616 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 20\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0012803794250074293\n",
      "κ = 0.0012010956535551984\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 58\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 116\n",
      "- Increase !! with 58\n",
      "New sample size = 116\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.12064979709316527\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.08296080611581393 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 20\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0008747902232133829\n",
      "κ = 0.0001772304320237144\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 116\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 232\n",
      "- Increase !! with 116\n",
      "New sample size = 232\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.11308853382601264\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.05948905183811838 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 20\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0002715849168275554\n",
      "κ = 0.00016544078925804321\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 232\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 464\n",
      "- Increase !! with 232\n",
      "New sample size = 464\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.1434025956184979\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.09479291400546275 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 20\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0012560486738100514\n",
      "κ = 9.35921438180151e-5\n",
      "κ = 1.3714719910278424e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 464\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 928\n",
      "- Increase !! with 464\n",
      "New sample size = 928\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.12835264142886715\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.060888020080262464 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 20\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0007050245599957177\n",
      "κ = 5.177337135344726e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 928\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1010\n",
      "- Increase !! with 82\n",
      "New sample size = 1010\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.11462925406917729\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.021147157675854927 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 16  and  max = 20\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.463185689202954e-5\n",
      "κ = 8.141564677747546e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1010\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2020\n",
      "- Increase !! with 1010\n",
      "New sample size = 2020\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.11592166352163476\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.028852397491528528 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 20\n",
      "\n",
      "Iteration 17 -> 18\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00010679391779985171\n",
      "κ = 2.4834962296798975e-6\n",
      "κ = 2.7793372018280652e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2020\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1515\n",
      "- Decrease !! with 505\n",
      "New sample size = 1515\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.10088446659784887\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0283920245309921 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 20\n",
      "\n",
      "Iteration 18 -> 19\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.761164091457898e-5\n",
      "κ = 4.956974974739039e-6\n",
      "κ = 1.3067448138196805e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1515\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1136\n",
      "- Decrease !! with 379\n",
      "New sample size = 1136\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.08460725572876739\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01769823467793513 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 19  and  max = 20\n",
      "\n",
      "Iteration 19 -> 20\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.181505934740142e-5\n",
      "κ = 1.2339489624364542e-6\n",
      "κ = 2.331920404927471e-6\n",
      "κ = 3.7034510340193314e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1136\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 876\n",
      "- Decrease !! with 260\n",
      "New sample size = 876\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 20\n",
      "0.06915197428351262\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.023133457503437583 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 20  and  max = 20\n",
      "nmaxReached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 9 entries:\n",
       "  :IsAcceptedAccumulator              => Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, …\n",
       "  :DeltaAccumulator                   => [0.120085, 0.180127, 0.270191, 0.40528…\n",
       "  Symbol(\"FieldAccumulator{Float64}\") => [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.…\n",
       "  :DistTo                             => [43.2435, 43.1859, 43.0997, 42.9695, 4…\n",
       "  :ParamAccumulator                   => Array{T,1} where T[[0.0, 0.0, 0.0, 0.0…\n",
       "  :ValueAccumulator                   => [1.60944, 1.5403, 1.44549, 1.30653, 1.…\n",
       "  :SamplingSizeAccumulator            => ([100, 75, 56, 52, 53, 54, 55, 56, 57,…\n",
       "  :Times                              => [0.0, 0.209733, 0.249059, 0.295502, 0.…\n",
       "  :IterAccumulator                    => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9  …  11, …"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "                                # Test Hessian / True Var \n",
    "\n",
    "accumulator = Accum_2nd_tv(xstar)\n",
    "# Hessian\n",
    "Hessian = Geraldine.UncomputedHessian{TYPE}\n",
    "\n",
    "# Smoothing\n",
    "smoothing = Geraldine.NaiveSmoothing()\n",
    "# --- Sampling\n",
    "varStrategy = Geraldine.TrueVar{Float64}(smoothing)\n",
    "\n",
    "# --- Sampling\n",
    "subSampling = ConstantCoeffSubSampling(maxBhhh, coeff_bhhh)\n",
    "samplingStrategy = Geraldine.DynamicSampling{Geraldine.IndComRN}(Sofia.Nobs(mo), varStrategy, \n",
    "                                                                    NMin = NMin, N0=N0, \n",
    "                                                                    increment=increment, \n",
    "                                                                    subSampling=subSampling)\n",
    "\n",
    "# BTR\n",
    "accBtr =  Accum_2nd_tv(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = IterMax, TMax = TMax, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian,  sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorHEStv = btr(mo, copy(x0) , samplingStrategy, accumulator = accBtr, verbose = verbose)\n",
    "\n",
    " # Collecting results\n",
    " resultHEStv = Geraldine.structToDict(accumulatorHEStv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "paperback-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Collecting results\n",
    " resultHEStv = Geraldine.structToDict(accumulatorHEStv)\n",
    "\n",
    "samplingHEStv = resultHEStv[:SamplingSizeAccumulator]\n",
    "fHEStv = resultHEStv[:ValueAccumulator]\n",
    "paramHEStv = resultHEStv[:ParamAccumulator];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "boolean-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "y1",
         "line": {
          "color": "rgba(0, 154, 250, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "y1",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21
         ],
         "xaxis": "x1",
         "y": [
          100,
          75,
          56,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          58,
          58,
          116,
          232,
          464,
          928,
          1010,
          2020,
          1515,
          1136,
          876
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        }
       ],
       "layout": {
        "annotations": [],
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 1.000)",
         "bordercolor": "rgba(0, 0, 0, 1.000)",
         "font": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tracegroupgap": 0,
         "x": 1,
         "y": 1
        },
        "margin": {
         "b": 20,
         "l": 0,
         "r": 0,
         "t": 20
        },
        "paper_bgcolor": "rgba(255, 255, 255, 1.000)",
        "plot_bgcolor": "rgba(255, 255, 255, 1.000)",
        "showlegend": true,
        "width": 600,
        "xaxis": {
         "anchor": "y1",
         "domain": [
          0.0658209390492855,
          0.9934383202099738
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          0.4,
          21.6
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "5",
          "10",
          "15",
          "20"
         ],
         "tickvals": [
          5,
          10,
          15,
          20
         ],
         "title": "",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        },
        "yaxis": {
         "anchor": "x1",
         "domain": [
          0.03762029746281716,
          0.9901574803149606
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          -7.039999999999999,
          2079.04
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "0",
          "500",
          "1000",
          "1500",
          "2000"
         ],
         "tickvals": [
          0,
          500,
          1000,
          1500,
          2000
         ],
         "title": "",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        }
       }
      },
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "    <head>\n",
       "        <title>Plots.jl</title>\n",
       "        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
       "    </head>\n",
       "    <body>\n",
       "            <div id=\"f15e9fad-21cc-48a1-8105-d0ba8ad1c4f5\" style=\"width:600px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('f15e9fad-21cc-48a1-8105-d0ba8ad1c4f5');\n",
       "    Plotly.plot(PLOT, [\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            1,\n",
       "            2,\n",
       "            3,\n",
       "            4,\n",
       "            5,\n",
       "            6,\n",
       "            7,\n",
       "            8,\n",
       "            9,\n",
       "            10,\n",
       "            11,\n",
       "            12,\n",
       "            13,\n",
       "            14,\n",
       "            15,\n",
       "            16,\n",
       "            17,\n",
       "            18,\n",
       "            19,\n",
       "            20,\n",
       "            21\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"y1\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"y1\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(0, 154, 250, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            100.0,\n",
       "            75.0,\n",
       "            56.0,\n",
       "            52.0,\n",
       "            53.0,\n",
       "            54.0,\n",
       "            55.0,\n",
       "            56.0,\n",
       "            57.0,\n",
       "            58.0,\n",
       "            58.0,\n",
       "            58.0,\n",
       "            116.0,\n",
       "            232.0,\n",
       "            464.0,\n",
       "            928.0,\n",
       "            1010.0,\n",
       "            2020.0,\n",
       "            1515.0,\n",
       "            1136.0,\n",
       "            876.0\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    }\n",
       "]\n",
       ", {\n",
       "    \"showlegend\": true,\n",
       "    \"xaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            5.0,\n",
       "            10.0,\n",
       "            15.0,\n",
       "            20.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            0.4,\n",
       "            21.6\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.0658209390492855,\n",
       "            0.9934383202099738\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"5\",\n",
       "            \"10\",\n",
       "            \"15\",\n",
       "            \"20\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"y1\"\n",
       "    },\n",
       "    \"paper_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"annotations\": [],\n",
       "    \"height\": 400,\n",
       "    \"margin\": {\n",
       "        \"l\": 0,\n",
       "        \"b\": 20,\n",
       "        \"r\": 0,\n",
       "        \"t\": 20\n",
       "    },\n",
       "    \"plot_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"yaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            0.0,\n",
       "            500.0,\n",
       "            1000.0,\n",
       "            1500.0,\n",
       "            2000.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            -7.039999999999999,\n",
       "            2079.04\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.03762029746281716,\n",
       "            0.9901574803149606\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"0\",\n",
       "            \"500\",\n",
       "            \"1000\",\n",
       "            \"1500\",\n",
       "            \"2000\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"x1\"\n",
       "    },\n",
       "    \"legend\": {\n",
       "        \"tracegroupgap\": 0,\n",
       "        \"bordercolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "        \"font\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"y\": 1.0,\n",
       "        \"x\": 1.0\n",
       "    },\n",
       "    \"width\": 600\n",
       "}\n",
       ");\n",
       "    </script>\n",
       "\n",
       "    </body>\n",
       "</html>\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(samplingHEStv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fuzzy-glenn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "initializeSampling Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}! Ind / Com RN\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1367614531508978 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 20\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.9749993779603691\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 876\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 657\n",
      "- Decrease !! with 219\n",
      "New sample size = 657\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.5455483785986546\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1022635405153316 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 20\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.9080197379807318\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 657\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 492\n",
      "- Decrease !! with 165\n",
      "New sample size = 492\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.453388765272481\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.042727610950944 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 20\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.987017153950988\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 492\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 369\n",
      "- Decrease !! with 123\n",
      "New sample size = 369\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.3294122424609187\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.9375251136197055 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 20\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.5743376440782717\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 369\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 276\n",
      "- Decrease !! with 93\n",
      "New sample size = 276\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.1576413993255898\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.8052934500551387 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 20\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.5070706395875515\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 276\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 207\n",
      "- Decrease !! with 69\n",
      "New sample size = 207\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.9659862642730552\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.6162502257935556 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 20\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.23115525349516514\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 207\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 155\n",
      "- Decrease !! with 52\n",
      "New sample size = 155\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.7452878440154856\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.4233084383733838 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 20\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.07131015331148483\n",
      "κ = 0.008181614550081937\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 155\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 116\n",
      "- Decrease !! with 39\n",
      "New sample size = 116\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.4242183512549217\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.20012499864605515 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 20\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00712330430812976\n",
      "κ = 0.005775487083995962\n",
      "κ = 0.0012573913798551066\n",
      "κ = 0.0004531556776556238\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 116\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 87\n",
      "- Decrease !! with 29\n",
      "New sample size = 87\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.24753157598609313\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.12673208070595138 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 20\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0025854628442487327\n",
      "κ = 0.002947118226117535\n",
      "κ = 0.0007753172406671032\n",
      "κ = 0.0005525971617603574\n",
      "κ = 0.0012805819803995391\n",
      "κ = 0.00029927023259756293\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 87\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 109\n",
      "- Increase !! with 22\n",
      "New sample size = 109\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.16383042362614406\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.1324943795017446 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 20\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0022158237341432865\n",
      "κ = 0.004495532768396741\n",
      "κ = 0.0006912739970872139\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.16383042362614406\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.1324943795017446 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 20\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0022158237341432865\n",
      "κ = 0.004495532768396741\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 109\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 218\n",
      "- Increase !! with 109\n",
      "New sample size = 218\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.1575188002841198\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.11535408027419602 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 20\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0029731576986801204\n",
      "κ = 0.0004498527318603483\n",
      "κ = 0.0003895863689117417\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 218\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 436\n",
      "- Increase !! with 218\n",
      "New sample size = 436\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.17209413050698488\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.12490889727435271 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 20\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.002236866072704902\n",
      "κ = 0.00015913250086614048\n",
      "κ = 1.3909424824379002e-5\n",
      "κ = 4.7378338384529194e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 436\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 327\n",
      "- Decrease !! with 109\n",
      "New sample size = 327\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.12279846033842982\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0511589072932748 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 20\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00025505738471118787\n",
      "κ = 5.907262311928109e-5\n",
      "κ = 3.2073050595988e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.12279846033842982\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0511589072932748 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 20\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00025505738471118787\n",
      "κ = 5.907262311928109e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 327\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 654\n",
      "- Increase !! with 327\n",
      "New sample size = 654\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.11970385978381513\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.04237389190386908 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 20\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00020681281430643506\n",
      "κ = 2.5028534989291008e-5\n",
      "κ = 2.43002692831723e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 654\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1308\n",
      "- Increase !! with 654\n",
      "New sample size = 1308\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.12109732726122154\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.04426442738682912 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 20\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0002656074149222084\n",
      "κ = 1.7727168677685912e-5\n",
      "κ = 8.520161577829122e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1308\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2067\n",
      "- Increase !! with 759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 2067\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.12114867408901146\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03215884571727157 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 20\n",
      "\n",
      "Iteration 17 -> 18\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0001264129089626568\n",
      "κ = 9.096349653820402e-6\n",
      "κ = 7.074282900967943e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2067\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2898\n",
      "- Increase !! with 831\n",
      "New sample size = 2898\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.1133809480842903\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.032889026486514074 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 20\n",
      "\n",
      "Iteration 18 -> 19\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00011238258897149773\n",
      "κ = 1.038364164628685e-5\n",
      "κ = 3.4134018776099786e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2898\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2580\n",
      "- Decrease !! with 318\n",
      "New sample size = 2580\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.10068281860899285\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.021734562085567607 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 19  and  max = 20\n",
      "\n",
      "Iteration 19 -> 20\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.922985598808363e-5\n",
      "κ = 9.792438226728216e-7\n",
      "κ = 1.5026312020980732e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2580\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1935\n",
      "- Decrease !! with 645\n",
      "New sample size = 1935\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 20\n",
      "0.09432438378143557\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.028873008465081677 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 20  and  max = 20\n",
      "nmaxReached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"here's a state\"\"here's an Accumulator\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "                                # Test Hessian / Ture Var \n",
    "\n",
    "accumulator = Accum_2nd_tv(xstar)\n",
    "# Hessian\n",
    "Hessian = Geraldine.UncomputedHessian{TYPE}\n",
    "\n",
    "# Smoothing\n",
    "smoothing = Geraldine.CumulativeDecreaseSmoothing{Float64}(maxIter=5)\n",
    "\n",
    "# --- Sampling\n",
    "varStrategy = Geraldine.TrueVar{Float64}(smoothing)\n",
    "\n",
    "# --- Sampling\n",
    "Geraldine.DynamicSampling{Geraldine.IndComRN}(Sofia.Nobs(mo), varStrategy, \n",
    "                                                                    NMin = NMin, N0=N0, \n",
    "                                                                    increment=increment, \n",
    "                                                                    subSampling=subSampling)\n",
    "\n",
    "\n",
    "# BTR\n",
    "accBtr =  Accum_2nd_tv(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = IterMax, TMax = TMax, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian,  sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorHEStv2 = btr(mo, copy(x0) , samplingStrategy, accumulator = accBtr, verbose = verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "after-reverse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "initializeSampling Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}! Ind / Com RN\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.200849827111758 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 20\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.8313236300509061\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 100\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 75\n",
      "- Decrease !! with 25\n",
      "New sample size = 75\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.536545657074348\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1903612611691718 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 20\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.893719891022381\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 75\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56\n",
      "- Decrease !! with 19\n",
      "New sample size = 56\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.4314502105448257\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1359433876583316 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 20\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.2429655393814896\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 52\n",
      "- Decrease !! with 4\n",
      "New sample size = 52\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.2823686931623866\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.0176987095217684 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 20\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.4326903460063876\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 52\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 53\n",
      "- Increase !! with 1\n",
      "New sample size = 53\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.0891167463701439\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.8463995089168299 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 20\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.6134511867052208\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 53\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 54\n",
      "- Increase !! with 1\n",
      "New sample size = 54\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.8670982749874647\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.6289013450826134 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 20\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.18281248676000145\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 54\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 55\n",
      "- Increase !! with 1\n",
      "New sample size = 55\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.6436951421588483\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.4078680050142851 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 20\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.028618005963046124\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 55\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56\n",
      "- Increase !! with 1\n",
      "New sample size = 56\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.4281810666851908\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.22988827916184754 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 20\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0041941209891537875\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 57\n",
      "- Increase !! with 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 57\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.26557734187206383\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.11464067141584772 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 20\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00019308527078932056\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 57\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 58\n",
      "- Increase !! with 1\n",
      "New sample size = 58\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.1636583007510896\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.08728944548621566 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 20\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0002102593222124414\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.1636583007510896\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.08728944548621566 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 20\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0002102593222124414\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 58\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 116\n",
      "- Increase !! with 58\n",
      "New sample size = 116\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.2542077287407766\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.2277542146467231 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 20\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.018989507532935056\n",
      "κ = 0.0035610060623060633\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 116\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 87\n",
      "- Decrease !! with 29\n",
      "New sample size = 87\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.16151915230731642\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.08079625126177181 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 20\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00022278737765320234\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 87\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 174\n",
      "- Increase !! with 87\n",
      "New sample size = 174\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.17439150391318833\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.09289021364976943 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 20\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0009696669393580285\n",
      "κ = 0.00015011787568899187\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 174\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 348\n",
      "- Increase !! with 174\n",
      "New sample size = 348\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.20264142593748327\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.1539765833355944 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 20\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.005481785705192512\n",
      "κ = 0.0002310224273646439\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 348\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 265\n",
      "- Decrease !! with 83\n",
      "New sample size = 265\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.13744405303173277\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.04664963148545887 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 20\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00013552364755669853\n",
      "κ = 0.00010206941632184347\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.13744405303173277\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.04664963148545887 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 20\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00013552364755669853\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 265\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 530\n",
      "- Increase !! with 265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 530\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.16144483266504756\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.05313716507675869 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 20\n",
      "\n",
      "Iteration 17 -> 18\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0002047412203730502\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 530\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1060\n",
      "- Increase !! with 530\n",
      "New sample size = 1060\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.16168977513557445\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.045898250852217 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 20\n",
      "\n",
      "Iteration 18 -> 19\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00012108383790727302\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1060\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2120\n",
      "- Increase !! with 1060\n",
      "New sample size = 2120\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.15085109215137205\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0287105154057031 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 19  and  max = 20\n",
      "\n",
      "Iteration 19 -> 20\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.008750606427904e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2120\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3884\n",
      "- Increase !! with 1764\n",
      "New sample size = 3884\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 20\n",
      "0.1461384735492102\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.025035397014427082 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 20  and  max = 20\n",
      "nmaxReached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"here's a state\"\"here's an Accumulator\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "\n",
    "                        # Test 1 : BHHH / True Var\n",
    "\n",
    "# --- Hessian Approx\n",
    "Hessian = Geraldine.BHHHScores{TYPE}\n",
    "# Smoothing\n",
    "smoothing = Geraldine.NaiveSmoothing()\n",
    "# --- Sampling\n",
    "varStrategy = Geraldine.TrueVar{Float64}(smoothing)\n",
    "\n",
    "samplingStrategy = Geraldine.DynamicSampling{Geraldine.IndComRN}(Sofia.Nobs(mo), varStrategy, \n",
    "                                                                    NMin = NMin, N0=N0, \n",
    "                                                                    increment=increment, \n",
    "                                                                    subSampling=subSampling)\n",
    "\n",
    "# BTR\n",
    "accBHHH =  Accum_2nd_sHs(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = IterMax, TMax = 120.0, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian, sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorBHHHtv = btr(mo, copy(x0) , samplingStrategy, accumulator = accBHHH, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "marine-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Collecting results\n",
    " resultBHHHtv = Geraldine.structToDict(accumulatorBHHHtv)\n",
    "\n",
    "samplingBHHHtv = resultBHHHtv[:SamplingSizeAccumulator]\n",
    "fBHHHtv = resultBHHHtv[:ValueAccumulator]\n",
    "paramBHHHtv = resultBHHHtv[:ParamAccumulator];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "trying-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "y1",
         "line": {
          "color": "rgba(0, 154, 250, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "y1",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21
         ],
         "xaxis": "x1",
         "y": [
          100,
          75,
          56,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          58,
          116,
          87,
          174,
          348,
          265,
          265,
          530,
          1060,
          2120,
          3884
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        }
       ],
       "layout": {
        "annotations": [],
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 1.000)",
         "bordercolor": "rgba(0, 0, 0, 1.000)",
         "font": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tracegroupgap": 0,
         "x": 1,
         "y": 1
        },
        "margin": {
         "b": 20,
         "l": 0,
         "r": 0,
         "t": 20
        },
        "paper_bgcolor": "rgba(255, 255, 255, 1.000)",
        "plot_bgcolor": "rgba(255, 255, 255, 1.000)",
        "showlegend": true,
        "width": 600,
        "xaxis": {
         "anchor": "y1",
         "domain": [
          0.0658209390492855,
          0.9934383202099738
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          0.4,
          21.6
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "5",
          "10",
          "15",
          "20"
         ],
         "tickvals": [
          5,
          10,
          15,
          20
         ],
         "title": "",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        },
        "yaxis": {
         "anchor": "x1",
         "domain": [
          0.03762029746281716,
          0.9901574803149606
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          -62.959999999999994,
          3998.96
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "0",
          "1000",
          "2000",
          "3000"
         ],
         "tickvals": [
          0,
          1000,
          2000,
          3000
         ],
         "title": "",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        }
       }
      },
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "    <head>\n",
       "        <title>Plots.jl</title>\n",
       "        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
       "    </head>\n",
       "    <body>\n",
       "            <div id=\"f94a96cd-22a3-4e2a-b709-f9965e800fe6\" style=\"width:600px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('f94a96cd-22a3-4e2a-b709-f9965e800fe6');\n",
       "    Plotly.plot(PLOT, [\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            1,\n",
       "            2,\n",
       "            3,\n",
       "            4,\n",
       "            5,\n",
       "            6,\n",
       "            7,\n",
       "            8,\n",
       "            9,\n",
       "            10,\n",
       "            11,\n",
       "            12,\n",
       "            13,\n",
       "            14,\n",
       "            15,\n",
       "            16,\n",
       "            17,\n",
       "            18,\n",
       "            19,\n",
       "            20,\n",
       "            21\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"y1\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"y1\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(0, 154, 250, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            100.0,\n",
       "            75.0,\n",
       "            56.0,\n",
       "            52.0,\n",
       "            53.0,\n",
       "            54.0,\n",
       "            55.0,\n",
       "            56.0,\n",
       "            57.0,\n",
       "            58.0,\n",
       "            58.0,\n",
       "            116.0,\n",
       "            87.0,\n",
       "            174.0,\n",
       "            348.0,\n",
       "            265.0,\n",
       "            265.0,\n",
       "            530.0,\n",
       "            1060.0,\n",
       "            2120.0,\n",
       "            3884.0\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    }\n",
       "]\n",
       ", {\n",
       "    \"showlegend\": true,\n",
       "    \"xaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            5.0,\n",
       "            10.0,\n",
       "            15.0,\n",
       "            20.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            0.4,\n",
       "            21.6\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.0658209390492855,\n",
       "            0.9934383202099738\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"5\",\n",
       "            \"10\",\n",
       "            \"15\",\n",
       "            \"20\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"y1\"\n",
       "    },\n",
       "    \"paper_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"annotations\": [],\n",
       "    \"height\": 400,\n",
       "    \"margin\": {\n",
       "        \"l\": 0,\n",
       "        \"b\": 20,\n",
       "        \"r\": 0,\n",
       "        \"t\": 20\n",
       "    },\n",
       "    \"plot_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"yaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            0.0,\n",
       "            1000.0,\n",
       "            2000.0,\n",
       "            3000.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            -62.959999999999994,\n",
       "            3998.96\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.03762029746281716,\n",
       "            0.9901574803149606\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"0\",\n",
       "            \"1000\",\n",
       "            \"2000\",\n",
       "            \"3000\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"x1\"\n",
       "    },\n",
       "    \"legend\": {\n",
       "        \"tracegroupgap\": 0,\n",
       "        \"bordercolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "        \"font\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"y\": 1.0,\n",
       "        \"x\": 1.0\n",
       "    },\n",
       "    \"width\": 600\n",
       "}\n",
       ");\n",
       "    </script>\n",
       "\n",
       "    </body>\n",
       "</html>\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(samplingBHHHtv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aging-smell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "initializeSampling Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}! Ind / Com RN\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.200849827111758 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 1000\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.780352817704662\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 100\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 75\n",
      "- Decrease !! with 25\n",
      "New sample size = 75\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.5382546113879094\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1626473396647798 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 1000\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.424189966152688\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 75\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56\n",
      "- Decrease !! with 19\n",
      "New sample size = 56\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.4362581824387544\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1000518056083055 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 1000\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.4996716879396073\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 52\n",
      "- Decrease !! with 4\n",
      "New sample size = 52\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.2967941639394587\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.9792759921970717 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 1000\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6990416835777373\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 52\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 53\n",
      "- Increase !! with 1\n",
      "New sample size = 53\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.1164261972627565\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.8150469443243404 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 1000\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.4300161107926297\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 53\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 54\n",
      "- Increase !! with 1\n",
      "New sample size = 54\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.9004422872009733\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.6158854131001079 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 1000\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.12763854676770006\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 54\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 55\n",
      "- Increase !! with 1\n",
      "New sample size = 55\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.6769261168950451\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.40504025307730934 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 1000\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.032868024127021785\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 55\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56\n",
      "- Increase !! with 1\n",
      "New sample size = 56\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.4735950305477335\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.23119093675877997 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 1000\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0035829528740055515\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 57\n",
      "- Increase !! with 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 57\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.31569958449489954\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.11980751673995725 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 1000\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0006781207693845519\n",
      "κ = 0.00921662431437264\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 57\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 114\n",
      "- Increase !! with 57\n",
      "New sample size = 114\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.27137299847289936\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.2282185644566324 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 1000\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.03261249301359417\n",
      "κ = 0.0036246318549078725\n",
      "κ = 0.01637434006471517\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.27137299847289936\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.2282185644566324 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 1000\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.03261249301359417\n",
      "κ = 0.0036246318549078725\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 114\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 128\n",
      "- Increase !! with 14\n",
      "New sample size = 128\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.18725918924346632\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.12685378389054117 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 1000\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0029773182861037714\n",
      "κ = 0.0011865007198386052\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 128\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 256\n",
      "- Increase !! with 128\n",
      "New sample size = 256\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.18693839412280824\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.09904214855816543 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 1000\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.001965884583016857\n",
      "κ = 0.00024453923447015206\n",
      "κ = 0.0001775708898685289\n",
      "TCG on border\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 256\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 512\n",
      "- Increase !! with 256\n",
      "New sample size = 512\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.16792280774772556\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0943319654475963 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 1000\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0012989305488871155\n",
      "κ = 0.0003720228886220019\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 512\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1024\n",
      "- Increase !! with 512\n",
      "New sample size = 1024\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.14860581337941658\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.059428629948266386 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 1000\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0003816377447476204\n",
      "κ = 2.437452159306003e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1024\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2048\n",
      "- Increase !! with 1024\n",
      "New sample size = 2048\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.14294381840049164\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.054706731522797564 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 1000\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00023049383186974726\n",
      "κ = 1.2953523525048096e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2048\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Increase !! with 2048\n",
      "New sample size = 4096\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.14304953213017566\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.06312464381104156 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 1000\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00029839106805383065\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 4096\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3072\n",
      "- Decrease !! with 1024\n",
      "New sample size = 3072\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.13161651911330738\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.018075727108524304 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 1000\n",
      "\n",
      "Iteration 17 -> 18\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.648952209284382e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3072\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 4035\n",
      "- Increase !! with 963\n",
      "New sample size = 4035\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.1254208580742763\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.020684743083094193 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 1000\n",
      "\n",
      "Iteration 18 -> 19\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.3093253792534126e-5\n",
      "κ = 3.348024860171519e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 4035\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 8070\n",
      "- Increase !! with 4035\n",
      "New sample size = 8070\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.12474089287287347\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.05142729149238582 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 19  and  max = 1000\n",
      "\n",
      "Iteration 19 -> 20\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0001788730276213615\n",
      "κ = 4.4146154490945955e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 8070\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 16140\n",
      "- Increase !! with 8070\n",
      "New sample size = 16140\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 20\n",
      "0.12268372978767822\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.05358101843601507 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 20  and  max = 1000\n",
      "\n",
      "Iteration 20 -> 21\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00020703583797432\n",
      "κ = 3.3181347194822395e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 16140\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 12105\n",
      "- Decrease !! with 4035\n",
      "New sample size = 12105\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 21\n",
      "0.11698735021652261\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.04357310884556682 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 21  and  max = 1000\n",
      "\n",
      "Iteration 21 -> 22\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0001430837461422155\n",
      "κ = 4.939550331457053e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 12105\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 11510\n",
      "- Decrease !! with 595\n",
      "New sample size = 11510\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 22\n",
      "0.11130883316945774\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.033428716820286024 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 22  and  max = 1000\n",
      "\n",
      "Iteration 22 -> 23\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.300550488836953e-5\n",
      "κ = 9.476916787531629e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 11510\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 23020\n",
      "- Increase !! with 11510\n",
      "New sample size = 23020\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 23\n",
      "0.10879520825621895\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03167564304188371 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 23  and  max = 1000\n",
      "\n",
      "Iteration 23 -> 24\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.365004877492782e-5\n",
      "κ = 1.1411607295815835e-6\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 23020\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 30781\n",
      "- Increase !! with 7761\n",
      "New sample size = 30781\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 24\n",
      "0.10611405447705052\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.028643451725078532 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 24  and  max = 1000\n",
      "\n",
      "Iteration 24 -> 25\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.1128056283795383e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 30781\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 23085\n",
      "- Decrease !! with 7696\n",
      "New sample size = 23085\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 25\n",
      "0.10263896682330215\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009557120053655214 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 25  and  max = 1000\n",
      "\n",
      "Iteration 25 -> 26\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.261954807491154e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 23085\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 17313\n",
      "- Decrease !! with 5772\n",
      "New sample size = 17313\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 26\n",
      "0.10100246696722277\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.011417059154475452 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 26  and  max = 1000\n",
      "\n",
      "Iteration 26 -> 27\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.583297948288671e-6\n",
      "κ = 2.1001158935950824e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 27\n",
      "0.10100246696722277\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.011417059154475452 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 27  and  max = 1000\n",
      "\n",
      "Iteration 27 -> 28\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.583297948288671e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 17313\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 34626\n",
      "- Increase !! with 17313\n",
      "New sample size = 34626\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 28\n",
      "0.09839451266402181\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01124236160632986 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 28  and  max = 1000\n",
      "\n",
      "Iteration 28 -> 29\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.683621454549738e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 34626\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 47626\n",
      "- Increase !! with 13000\n",
      "New sample size = 47626\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 29\n",
      "0.09790857758110752\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009730549609230867 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 29  and  max = 1000\n",
      "\n",
      "Iteration 29 -> 30\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2906997318836006e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 47626\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 41720\n",
      "- Decrease !! with 5906\n",
      "New sample size = 41720\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 30\n",
      "0.09715664428967583\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.008658665773426432 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 30  and  max = 1000\n",
      "\n",
      "Iteration 30 -> 31\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.414541466184662e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 41720\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 31290\n",
      "- Decrease !! with 10430\n",
      "New sample size = 31290\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 31\n",
      "0.09591731060779322\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009150482218018284 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 31  and  max = 1000\n",
      "\n",
      "Iteration 31 -> 32\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.1834938942521222e-6\n",
      "κ = 2.6419693815727195e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Iteration 32\n",
      "0.09591731060779322\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009150482218018284 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 32  and  max = 1000\n",
      "\n",
      "Iteration 32 -> 33\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.1834938942521222e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 31290\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 46930\n",
      "- Increase !! with 15640\n",
      "New sample size = 46930\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 33\n",
      "0.09476533369284561\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.008996639535789617 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 33  and  max = 1000\n",
      "\n",
      "Iteration 33 -> 34\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.1898289182412474e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 46930\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 50765\n",
      "- Increase !! with 3835\n",
      "New sample size = 50765\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 34\n",
      "0.09346060173336514\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01153959574441904 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 34  and  max = 1000\n",
      "\n",
      "Iteration 34 -> 35\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.8950150445725315e-6\n",
      "κ = 4.965854263215971e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 35\n",
      "0.09346060173336514\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01153959574441904 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 35  and  max = 1000\n",
      "\n",
      "Iteration 35 -> 36\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.8950150445725315e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 50765\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 62852\n",
      "- Increase !! with 12087\n",
      "New sample size = 62852\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 36\n",
      "0.09239983830930219\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0072804251158115185 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 36  and  max = 1000\n",
      "\n",
      "Iteration 36 -> 37\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.488204381294266e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 62852\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 47139\n",
      "- Decrease !! with 15713\n",
      "New sample size = 47139\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 37\n",
      "0.0916748997069207\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007281819129675788 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 37  and  max = 1000\n",
      "\n",
      "Iteration 37 -> 38\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.2180340898586772e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 47139\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 35354\n",
      "- Decrease !! with 11785\n",
      "New sample size = 35354\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 38\n",
      "0.09102618726567321\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009184260243610375 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 38  and  max = 1000\n",
      "\n",
      "Iteration 38 -> 39\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.7937166909007595e-6\n",
      "κ = 1.0633395442103317e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 35354\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 70708\n",
      "- Increase !! with 35354\n",
      "New sample size = 70708\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 39\n",
      "0.08821164986296551\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.022789251539272817 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 39  and  max = 1000\n",
      "\n",
      "Iteration 39 -> 40\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.331592691537061e-5\n",
      "κ = 1.6722209776907735e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 70708\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 141416\n",
      "- Increase !! with 70708\n",
      "New sample size = 141416\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 40\n",
      "0.08671705161063685\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.023909086394384896 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 40  and  max = 1000\n",
      "\n",
      "Iteration 40 -> 41\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.739770603422738e-5\n",
      "κ = 2.1616031755041187e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 141416\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 106062\n",
      "- Decrease !! with 35354\n",
      "New sample size = 106062\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 41\n",
      "0.08435048041313295\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.02151613933270202 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 41  and  max = 1000\n",
      "\n",
      "Iteration 41 -> 42\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.1035014237152582e-5\n",
      "κ = 1.3729446505501164e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 106062\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 155456\n",
      "- Increase !! with 49394\n",
      "New sample size = 155456\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 42\n",
      "0.08298885369406303\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.021141970494553512 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 42  and  max = 1000\n",
      "\n",
      "Iteration 42 -> 43\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9939246947034277e-5\n",
      "κ = 6.609485225029414e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 155456\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 310912\n",
      "- Increase !! with 155456\n",
      "New sample size = 310912\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 43\n",
      "0.08275011314486155\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.02057762130282282 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 43  and  max = 1000\n",
      "\n",
      "Iteration 43 -> 44\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9035515553106672e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 310912\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 233184\n",
      "- Decrease !! with 77728\n",
      "New sample size = 233184\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 44\n",
      "0.08021146963123127\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005331715563058895 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 44  and  max = 1000\n",
      "\n",
      "Iteration 44 -> 45\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.412699316268901e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 233184\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 174888\n",
      "- Decrease !! with 58296\n",
      "New sample size = 174888\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 45\n",
      "0.07904278610593961\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006031550667498773 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 45  and  max = 1000\n",
      "\n",
      "Iteration 45 -> 46\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.4971245136055383e-7\n",
      "κ = 6.311900450685611e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 46\n",
      "0.07904278610593961\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006031550667498773 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 46  and  max = 1000\n",
      "\n",
      "Iteration 46 -> 47\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.4971245136055383e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 174888\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 131492\n",
      "- Decrease !! with 43396\n",
      "New sample size = 131492\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 47\n",
      "0.07851472648466963\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00640215224594064 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 47  and  max = 1000\n",
      "\n",
      "Iteration 47 -> 48\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.671416712336225e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 131492\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 166112\n",
      "- Increase !! with 34620\n",
      "New sample size = 166112\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 48\n",
      "0.07789354879473542\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00587553041744327 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 48  and  max = 1000\n",
      "\n",
      "Iteration 48 -> 49\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.6526388484114705e-7\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 166112\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 149690\n",
      "- Decrease !! with 16422\n",
      "New sample size = 149690\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 49\n",
      "0.07715295947071629\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00538132175436768 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 49  and  max = 1000\n",
      "\n",
      "Iteration 49 -> 50\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.6315247491487007e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 149690\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 112267\n",
      "- Decrease !! with 37423\n",
      "New sample size = 112267\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 50\n",
      "0.07667864268440927\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006373575077260035 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 50  and  max = 1000\n",
      "\n",
      "Iteration 50 -> 51\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.135937046470745e-7\n",
      "κ = 6.145443739790843e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 112267\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 224534\n",
      "- Increase !! with 112267\n",
      "New sample size = 224534\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 51\n",
      "0.0768332739111094\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01412028924731569 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 51  and  max = 1000\n",
      "\n",
      "Iteration 51 -> 52\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.247094441208788e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 224534\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 168400\n",
      "- Decrease !! with 56134\n",
      "New sample size = 168400\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 52\n",
      "0.0752739418285362\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004984478797066642 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 52  and  max = 1000\n",
      "\n",
      "Iteration 52 -> 53\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.1852395998504541e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 168400\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 133677\n",
      "- Decrease !! with 34723\n",
      "New sample size = 133677\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 53\n",
      "0.07484278341772403\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00486741229781406 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 53  and  max = 1000\n",
      "\n",
      "Iteration 53 -> 54\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.0740128960171212e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 133677\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 124449\n",
      "- Decrease !! with 9228\n",
      "New sample size = 124449\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 54\n",
      "0.07433327386283972\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006425055837472952 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 54  and  max = 1000\n",
      "\n",
      "Iteration 54 -> 55\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.870426195498881e-7\n",
      "κ = 3.6498291089008105e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 124449\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 248898\n",
      "- Increase !! with 124449\n",
      "New sample size = 248898\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 55\n",
      "0.07456287516150378\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01422498259276361 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 55  and  max = 1000\n",
      "\n",
      "Iteration 55 -> 56\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.1032145092911735e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 248898\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 186673\n",
      "- Decrease !! with 62225\n",
      "New sample size = 186673\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 56\n",
      "0.07344886137464672\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004478426891528882 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 56  and  max = 1000\n",
      "\n",
      "Iteration 56 -> 57\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.5521416979478505e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 186673\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 146064\n",
      "- Decrease !! with 40609\n",
      "New sample size = 146064\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 57\n",
      "0.07336634694086572\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005029226831886494 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 57  and  max = 1000\n",
      "\n",
      "Iteration 57 -> 58\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.671206204677822e-7\n",
      "κ = 2.7333590787343945e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 146064\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 292128\n",
      "- Increase !! with 146064\n",
      "New sample size = 292128\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 58\n",
      "0.07254386018920005\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.013971298199586332 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 58  and  max = 1000\n",
      "\n",
      "Iteration 58 -> 59\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.221607784057943e-6\n",
      "κ = 4.639158834069817e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 292128\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 584256\n",
      "- Increase !! with 292128\n",
      "New sample size = 584256\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 59\n",
      "0.07269123942835516\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01475932046865457 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 59  and  max = 1000\n",
      "\n",
      "Iteration 59 -> 60\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.954461810312426e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 584256\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 438192\n",
      "- Decrease !! with 146064\n",
      "New sample size = 438192\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 60\n",
      "0.07118003022494011\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0039299142907901026 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 60  and  max = 1000\n",
      "\n",
      "Iteration 60 -> 61\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.95151474806028e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 438192\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 328644\n",
      "- Decrease !! with 109548\n",
      "New sample size = 328644\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 61\n",
      "0.07069623227189455\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004631924915445142 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 61  and  max = 1000\n",
      "\n",
      "Iteration 61 -> 62\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.364487263259046e-7\n",
      "κ = 2.1814132645403334e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 328644\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 575215\n",
      "- Increase !! with 246571\n",
      "New sample size = 575215\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 62\n",
      "0.07052598231729613\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.011776199010931191 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 62  and  max = 1000\n",
      "\n",
      "Iteration 62 -> 63\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.891537342660316e-6\n",
      "κ = 7.017806214870526e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 575215\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1000000\n",
      "- Increase !! with 424785\n",
      "New sample size = 1000000\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 63\n",
      "0.06991301707265964\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.012891499071289343 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 63  and  max = 1000\n",
      "\n",
      "Iteration 63 -> 64\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.841133648087943e-6\n",
      "κ = 1.03312618677053e-7\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1000000\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1000000\n",
      "New sample size = 1000000\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 64\n",
      "0.06966017912706712\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.013496925072557672 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 64  and  max = 1000\n",
      "\n",
      "Iteration 64 -> 65\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.9121333817073286e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1000000\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 750000\n",
      "- Decrease !! with 250000\n",
      "New sample size = 750000\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 65\n",
      "0.06826694846419772\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0034846499532644295 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 65  and  max = 1000\n",
      "\n",
      "Iteration 65 -> 66\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.8772491458347063e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 750000\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 562500\n",
      "- Decrease !! with 187500\n",
      "New sample size = 562500\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 66\n",
      "0.06766444918844973\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004093974874965131 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 66  and  max = 1000\n",
      "\n",
      "Iteration 66 -> 67\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.370517208942016e-7\n",
      "κ = 2.017835596959272e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 562500\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1000000\n",
      "- Increase !! with 437500\n",
      "New sample size = 1000000\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 67\n",
      "0.06759129646188994\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.010491137547345899 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 67  and  max = 1000\n",
      "\n",
      "Iteration 67 -> 68\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.846897745988088e-6\n",
      "κ = 3.3175075665392904e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1000000\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 750000\n",
      "- Decrease !! with 250000\n",
      "New sample size = 750000\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 68\n",
      "0.06695183328552728\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.010382550199378358 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 68  and  max = 1000\n",
      "\n",
      "Iteration 68 -> 69\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.2983147178848396e-6\n",
      "κ = 6.63698238519849e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 69\n",
      "0.06695183328552728\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.010382550199378358 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 69  and  max = 1000\n",
      "\n",
      "Iteration 69 -> 70\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.2983147178848396e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 750000\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 562500\n",
      "- Decrease !! with 187500\n",
      "New sample size = 562500\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 70\n",
      "0.06636459201467933\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004720973162335937 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 70  and  max = 1000\n",
      "\n",
      "Iteration 70 -> 71\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.813222098899862e-7\n",
      "κ = 2.2809564129291758e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 562500\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1000000\n",
      "- Increase !! with 437500\n",
      "New sample size = 1000000\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 71\n",
      "0.06614383871393385\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.008271381699319062 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 71  and  max = 1000\n",
      "\n",
      "Iteration 71 -> 72\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.3327293721125495e-6\n",
      "κ = 2.7714349586147085e-8\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1000000\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1000000\n",
      "New sample size = 1000000\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 72\n",
      "0.06585937568410495\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.008157153067458135 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 72  and  max = 1000\n",
      "\n",
      "Iteration 72 -> 73\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.068602595871182e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1000000\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 750000\n",
      "- Decrease !! with 250000\n",
      "New sample size = 750000\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 73\n",
      "0.0652675369970407\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002836683168625889 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 73  and  max = 1000\n",
      "\n",
      "Iteration 73 -> 74\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.8990459719013655e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 750000\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 562500\n",
      "- Decrease !! with 187500\n",
      "New sample size = 562500\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 74\n",
      "0.06503761891335921\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0028696502104103854 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 74  and  max = 1000\n",
      "\n",
      "Iteration 74 -> 75\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.0389937266441025e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 562500\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- True Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 421875\n",
      "- Decrease !! with 140625\n",
      "New sample size = 421875\n",
      "compute gradient for Classic\n",
      "-------  updatePreviousValues  True Var --------\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 75\n",
      "0.06470823156718929\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0032704863387518603 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 75  and  max = 1000\n",
      "tmaxReached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"here's a state\"\"here's an Accumulator\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "\n",
    "                        # Test 1 : BHHH / True Var -> Cumulative Decrease\n",
    "\n",
    "# --- Hessian Approx\n",
    "Hessian = Geraldine.BHHHScores{TYPE}\n",
    "# Smoothing\n",
    "smoothing = Geraldine.NaiveSmoothing()\n",
    "# --- Sampling\n",
    "varStrategy = Geraldine.TrueVar{Float64}(smoothing)\n",
    "\n",
    "samplingStrategy = Geraldine.DynamicSampling{Geraldine.IndComRN}(Sofia.Nobs(mo), varStrategy, \n",
    "                                                                    NMin = NMin, N0=N0, \n",
    "                                                                    increment=increment, \n",
    "                                                                    subSampling=subSampling)\n",
    "\n",
    "# BTR\n",
    "accBHHH =  Accum_2nd_sHs(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = 1000, TMax = 120.0, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian, sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorBHHHtv = btr(mo, copy(x0) , samplingStrategy, accumulator = accBHHH, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hazardous-footage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 (selected SAM) : \n",
      "------ Classic btr ---------- : \n",
      " --- sampling : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Classic\n",
      "initializeSampling Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}! Ind / Com RN\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.200849827111758 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 1000\n",
      "\n",
      "Iteration 0 -> 1\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.702836444761651\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 100\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 75\n",
      "- Decrease !! with 25\n",
      "New sample size = 75\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.5384538370126153\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.1580564881553037 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 1000\n",
      "\n",
      "Iteration 1 -> 2\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.872458766048467\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 75\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56\n",
      "- Decrease !! with 19\n",
      "New sample size = 56\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "1.4411124264278992\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 1.0702260591381887 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 1000\n",
      "\n",
      "Iteration 2 -> 3\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.5554267268947846\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 52\n",
      "- Decrease !! with 4\n",
      "New sample size = 52\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "1.3118666278468711\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.939603766099612 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 1000\n",
      "\n",
      "Iteration 3 -> 4\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.8454032978901936\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 52\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 53\n",
      "- Increase !! with 1\n",
      "New sample size = 53\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "1.141818644121222\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.7835887540132117 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 1000\n",
      "\n",
      "Iteration 4 -> 5\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.32898184824521937\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 53\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 54\n",
      "- Increase !! with 1\n",
      "New sample size = 54\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.9368672556828421\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.5917876953316455 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 1000\n",
      "\n",
      "Iteration 5 -> 6\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.10871871031911032\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 54\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 55\n",
      "- Increase !! with 1\n",
      "New sample size = 55\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.719067414643388\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.39240541464937767 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 1000\n",
      "\n",
      "Iteration 6 -> 7\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.023778777896518048\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 55\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56\n",
      "- Increase !! with 1\n",
      "New sample size = 56\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.5094360163719704\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.22342065732112407 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 1000\n",
      "\n",
      "Iteration 7 -> 8\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.002800151132838474\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Increase !! with 1\n",
      "New sample size = 57\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.34095762992279177\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.11466074052504938 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 1000\n",
      "\n",
      "Iteration 8 -> 9\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00046747660906511885\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 57\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 58\n",
      "- Increase !! with 1\n",
      "New sample size = 58\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.22778864038234498\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.07823517025008234 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 1000\n",
      "\n",
      "Iteration 9 -> 10\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0003043426313755377\n",
      "κ = 0.0002851517972704169\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.22778864038234498\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.07823517025008234 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 1000\n",
      "\n",
      "Iteration 10 -> 11\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0003043426313755377\n",
      "κ = 0.0002851517972704169\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.22778864038234498\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.07823517025008234 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 1000\n",
      "\n",
      "Iteration 11 -> 12\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0003043426313755377\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 58\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 116\n",
      "- Increase !! with 58\n",
      "New sample size = 116\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.2501027825722762\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.14650806877570227 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 1000\n",
      "\n",
      "Iteration 12 -> 13\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.003584346322889668\n",
      "κ = 0.0001670447865883174\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 116\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 232\n",
      "- Increase !! with 116\n",
      "New sample size = 232\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.23922958729685873\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.13791912631641617 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 1000\n",
      "\n",
      "Iteration 13 -> 14\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.005969174059215659\n",
      "κ = 0.0018935147365691269\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 232\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 174\n",
      "- Decrease !! with 58\n",
      "New sample size = 174\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.1895424855756893\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.08260009132967021 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 1000\n",
      "\n",
      "Iteration 14 -> 15\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0003850909354470155\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 174\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 130\n",
      "- Decrease !! with 44\n",
      "New sample size = 130\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.17327374326318343\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0691868700901931 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 1000\n",
      "\n",
      "Iteration 15 -> 16\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0006882415337320629\n",
      "κ = 0.00019984545395100407\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 130\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 260\n",
      "- Increase !! with 130\n",
      "New sample size = 260\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.16697914938852948\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.08769628616609965 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 1000\n",
      "\n",
      "Iteration 16 -> 17\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0009658518534948345\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 260\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 195\n",
      "- Decrease !! with 65\n",
      "New sample size = 195\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.14555250721775456\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.041068038516721105 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 1000\n",
      "\n",
      "Iteration 17 -> 18\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.08827997956107e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 195\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 146\n",
      "- Decrease !! with 49\n",
      "New sample size = 146\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.14844548790452303\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0438615279034526 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 1000\n",
      "\n",
      "Iteration 18 -> 19\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00011484163834980038\n",
      "κ = 0.0002435022325015727\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.14844548790452303\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0438615279034526 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 19  and  max = 1000\n",
      "\n",
      "Iteration 19 -> 20\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00011484163834980038\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sample size = 146\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 214\n",
      "- Increase !! with 68\n",
      "New sample size = 214\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 20\n",
      "0.15148429574809463\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.04725653863380047 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 20  and  max = 1000\n",
      "\n",
      "Iteration 20 -> 21\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00017770585853097126\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 214\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 220\n",
      "- Increase !! with 6\n",
      "New sample size = 220\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 21\n",
      "0.1445123343739892\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.02525341230799217 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 21  and  max = 1000\n",
      "\n",
      "Iteration 21 -> 22\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.280662601929998e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 220\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 165\n",
      "- Decrease !! with 55\n",
      "New sample size = 165\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 22\n",
      "0.14429599153818715\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03765986432935364 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 22  and  max = 1000\n",
      "\n",
      "Iteration 22 -> 23\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.507524398673783e-5\n",
      "κ = 0.00010797895569325965\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 23\n",
      "0.14429599153818715\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03765986432935364 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 23  and  max = 1000\n",
      "\n",
      "Iteration 23 -> 24\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.507524398673783e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 165\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 232\n",
      "- Increase !! with 67\n",
      "New sample size = 232\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 24\n",
      "0.1390523467899224\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03405021442171302 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 24  and  max = 1000\n",
      "\n",
      "Iteration 24 -> 25\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.341583844742679e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 232\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 174\n",
      "- Decrease !! with 58\n",
      "New sample size = 174\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 25\n",
      "0.12771067061201358\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03534523025572842 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 25  and  max = 1000\n",
      "\n",
      "Iteration 25 -> 26\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.267656365816525e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 174\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 130\n",
      "- Decrease !! with 44\n",
      "New sample size = 130\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 26\n",
      "0.13179483511775686\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.02390533960731819 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 26  and  max = 1000\n",
      "\n",
      "Iteration 26 -> 27\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.764043945403408e-5\n",
      "κ = 1.965769286418963e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 130\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 260\n",
      "- Increase !! with 130\n",
      "New sample size = 260\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 27\n",
      "0.1263887499907989\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.04382431243650443 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 27  and  max = 1000\n",
      "\n",
      "Iteration 27 -> 28\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00011200674865811258\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 260\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 200\n",
      "- Decrease !! with 60\n",
      "New sample size = 200\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 28\n",
      "0.13013759304099115\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03196139825748387 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 28  and  max = 1000\n",
      "\n",
      "Iteration 28 -> 29\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0001443922865808075\n",
      "κ = 1.4498256586871505e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 200\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 400\n",
      "- Increase !! with 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 400\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 29\n",
      "0.13737376926375996\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.04414141307690749 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 29  and  max = 1000\n",
      "\n",
      "Iteration 29 -> 30\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.512839679905323e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 400\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 323\n",
      "- Decrease !! with 77\n",
      "New sample size = 323\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 30\n",
      "0.1296364338924181\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.027015561690408727 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 30  and  max = 1000\n",
      "\n",
      "Iteration 30 -> 31\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.2543098459273013e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 323\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 646\n",
      "- Increase !! with 323\n",
      "New sample size = 646\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 31\n",
      "0.12948020445913005\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.039219879346513956 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 31  and  max = 1000\n",
      "\n",
      "Iteration 31 -> 32\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.0001544745551511251\n",
      "κ = 1.3885573797144334e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 646\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1034\n",
      "- Increase !! with 388\n",
      "New sample size = 1034\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 32\n",
      "0.1266718189180097\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.036765008366055646 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 32  and  max = 1000\n",
      "\n",
      "Iteration 32 -> 33\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.757336897562108e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1034\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 775\n",
      "- Decrease !! with 259\n",
      "New sample size = 775\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 33\n",
      "0.12279456413739794\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.018853509336656568 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 33  and  max = 1000\n",
      "\n",
      "Iteration 33 -> 34\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.068281588261427e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 775\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 581\n",
      "- Decrease !! with 194\n",
      "New sample size = 581\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 34\n",
      "0.11114317502463585\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01567061180517964 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 34  and  max = 1000\n",
      "\n",
      "Iteration 34 -> 35\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.793986117758719e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 581\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 435\n",
      "- Decrease !! with 146\n",
      "New sample size = 435\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 35\n",
      "0.11099987504207814\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01841132398876942 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 35  and  max = 1000\n",
      "\n",
      "Iteration 35 -> 36\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.082468448971477e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 435\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 582\n",
      "- Increase !! with 147\n",
      "New sample size = 582\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 36\n",
      "0.11820177979755347\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.02433343812274024 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 36  and  max = 1000\n",
      "\n",
      "Iteration 36 -> 37\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.548942825332987e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 582\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 745\n",
      "- Increase !! with 163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 745\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 37\n",
      "0.11642213687234601\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.015102141183037262 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 37  and  max = 1000\n",
      "\n",
      "Iteration 37 -> 38\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.94428590057232e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 745\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 558\n",
      "- Decrease !! with 187\n",
      "New sample size = 558\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 38\n",
      "0.11020373463705982\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.013361957335652624 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 38  and  max = 1000\n",
      "\n",
      "Iteration 38 -> 39\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.455204081119116e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 558\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 487\n",
      "- Decrease !! with 71\n",
      "New sample size = 487\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 39\n",
      "0.10992866368092656\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.014574538680316091 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 39  and  max = 1000\n",
      "\n",
      "Iteration 39 -> 40\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.926227525285247e-6\n",
      "κ = 1.5763610336419457e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 487\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 974\n",
      "- Increase !! with 487\n",
      "New sample size = 974\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 40\n",
      "0.11724543859391276\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.049166214822389726 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 40  and  max = 1000\n",
      "\n",
      "Iteration 40 -> 41\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 0.00014673274227067941\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 974\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 730\n",
      "- Decrease !! with 244\n",
      "New sample size = 730\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 41\n",
      "0.10626321396721614\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.02157886254620805 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 41  and  max = 1000\n",
      "\n",
      "Iteration 41 -> 42\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.4145154148911057e-5\n",
      "κ = 1.3737316438267425e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 730\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1460\n",
      "- Increase !! with 730\n",
      "New sample size = 1460\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 42\n",
      "0.1081408797588945\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.03501374112582379 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 42  and  max = 1000\n",
      "\n",
      "Iteration 42 -> 43\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.292510660698517e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1460\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1095\n",
      "- Decrease !! with 365\n",
      "New sample size = 1095\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 43\n",
      "0.10639449611169216\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.015607050312457585 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 43  and  max = 1000\n",
      "\n",
      "Iteration 43 -> 44\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.963951326101247e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1095\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1626\n",
      "- Increase !! with 531\n",
      "New sample size = 1626\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 44\n",
      "0.1044574294478979\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.017005576734103963 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 44  and  max = 1000\n",
      "\n",
      "Iteration 44 -> 45\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.1906741974771512e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1626\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1566\n",
      "- Decrease !! with 60\n",
      "New sample size = 1566\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 45\n",
      "0.10330112693478515\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01199494918373381 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 45  and  max = 1000\n",
      "\n",
      "Iteration 45 -> 46\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.701468105680156e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1566\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2145\n",
      "- Increase !! with 579\n",
      "New sample size = 2145\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 46\n",
      "0.10336309371087889\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.015106370742334774 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 46  and  max = 1000\n",
      "\n",
      "Iteration 46 -> 47\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.736339567883292e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2145\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1608\n",
      "- Decrease !! with 537\n",
      "New sample size = 1608\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 47\n",
      "0.10494789191648042\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.012707484546515036 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 47  and  max = 1000\n",
      "\n",
      "Iteration 47 -> 48\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.5355314190717e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1608\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1206\n",
      "- Decrease !! with 402\n",
      "New sample size = 1206\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 48\n",
      "0.1086276512748982\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.011879628961856617 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 48  and  max = 1000\n",
      "\n",
      "Iteration 48 -> 49\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.502793934864386e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1206\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1303\n",
      "- Increase !! with 97\n",
      "New sample size = 1303\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 49\n",
      "0.1059710270985324\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.010709233940179773 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 49  and  max = 1000\n",
      "\n",
      "Iteration 49 -> 50\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.9503028614364054e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1303\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2062\n",
      "- Increase !! with 759\n",
      "New sample size = 2062\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 50\n",
      "0.09927783730034613\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.014979147769741996 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 50  and  max = 1000\n",
      "\n",
      "Iteration 50 -> 51\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.080486203485925e-5\n",
      "κ = 2.1946235728634083e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2062\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 4124\n",
      "- Increase !! with 2062\n",
      "New sample size = 4124\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 51\n",
      "0.09334099467784578\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.016215710934856385 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 51  and  max = 1000\n",
      "\n",
      "Iteration 51 -> 52\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0509762206017034e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 4124\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3093\n",
      "- Decrease !! with 1031\n",
      "New sample size = 3093\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 52\n",
      "0.09057950259931191\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009280574683964435 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 52  and  max = 1000\n",
      "\n",
      "Iteration 52 -> 53\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.0310195773122954e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3093\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2319\n",
      "- Decrease !! with 774\n",
      "New sample size = 2319\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 53\n",
      "0.09183573865602414\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009690862230597824 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 53  and  max = 1000\n",
      "\n",
      "Iteration 53 -> 54\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.279817191542624e-6\n",
      "κ = 1.1705449449629067e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "step refused region reduced (BAD accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 54\n",
      "0.09183573865602414\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009690862230597824 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 54  and  max = 1000\n",
      "\n",
      "Iteration 54 -> 55\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.279817191542624e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2319\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1739\n",
      "- Decrease !! with 580\n",
      "New sample size = 1739\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 55\n",
      "0.09308861435352603\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009367847084057598 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 55  and  max = 1000\n",
      "\n",
      "Iteration 55 -> 56\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.6629264949056147e-6\n",
      "κ = 1.0584141364173394e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1739\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3478\n",
      "- Increase !! with 1739\n",
      "New sample size = 3478\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 56\n",
      "0.09231721018207502\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.025228418273626645 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 56  and  max = 1000\n",
      "\n",
      "Iteration 56 -> 57\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.618099353423264e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3478\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2608\n",
      "- Decrease !! with 870\n",
      "New sample size = 2608\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 57\n",
      "0.09238018355025954\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.013408118243967461 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 57  and  max = 1000\n",
      "\n",
      "Iteration 57 -> 58\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0145771174271558e-5\n",
      "κ = 8.852418423202832e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2608\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3435\n",
      "- Increase !! with 827\n",
      "New sample size = 3435\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 58\n",
      "0.08992583420865576\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01359332375278625 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 58  and  max = 1000\n",
      "\n",
      "Iteration 58 -> 59\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.346309323876628e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3435\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2677\n",
      "- Decrease !! with 758\n",
      "New sample size = 2677\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 59\n",
      "0.0884076777917747\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.012511990446343295 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 59  and  max = 1000\n",
      "\n",
      "Iteration 59 -> 60\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.588000658137259e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2677\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2756\n",
      "- Increase !! with 79\n",
      "New sample size = 2756\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 60\n",
      "0.08771844773165413\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00795880682923429 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 60  and  max = 1000\n",
      "\n",
      "Iteration 60 -> 61\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.383204742983743e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2756\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2067\n",
      "- Decrease !! with 689\n",
      "New sample size = 2067\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 61\n",
      "0.08526322722089592\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009842412423751442 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 61  and  max = 1000\n",
      "\n",
      "Iteration 61 -> 62\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.1521915917075103e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2067\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2783\n",
      "- Increase !! with 716\n",
      "New sample size = 2783\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 62\n",
      "0.08341943898608219\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009626761654321714 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 62  and  max = 1000\n",
      "\n",
      "Iteration 62 -> 63\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.1293233045427147e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2783\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2087\n",
      "- Decrease !! with 696\n",
      "New sample size = 2087\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 63\n",
      "0.08421688079719904\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006385399869608085 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 63  and  max = 1000\n",
      "\n",
      "Iteration 63 -> 64\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.452357620723357e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2087\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 1565\n",
      "- Decrease !! with 522\n",
      "New sample size = 1565\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 64\n",
      "0.08651239937987942\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.009573361634089167 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 64  and  max = 1000\n",
      "\n",
      "Iteration 64 -> 65\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.8959024134374797e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 1565\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2468\n",
      "- Increase !! with 903\n",
      "New sample size = 2468\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 65\n",
      "0.08164951879615039\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01163209724941052 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 65  and  max = 1000\n",
      "\n",
      "Iteration 65 -> 66\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.313963894683183e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2468\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2274\n",
      "- Decrease !! with 194\n",
      "New sample size = 2274\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 66\n",
      "0.08067692805388077\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006784790522116656 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 66  and  max = 1000\n",
      "\n",
      "Iteration 66 -> 67\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.5934828300226e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2274\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2157\n",
      "- Decrease !! with 117\n",
      "New sample size = 2157\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 67\n",
      "0.07926945231580886\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0064048560875211375 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 67  and  max = 1000\n",
      "\n",
      "Iteration 67 -> 68\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.015155321603253e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2157\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2680\n",
      "- Increase !! with 523\n",
      "New sample size = 2680\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 68\n",
      "0.07887750478705631\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.010559722947002147 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 68  and  max = 1000\n",
      "\n",
      "Iteration 68 -> 69\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.8049646441235455e-6\n",
      "κ = 4.795780653328505e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2680\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 5360\n",
      "- Increase !! with 2680\n",
      "New sample size = 5360\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 69\n",
      "0.08188387110360397\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.018949459705901502 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 69  and  max = 1000\n",
      "\n",
      "Iteration 69 -> 70\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6284414757095712e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 5360\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 4020\n",
      "- Decrease !! with 1340\n",
      "New sample size = 4020\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 70\n",
      "0.08252211954860866\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00865395033571999 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 70  and  max = 1000\n",
      "\n",
      "Iteration 70 -> 71\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.076647701004121e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 4020\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 4109\n",
      "- Increase !! with 89\n",
      "New sample size = 4109\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 71\n",
      "0.08175630279117813\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00669469556339513 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 71  and  max = 1000\n",
      "\n",
      "Iteration 71 -> 72\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.793061035044e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 4109\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3352\n",
      "- Decrease !! with 757\n",
      "New sample size = 3352\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 72\n",
      "0.08324310666210687\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0073039214915634355 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 72  and  max = 1000\n",
      "\n",
      "Iteration 72 -> 73\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.3306838777626129e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3352\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3530\n",
      "- Increase !! with 178\n",
      "New sample size = 3530\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 73\n",
      "0.08206628020890913\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006256968667078389 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 73  and  max = 1000\n",
      "\n",
      "Iteration 73 -> 74\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.715861290776027e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3530\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2647\n",
      "- Decrease !! with 883\n",
      "New sample size = 2647\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 74\n",
      "0.08290705985446208\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.008312762692595826 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 74  and  max = 1000\n",
      "\n",
      "Iteration 74 -> 75\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.0136769791393584e-6\n",
      "κ = 2.3148271972036745e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2647\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 5294\n",
      "- Increase !! with 2647\n",
      "New sample size = 5294\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 75\n",
      "0.08126957819316374\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.016924561361799404 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 75  and  max = 1000\n",
      "\n",
      "Iteration 75 -> 76\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.683293961293833e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 5294\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3970\n",
      "- Decrease !! with 1324\n",
      "New sample size = 3970\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 76\n",
      "0.08095636574470419\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007787006442504694 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 76  and  max = 1000\n",
      "\n",
      "Iteration 76 -> 77\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.0902725506537014e-6\n",
      "κ = 2.568233130346262e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3970\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 7940\n",
      "- Increase !! with 3970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 7940\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 77\n",
      "0.0804806609733747\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01735863364144225 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 77  and  max = 1000\n",
      "\n",
      "Iteration 77 -> 78\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2703697766661411e-5\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 7940\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 5955\n",
      "- Decrease !! with 1985\n",
      "New sample size = 5955\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 78\n",
      "0.07969711613944497\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007823358650378451 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 78  and  max = 1000\n",
      "\n",
      "Iteration 78 -> 79\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.7335054891191997e-6\n",
      "κ = 1.7142838182656368e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 5955\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 11910\n",
      "- Increase !! with 5955\n",
      "New sample size = 11910\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 79\n",
      "0.07931522213832223\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.014460021345639992 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 79  and  max = 1000\n",
      "\n",
      "Iteration 79 -> 80\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.032545008549755e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 11910\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 8932\n",
      "- Decrease !! with 2978\n",
      "New sample size = 8932\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 80\n",
      "0.07990070114623311\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005440632145890107 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 80  and  max = 1000\n",
      "\n",
      "Iteration 80 -> 81\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.3774452754966177e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 8932\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 6699\n",
      "- Decrease !! with 2233\n",
      "New sample size = 6699\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 81\n",
      "0.07872725453924964\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007092850037950641 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 81  and  max = 1000\n",
      "\n",
      "Iteration 81 -> 82\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2127271031608306e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 6699\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 5396\n",
      "- Decrease !! with 1303\n",
      "New sample size = 5396\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 82\n",
      "0.07863561383507849\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00630659510585641 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 82  and  max = 1000\n",
      "\n",
      "Iteration 82 -> 83\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.426845094586371e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 5396\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 4173\n",
      "- Decrease !! with 1223\n",
      "New sample size = 4173\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 83\n",
      "0.07902495978631709\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005978028398947105 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 83  and  max = 1000\n",
      "\n",
      "Iteration 83 -> 84\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.369753850955539e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 4173\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3129\n",
      "- Decrease !! with 1044\n",
      "New sample size = 3129\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 84\n",
      "0.07956932804934119\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007696355814643689 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 84  and  max = 1000\n",
      "\n",
      "Iteration 84 -> 85\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6940828443952004e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3129\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3189\n",
      "- Increase !! with 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 3189\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 85\n",
      "0.07892395788782812\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004246359747000221 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 85  and  max = 1000\n",
      "\n",
      "Iteration 85 -> 86\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.034108714115748e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3189\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 2391\n",
      "- Decrease !! with 798\n",
      "New sample size = 2391\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 86\n",
      "0.08115215164212022\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00893797748548793 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 86  and  max = 1000\n",
      "\n",
      "Iteration 86 -> 87\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.845424626262362e-6\n",
      "κ = 1.0257996811535906e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 2391\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 4782\n",
      "- Increase !! with 2391\n",
      "New sample size = 4782\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 87\n",
      "0.07837857621776001\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.017510872117205256 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 87  and  max = 1000\n",
      "\n",
      "Iteration 87 -> 88\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.982011811987442e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 4782\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 3586\n",
      "- Decrease !! with 1196\n",
      "New sample size = 3586\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 88\n",
      "0.07748288265998576\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.012346042492880653 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 88  and  max = 1000\n",
      "\n",
      "Iteration 88 -> 89\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.4788269014105854e-6\n",
      "κ = 1.5578460558920255e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 3586\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 7172\n",
      "- Increase !! with 3586\n",
      "New sample size = 7172\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 89\n",
      "0.0744784415756203\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.014274122939752857 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 89  and  max = 1000\n",
      "\n",
      "Iteration 89 -> 90\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 8.86565240376363e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 7172\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 5379\n",
      "- Decrease !! with 1793\n",
      "New sample size = 5379\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 90\n",
      "0.07319664794642816\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005260613626449152 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 90  and  max = 1000\n",
      "\n",
      "Iteration 90 -> 91\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.91962507226147e-7\n",
      "κ = 1.200796191366054e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 5379\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 10758\n",
      "- Increase !! with 5379\n",
      "New sample size = 10758\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 91\n",
      "0.07346037122198622\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007435984031815469 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 91  and  max = 1000\n",
      "\n",
      "Iteration 91 -> 92\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9123536317409304e-6\n",
      "κ = 3.4044455116219266e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 10758\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 21516\n",
      "- Increase !! with 10758\n",
      "New sample size = 21516\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 92\n",
      "0.0724606233900473\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.008210174116988255 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 92  and  max = 1000\n",
      "\n",
      "Iteration 92 -> 93\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.1653665817890983e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 21516\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 16137\n",
      "- Decrease !! with 5379\n",
      "New sample size = 16137\n",
      "compute gradient for Classic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 93\n",
      "0.07172337224871826\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004518734983520442 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 93  and  max = 1000\n",
      "\n",
      "Iteration 93 -> 94\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.3422012169059377e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 16137\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 12102\n",
      "- Decrease !! with 4035\n",
      "New sample size = 12102\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 94\n",
      "0.07272028027011776\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004389296178353029 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 94  and  max = 1000\n",
      "\n",
      "Iteration 94 -> 95\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.717285824100457e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 12102\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 9076\n",
      "- Decrease !! with 3026\n",
      "New sample size = 9076\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 95\n",
      "0.07268836279356643\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004976496987922808 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 95  and  max = 1000\n",
      "\n",
      "Iteration 95 -> 96\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.47861553811243e-7\n",
      "κ = 3.264298751411066e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 9076\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 18152\n",
      "- Increase !! with 9076\n",
      "New sample size = 18152\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 96\n",
      "0.07130679669606348\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.011712659802031039 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 96  and  max = 1000\n",
      "\n",
      "Iteration 96 -> 97\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.027937085065641e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 18152\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 13614\n",
      "- Decrease !! with 4538\n",
      "New sample size = 13614\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 97\n",
      "0.07021631248501446\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004738228161076383 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 97  and  max = 1000\n",
      "\n",
      "Iteration 97 -> 98\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.2792288362624673e-7\n",
      "κ = 5.7329092050508786e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 13614\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 27228\n",
      "- Increase !! with 13614\n",
      "New sample size = 27228\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 98\n",
      "0.06999229451505765\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.012469374592667688 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 98  and  max = 1000\n",
      "\n",
      "Iteration 98 -> 99\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.9861017009304504e-6\n",
      "κ = 9.434623005019514e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 27228\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 33221\n",
      "- Increase !! with 5993\n",
      "New sample size = 33221\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 99\n",
      "0.06976264681811359\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01084173616015508 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 99  and  max = 1000\n",
      "\n",
      "Iteration 99 -> 100\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.108482909227762e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 33221\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 24915\n",
      "- Decrease !! with 8306\n",
      "New sample size = 24915\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 100\n",
      "0.0686050438493108\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0034579113024676388 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 100  and  max = 1000\n",
      "\n",
      "Iteration 100 -> 101\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.625894139700145e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 24915\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 18686\n",
      "- Decrease !! with 6229\n",
      "New sample size = 18686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 101\n",
      "0.06819882338845427\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004892571989371146 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 101  and  max = 1000\n",
      "\n",
      "Iteration 101 -> 102\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.445989065581009e-7\n",
      "κ = 7.123820328378842e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 18686\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 37372\n",
      "- Increase !! with 18686\n",
      "New sample size = 37372\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 102\n",
      "0.06745426045535395\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.01234449985303116 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 102  and  max = 1000\n",
      "\n",
      "Iteration 102 -> 103\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.811209600183516e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 37372\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 28029\n",
      "- Decrease !! with 9343\n",
      "New sample size = 28029\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 103\n",
      "0.06741410156938077\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0033908766831329934 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 103  and  max = 1000\n",
      "\n",
      "Iteration 103 -> 104\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.1579487887609628e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 28029\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 21021\n",
      "- Decrease !! with 7008\n",
      "New sample size = 21021\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 104\n",
      "0.06582250996130987\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004374275034714726 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 104  and  max = 1000\n",
      "\n",
      "Iteration 104 -> 105\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.913686043212215e-7\n",
      "κ = 4.2192268195184076e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 21021\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 42042\n",
      "- Increase !! with 21021\n",
      "New sample size = 42042\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 105\n",
      "0.06589930438918157\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.008374446141856454 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 105  and  max = 1000\n",
      "\n",
      "Iteration 105 -> 106\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.270461337284694e-6\n",
      "κ = 2.2717975406235493e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 42042\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 74093\n",
      "- Increase !! with 32051\n",
      "New sample size = 74093\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 106\n",
      "0.06563139887173981\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00814449220442718 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 106  and  max = 1000\n",
      "\n",
      "Iteration 106 -> 107\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.1265947051445604e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 74093\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 55569\n",
      "- Decrease !! with 18524\n",
      "New sample size = 55569\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 107\n",
      "0.06533294270191065\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0029253245903409883 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 107  and  max = 1000\n",
      "\n",
      "Iteration 107 -> 108\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.1186985653198065e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 55569\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 41676\n",
      "- Decrease !! with 13893\n",
      "New sample size = 41676\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 108\n",
      "0.06479454877111815\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003677194723187955 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 108  and  max = 1000\n",
      "\n",
      "Iteration 108 -> 109\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.2968331610854747e-7\n",
      "κ = 1.4884546003879796e-8\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 41676\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 31257\n",
      "- Decrease !! with 10419\n",
      "New sample size = 31257\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 109\n",
      "0.06434636585339297\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007190053281226444 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 109  and  max = 1000\n",
      "\n",
      "Iteration 109 -> 110\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.62258047398801e-6\n",
      "κ = 6.572123349501836e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 31257\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 62514\n",
      "- Increase !! with 31257\n",
      "New sample size = 62514\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 110\n",
      "0.06294396287079926\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00722515730023743 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 110  and  max = 1000\n",
      "\n",
      "Iteration 110 -> 111\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.5890528234134254e-6\n",
      "κ = 1.9899732539357692e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 62514\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 92681\n",
      "- Increase !! with 30167\n",
      "New sample size = 92681\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 111\n",
      "0.0628427562826478\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.008000703505628254 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 111  and  max = 1000\n",
      "\n",
      "Iteration 111 -> 112\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9281508153677754e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 92681\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 69510\n",
      "- Decrease !! with 23171\n",
      "New sample size = 69510\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 112\n",
      "0.0625199416894584\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0026226871451749878 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 112  and  max = 1000\n",
      "\n",
      "Iteration 112 -> 113\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9827100710195054e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 69510\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 52132\n",
      "- Decrease !! with 17378\n",
      "New sample size = 52132\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 113\n",
      "0.06288924787372088\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0028803517613153616 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 113  and  max = 1000\n",
      "\n",
      "Iteration 113 -> 114\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.31388944583653e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 52132\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 39099\n",
      "- Decrease !! with 13033\n",
      "New sample size = 39099\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 114\n",
      "0.06221508164444547\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005226573967933561 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 114  and  max = 1000\n",
      "\n",
      "Iteration 114 -> 115\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.31131774898094e-7\n",
      "κ = 1.6914800895989326e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 39099\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 66009\n",
      "- Increase !! with 26910\n",
      "New sample size = 66009\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 115\n",
      "0.06286770989240567\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007292993568411281 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 115  and  max = 1000\n",
      "\n",
      "Iteration 115 -> 116\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6426717315653585e-6\n",
      "κ = 1.4500342013909006e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 66009\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 115266\n",
      "- Increase !! with 49257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 115266\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 116\n",
      "0.06201858415588788\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006951040232842087 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 116  and  max = 1000\n",
      "\n",
      "Iteration 116 -> 117\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2951631506825826e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 115266\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 86449\n",
      "- Decrease !! with 28817\n",
      "New sample size = 86449\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 117\n",
      "0.06188925043682885\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002401533417217093 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 117  and  max = 1000\n",
      "\n",
      "Iteration 117 -> 118\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2654580780952378e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 86449\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 64836\n",
      "- Decrease !! with 21613\n",
      "New sample size = 64836\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 118\n",
      "0.06203697257067834\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002979305154666841 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 118  and  max = 1000\n",
      "\n",
      "Iteration 118 -> 119\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.167101282977908e-7\n",
      "κ = 1.7043535829434148e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 64836\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 91252\n",
      "- Increase !! with 26416\n",
      "New sample size = 91252\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 119\n",
      "0.06153669515399135\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007598672645894946 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 119  and  max = 1000\n",
      "\n",
      "Iteration 119 -> 120\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.8362912546737551e-6\n",
      "κ = 1.638036762343464e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 91252\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 68439\n",
      "- Decrease !! with 22813\n",
      "New sample size = 68439\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 120\n",
      "0.062396656546057465\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007567278828175909 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 120  and  max = 1000\n",
      "\n",
      "Iteration 120 -> 121\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.8332850234525774e-6\n",
      "κ = 3.334994736717215e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 68439\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 86027\n",
      "- Increase !! with 17588\n",
      "New sample size = 86027\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 121\n",
      "0.06179795662677009\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007583158973001275 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 121  and  max = 1000\n",
      "\n",
      "Iteration 121 -> 122\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9538534241518456e-6\n",
      "κ = 1.9007448601816128e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 86027\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 64520\n",
      "- Decrease !! with 21507\n",
      "New sample size = 64520\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 122\n",
      "0.06067801971211419\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006331129333338258 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 122  and  max = 1000\n",
      "\n",
      "Iteration 122 -> 123\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2575222227645188e-6\n",
      "κ = 1.4222435098556363e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 64520\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 78563\n",
      "- Increase !! with 14043\n",
      "New sample size = 78563\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 123\n",
      "0.06032083749992096\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00628281076372459 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 123  and  max = 1000\n",
      "\n",
      "Iteration 123 -> 124\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0735285377875713e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 78563\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 58922\n",
      "- Decrease !! with 19641\n",
      "New sample size = 58922\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 124\n",
      "0.06000405314230699\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0027708823463229544 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 124  and  max = 1000\n",
      "\n",
      "Iteration 124 -> 125\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.101515120402557e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 58922\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 44191\n",
      "- Decrease !! with 14731\n",
      "New sample size = 44191\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 125\n",
      "0.059599678539825986\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002960762125570566 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 125  and  max = 1000\n",
      "\n",
      "Iteration 125 -> 126\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.445719022315158e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 44191\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 33143\n",
      "- Decrease !! with 11048\n",
      "New sample size = 33143\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 126\n",
      "0.05975252447462325\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0026392565978609075 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 126  and  max = 1000\n",
      "\n",
      "Iteration 126 -> 127\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.993041396356547e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 33143\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 24857\n",
      "- Decrease !! with 8286\n",
      "New sample size = 24857\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 127\n",
      "0.05957673405031555\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002324109363354912 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 127  and  max = 1000\n",
      "\n",
      "Iteration 127 -> 128\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.311998368859996e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 24857\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 18642\n",
      "- Decrease !! with 6215\n",
      "New sample size = 18642\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 128\n",
      "0.05910164254562451\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0033571602738292827 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 128  and  max = 1000\n",
      "\n",
      "Iteration 128 -> 129\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9993986850807958e-7\n",
      "κ = 2.2299551318016072e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 18642\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 37284\n",
      "- Increase !! with 18642\n",
      "New sample size = 37284\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 129\n",
      "0.06040916297843098\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007795252346374046 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 129  and  max = 1000\n",
      "\n",
      "Iteration 129 -> 130\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9206969236409067e-6\n",
      "κ = 3.141118046789189e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 37284\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 50827\n",
      "- Increase !! with 13543\n",
      "New sample size = 50827\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 130\n",
      "0.0595747883631317\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007308823376523378 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 130  and  max = 1000\n",
      "\n",
      "Iteration 130 -> 131\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6688706804485585e-6\n",
      "κ = 1.8950288568829287e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 50827\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 64529\n",
      "- Increase !! with 13702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 64529\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 131\n",
      "0.05939342535268196\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.007028107699210839 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 131  and  max = 1000\n",
      "\n",
      "Iteration 131 -> 132\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6200421168842129e-6\n",
      "κ = 3.9504249640690815e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 64529\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 48396\n",
      "- Decrease !! with 16133\n",
      "New sample size = 48396\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 132\n",
      "0.05884928342799557\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005428045862722816 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 132  and  max = 1000\n",
      "\n",
      "Iteration 132 -> 133\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.038590367271053e-7\n",
      "κ = 1.5418406860024384e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 48396\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 50554\n",
      "- Increase !! with 2158\n",
      "New sample size = 50554\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 133\n",
      "0.058601864909768646\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004788225542927945 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 133  and  max = 1000\n",
      "\n",
      "Iteration 133 -> 134\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.59245001147493e-7\n",
      "κ = 9.534302327099247e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 50554\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 78152\n",
      "- Increase !! with 27598\n",
      "New sample size = 78152\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 134\n",
      "0.058606776620995615\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004738012627332979 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 134  and  max = 1000\n",
      "\n",
      "Iteration 134 -> 135\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.668453936584972e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 78152\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 58614\n",
      "- Decrease !! with 19538\n",
      "New sample size = 58614\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 135\n",
      "0.05847843622584046\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0022875837678922196 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 135  and  max = 1000\n",
      "\n",
      "Iteration 135 -> 136\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.984924676767494e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 58614\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 43960\n",
      "- Decrease !! with 14654\n",
      "New sample size = 43960\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 136\n",
      "0.05817564438625044\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002403640787440008 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 136  and  max = 1000\n",
      "\n",
      "Iteration 136 -> 137\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.777256184010369e-8\n",
      "κ = 6.516400707811684e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 43960\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 87920\n",
      "- Increase !! with 43960\n",
      "New sample size = 87920\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 137\n",
      "0.05856016556994807\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.006963898967233833 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 137  and  max = 1000\n",
      "\n",
      "Iteration 137 -> 138\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.4428350501727937e-6\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 87920\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 65940\n",
      "- Decrease !! with 21980\n",
      "New sample size = 65940\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 138\n",
      "0.05872264153584924\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0022474922761314253 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 138  and  max = 1000\n",
      "\n",
      "Iteration 138 -> 139\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.288654222991975e-8\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 65940\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 49455\n",
      "- Decrease !! with 16485\n",
      "New sample size = 49455\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 139\n",
      "0.05848248169140877\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0026846005585528803 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 139  and  max = 1000\n",
      "\n",
      "Iteration 139 -> 140\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2115046229311155e-7\n",
      "κ = 3.993606286647159e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 49455\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 98910\n",
      "- Increase !! with 49455\n",
      "New sample size = 98910\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 140\n",
      "0.05839354268891755\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005524998329849822 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 140  and  max = 1000\n",
      "\n",
      "Iteration 140 -> 141\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.614319470077755e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 98910\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 74182\n",
      "- Decrease !! with 24728\n",
      "New sample size = 74182\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 141\n",
      "0.05793868448965435\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002342495894113179 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 141  and  max = 1000\n",
      "\n",
      "Iteration 141 -> 142\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.531754325622164e-8\n",
      "κ = 5.867987836037562e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 74182\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 103939\n",
      "- Increase !! with 29757\n",
      "New sample size = 103939\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 142\n",
      "0.057617222003613494\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005037983468198423 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 142  and  max = 1000\n",
      "\n",
      "Iteration 142 -> 143\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.27618508034069e-7\n",
      "κ = 2.1029302570230802e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 103939\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 91289\n",
      "- Decrease !! with 12650\n",
      "New sample size = 91289\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 143\n",
      "0.057346133155846093\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004694670053646891 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 143  and  max = 1000\n",
      "\n",
      "Iteration 143 -> 144\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.006213867904321e-7\n",
      "κ = 8.539699142473118e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 91289\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 168714\n",
      "- Increase !! with 77425\n",
      "New sample size = 168714\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 144\n",
      "0.05717690712856506\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004893621699550735 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 144  and  max = 1000\n",
      "\n",
      "Iteration 144 -> 145\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.819547166641069e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 168714\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 126535\n",
      "- Decrease !! with 42179\n",
      "New sample size = 126535\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 145\n",
      "0.05679779126838992\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002015990230142294 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 145  and  max = 1000\n",
      "\n",
      "Iteration 145 -> 146\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.7297387474768446e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 126535\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 94901\n",
      "- Decrease !! with 31634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 94901\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 146\n",
      "0.056511678411667696\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0022748775063045575 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 146  and  max = 1000\n",
      "\n",
      "Iteration 146 -> 147\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.52816521851866e-8\n",
      "κ = 3.592013213539798e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 94901\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 189802\n",
      "- Increase !! with 94901\n",
      "New sample size = 189802\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 147\n",
      "0.05659263908920655\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005817182408858524 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 147  and  max = 1000\n",
      "\n",
      "Iteration 147 -> 148\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0347911917907876e-6\n",
      "κ = 2.2894768166642206e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 189802\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 142351\n",
      "- Decrease !! with 47451\n",
      "New sample size = 142351\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 148\n",
      "0.05618822664160718\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0044172142662820355 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 148  and  max = 1000\n",
      "\n",
      "Iteration 148 -> 149\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.230272865207179e-7\n",
      "κ = 7.52621403560504e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 142351\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 164624\n",
      "- Increase !! with 22273\n",
      "New sample size = 164624\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 149\n",
      "0.056037744676468756\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0042881257140070005 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 149  and  max = 1000\n",
      "\n",
      "Iteration 149 -> 150\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.608373910095514e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 164624\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 123468\n",
      "- Decrease !! with 41156\n",
      "New sample size = 123468\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 150\n",
      "0.05582901296165427\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0018970862225394511 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 150  and  max = 1000\n",
      "\n",
      "Iteration 150 -> 151\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.5873462384400497e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 123468\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 92601\n",
      "- Decrease !! with 30867\n",
      "New sample size = 92601\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 151\n",
      "0.05561996309628003\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002070146020685346 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 151  and  max = 1000\n",
      "\n",
      "Iteration 151 -> 152\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.34439287031283e-8\n",
      "κ = 7.739318379619103e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 92601\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 185202\n",
      "- Increase !! with 92601\n",
      "New sample size = 185202\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 152\n",
      "0.05618087947142076\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004992090870850974 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 152  and  max = 1000\n",
      "\n",
      "Iteration 152 -> 153\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 6.73679039684897e-7\n",
      "κ = 8.489862353218555e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 185202\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 212398\n",
      "- Increase !! with 27196\n",
      "New sample size = 212398\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 153\n",
      "0.056000201693021244\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.005022443859374092 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 153  and  max = 1000\n",
      "\n",
      "Iteration 153 -> 154\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.539126296444145e-7\n",
      "κ = 6.066415191789592e-9\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 212398\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 159298\n",
      "- Decrease !! with 53100\n",
      "New sample size = 159298\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 154\n",
      "0.055689687216284894\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004038247396923947 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 154  and  max = 1000\n",
      "\n",
      "Iteration 154 -> 155\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.6714078152007655e-7\n",
      "κ = 1.1212490362843251e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 159298\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 119473\n",
      "- Decrease !! with 39825\n",
      "New sample size = 119473\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 155\n",
      "0.05554547465872333\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0038059790229485616 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 155  and  max = 1000\n",
      "\n",
      "Iteration 155 -> 156\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.2053671234283957e-7\n",
      "κ = 7.948156159163423e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 119473\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 89604\n",
      "- Decrease !! with 29869\n",
      "New sample size = 89604\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 156\n",
      "0.05589872734522958\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00362404862858445 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 156  and  max = 1000\n",
      "\n",
      "Iteration 156 -> 157\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.424394879210637e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 89604\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 67203\n",
      "- Decrease !! with 22401\n",
      "New sample size = 67203\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 157\n",
      "0.05538199751951332\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0019469894178176788 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 157  and  max = 1000\n",
      "\n",
      "Iteration 157 -> 158\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.1826657685026204e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 67203\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 50402\n",
      "- Decrease !! with 16801\n",
      "New sample size = 50402\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 158\n",
      "0.05517965106105261\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0017880704514508605 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 158  and  max = 1000\n",
      "\n",
      "Iteration 158 -> 159\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.1942605024274174e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 50402\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 37801\n",
      "- Decrease !! with 12601\n",
      "New sample size = 37801\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 159\n",
      "0.054524817502653984\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0025291830031360994 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 159  and  max = 1000\n",
      "\n",
      "Iteration 159 -> 160\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.1220864799954336e-7\n",
      "κ = 2.251133565405972e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 37801\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 63407\n",
      "- Increase !! with 25606\n",
      "New sample size = 63407\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 160\n",
      "0.05561853788686307\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0051736622493787745 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 160  and  max = 1000\n",
      "\n",
      "Iteration 160 -> 161\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.212537236126885e-7\n",
      "κ = 2.1637604799372347e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 63407\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 126814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Increase !! with 63407\n",
      "New sample size = 126814\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 161\n",
      "0.054925684275086754\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0051211755705262785 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 161  and  max = 1000\n",
      "\n",
      "Iteration 161 -> 162\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.999490430129382e-7\n",
      "κ = 1.8074838610666348e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 126814\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 95110\n",
      "- Decrease !! with 31704\n",
      "New sample size = 95110\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 162\n",
      "0.054629310518688294\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0038906507807410272 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 162  and  max = 1000\n",
      "\n",
      "Iteration 162 -> 163\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.201234651660405e-7\n",
      "κ = 8.389543435774398e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 95110\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 71332\n",
      "- Decrease !! with 23778\n",
      "New sample size = 71332\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 163\n",
      "0.05445463933568464\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003245330682159258 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 163  and  max = 1000\n",
      "\n",
      "Iteration 163 -> 164\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.5905055415157044e-7\n",
      "κ = 3.853615616956964e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 71332\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 94530\n",
      "- Increase !! with 23198\n",
      "New sample size = 94530\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 164\n",
      "0.05482844375050203\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004173632632870452 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 164  and  max = 1000\n",
      "\n",
      "Iteration 164 -> 165\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.922520734690786e-7\n",
      "κ = 4.482334362536952e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 94530\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 105568\n",
      "- Increase !! with 11038\n",
      "New sample size = 105568\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 165\n",
      "0.0549384362171124\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003534152989049632 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 165  and  max = 1000\n",
      "\n",
      "Iteration 165 -> 166\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.872031920583537e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 105568\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 79176\n",
      "- Decrease !! with 26392\n",
      "New sample size = 79176\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 166\n",
      "0.054777836473372976\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.001618751047588182 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 166  and  max = 1000\n",
      "\n",
      "Iteration 166 -> 167\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.9082102594436702e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 79176\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 59382\n",
      "- Decrease !! with 19794\n",
      "New sample size = 59382\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 167\n",
      "0.05411721632064868\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0019816591467884726 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 167  and  max = 1000\n",
      "\n",
      "Iteration 167 -> 168\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.7199988584703474e-8\n",
      "κ = 2.782034339503556e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 59382\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 118764\n",
      "- Increase !! with 59382\n",
      "New sample size = 118764\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 168\n",
      "0.054706261297941226\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.004591301966440273 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 168  and  max = 1000\n",
      "\n",
      "Iteration 168 -> 169\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.501673054442247e-7\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 118764\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 89073\n",
      "- Decrease !! with 29691\n",
      "New sample size = 89073\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 169\n",
      "0.0545710871738699\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0016329831465725464 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 169  and  max = 1000\n",
      "\n",
      "Iteration 169 -> 170\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.7125553748874806e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 89073\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 66804\n",
      "- Decrease !! with 22269\n",
      "New sample size = 66804\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 170\n",
      "0.053713768022537335\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002198181007209587 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 170  and  max = 1000\n",
      "\n",
      "Iteration 170 -> 171\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.08262313613871e-8\n",
      "κ = 2.6937338617313624e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 66804\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 50103\n",
      "- Decrease !! with 16701\n",
      "New sample size = 50103\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 171\n",
      "0.05310101687637026\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003662242013335029 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 171  and  max = 1000\n",
      "\n",
      "Iteration 171 -> 172\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.4629283718613563e-7\n",
      "κ = 1.5991721650710254e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 50103\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 100206\n",
      "- Increase !! with 50103\n",
      "New sample size = 100206\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 172\n",
      "0.053346747875247395\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003931531176904011 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 172  and  max = 1000\n",
      "\n",
      "Iteration 172 -> 173\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.4736340205522857e-7\n",
      "κ = 1.1389137657381345e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 100206\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 75154\n",
      "- Decrease !! with 25052\n",
      "New sample size = 75154\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 173\n",
      "0.053724575766884684\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003250420749371817 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 173  and  max = 1000\n",
      "\n",
      "Iteration 173 -> 174\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.0071779266546216e-7\n",
      "κ = 3.5810829480113618e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 75154\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 56365\n",
      "- Decrease !! with 18789\n",
      "New sample size = 56365\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 174\n",
      "0.05353147745248263\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002757990685779207 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 174  and  max = 1000\n",
      "\n",
      "Iteration 174 -> 175\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.7224010341939088e-7\n",
      "κ = 8.254316057517126e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 56365\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 112730\n",
      "- Increase !! with 56365\n",
      "New sample size = 112730\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 175\n",
      "0.053699552811711175\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0033349755197961163 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 175  and  max = 1000\n",
      "\n",
      "Iteration 175 -> 176\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.7322565875700954e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 112730\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 84547\n",
      "- Decrease !! with 28183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 84547\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 176\n",
      "0.05325845510873707\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0015163776794909973 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 176  and  max = 1000\n",
      "\n",
      "Iteration 176 -> 177\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.73848107828874e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 84547\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 63410\n",
      "- Decrease !! with 21137\n",
      "New sample size = 63410\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 177\n",
      "0.05335790757253498\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.001784164542432601 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 177  and  max = 1000\n",
      "\n",
      "Iteration 177 -> 178\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.3928795979535185e-8\n",
      "κ = 2.390889498852152e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 63410\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 126820\n",
      "- Increase !! with 63410\n",
      "New sample size = 126820\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 178\n",
      "0.05285953893890267\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0036523383796424618 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 178  and  max = 1000\n",
      "\n",
      "Iteration 178 -> 179\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.4644255870361437e-7\n",
      "κ = 1.0681952309778346e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 126820\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 135691\n",
      "- Increase !! with 8871\n",
      "New sample size = 135691\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 179\n",
      "0.05260966343774318\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003473615808049775 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 179  and  max = 1000\n",
      "\n",
      "Iteration 179 -> 180\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.7431830091246525e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 135691\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 101768\n",
      "- Decrease !! with 33923\n",
      "New sample size = 101768\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 180\n",
      "0.05225424840168425\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0015829894764504062 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 180  and  max = 1000\n",
      "\n",
      "Iteration 180 -> 181\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.567394781030429e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 101768\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 76326\n",
      "- Decrease !! with 25442\n",
      "New sample size = 76326\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 181\n",
      "0.05220047176525231\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0020177178928605355 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 181  and  max = 1000\n",
      "\n",
      "Iteration 181 -> 182\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.671692491387383e-8\n",
      "κ = 2.782320207926114e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 76326\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 57244\n",
      "- Decrease !! with 19082\n",
      "New sample size = 57244\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 182\n",
      "0.052163865630819296\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0029193510158565883 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 182  and  max = 1000\n",
      "\n",
      "Iteration 182 -> 183\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.179366558763656e-7\n",
      "κ = 5.635065632505569e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 57244\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 68662\n",
      "- Increase !! with 11418\n",
      "New sample size = 68662\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 183\n",
      "0.05236008226793728\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0030352592272380905 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 183  and  max = 1000\n",
      "\n",
      "Iteration 183 -> 184\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.441474203166431e-7\n",
      "κ = 5.331644727125156e-9\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 68662\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 77754\n",
      "- Increase !! with 9092\n",
      "New sample size = 77754\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 184\n",
      "0.05243370675649624\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0026274507773831465 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 184  and  max = 1000\n",
      "\n",
      "Iteration 184 -> 185\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.5719400894199042e-7\n",
      "κ = 3.785057531913702e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 77754\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 155508\n",
      "- Increase !! with 77754\n",
      "New sample size = 155508\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 185\n",
      "0.052556303588815856\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003341695092389591 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 185  and  max = 1000\n",
      "\n",
      "Iteration 185 -> 186\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.8389016572059544e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 155508\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 116631\n",
      "- Decrease !! with 38877\n",
      "New sample size = 116631\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 186\n",
      "0.05242646060465694\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0015049333634850946 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 186  and  max = 1000\n",
      "\n",
      "Iteration 186 -> 187\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.7373239408971038e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 116631\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 87473\n",
      "- Decrease !! with 29158\n",
      "New sample size = 87473\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 187\n",
      "0.05248837511877883\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0018438475700394562 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 187  and  max = 1000\n",
      "\n",
      "Iteration 187 -> 188\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.5471503442689533e-8\n",
      "κ = 1.7726090239860017e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 87473\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 134529\n",
      "- Increase !! with 47056\n",
      "New sample size = 134529\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 188\n",
      "0.05258466561303038\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003637368171362945 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 188  and  max = 1000\n",
      "\n",
      "Iteration 188 -> 189\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 4.0316971685915495e-7\n",
      "κ = 1.3652687272241785e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 134529\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 100896\n",
      "- Decrease !! with 33633\n",
      "New sample size = 100896\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 189\n",
      "0.051869181396210585\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002605205715771843 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 189  and  max = 1000\n",
      "\n",
      "Iteration 189 -> 190\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.5282419643353104e-7\n",
      "κ = 4.210428473326188e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 100896\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 201792\n",
      "- Increase !! with 100896\n",
      "New sample size = 201792\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 190\n",
      "0.05184247097249767\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002625566591746749 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 190  and  max = 1000\n",
      "\n",
      "Iteration 190 -> 191\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.7888326021913144e-7\n",
      "κ = 5.105855560220654e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 201792\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 151344\n",
      "- Decrease !! with 50448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size = 151344\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 191\n",
      "0.05168034254071159\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002344201679126829 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 191  and  max = 1000\n",
      "\n",
      "Iteration 191 -> 192\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.1978917920880667e-7\n",
      "κ = 1.4653173181073017e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 151344\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 302688\n",
      "- Increase !! with 151344\n",
      "New sample size = 302688\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 192\n",
      "0.051960129839504265\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0027124595040572508 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 192  and  max = 1000\n",
      "\n",
      "Iteration 192 -> 193\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.7050013372304652e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 302688\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 227016\n",
      "- Decrease !! with 75672\n",
      "New sample size = 227016\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 193\n",
      "0.05173558214349019\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.001216489268979167 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 193  and  max = 1000\n",
      "\n",
      "Iteration 193 -> 194\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.81101843894608e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 227016\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 170262\n",
      "- Decrease !! with 56754\n",
      "New sample size = 170262\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 194\n",
      "0.051287911876580466\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.001602193994127218 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 194  and  max = 1000\n",
      "\n",
      "Iteration 194 -> 195\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.307176847911242e-8\n",
      "κ = 2.2600798291872514e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 170262\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 127696\n",
      "- Decrease !! with 42566\n",
      "New sample size = 127696\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 195\n",
      "0.05116596707605735\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003359912209940441 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 195  and  max = 1000\n",
      "\n",
      "Iteration 195 -> 196\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.6070709217257274e-7\n",
      "κ = 7.751402666008702e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 127696\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 182574\n",
      "- Increase !! with 54878\n",
      "New sample size = 182574\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 196\n",
      "0.05149288602426544\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.003784643966167752 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 196  and  max = 1000\n",
      "\n",
      "Iteration 196 -> 197\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.583446270673936e-7\n",
      "κ = 7.461861803718743e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 182574\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 136930\n",
      "- Decrease !! with 45644\n",
      "New sample size = 136930\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 197\n",
      "0.051301547126304525\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0032188312757559477 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 197  and  max = 1000\n",
      "\n",
      "Iteration 197 -> 198\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.560467364584021e-7\n",
      "κ = 6.465146717049846e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 136930\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 128799\n",
      "- Decrease !! with 8131\n",
      "New sample size = 128799\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 198\n",
      "0.051071030492628074\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002924839791404076 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 198  and  max = 1000\n",
      "\n",
      "Iteration 198 -> 199\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.2361859124242828e-7\n",
      "κ = 4.587223382256224e-9\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 128799\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 96599\n",
      "- Decrease !! with 32200\n",
      "New sample size = 96599\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 199\n",
      "0.050712416811755506\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0027383143143397707 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 199  and  max = 1000\n",
      "\n",
      "Iteration 199 -> 200\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.8167807390676893e-7\n",
      "κ = 3.3394038933908727e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 96599\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 129509\n",
      "- Increase !! with 32910\n",
      "New sample size = 129509\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 200\n",
      "0.051389348942632425\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.00264119635579775 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 200  and  max = 1000\n",
      "\n",
      "Iteration 200 -> 201\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6672823079572466e-7\n",
      "κ = 3.0677711573199036e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 129509\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 218199\n",
      "- Increase !! with 88690\n",
      "New sample size = 218199\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 201\n",
      "0.0513353320007656\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002503849520718166 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 201  and  max = 1000\n",
      "\n",
      "Iteration 201 -> 202\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.4241556587685246e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 218199\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 163649\n",
      "- Decrease !! with 54550\n",
      "New sample size = 163649\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 202\n",
      "0.05131839326020334\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0011249782375619825 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 202  and  max = 1000\n",
      "\n",
      "Iteration 202 -> 203\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.917432333022461e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 163649\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 122736\n",
      "- Decrease !! with 40913\n",
      "New sample size = 122736\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 203\n",
      "0.051400244115966054\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.001376963635940367 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 203  and  max = 1000\n",
      "\n",
      "Iteration 203 -> 204\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.178326445044756e-8\n",
      "κ = 2.5019794313612847e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 122736\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 245472\n",
      "- Increase !! with 122736\n",
      "New sample size = 245472\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 204\n",
      "0.05164998877273625\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0036061958041850423 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 204  and  max = 1000\n",
      "\n",
      "Iteration 204 -> 205\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.910930407635114e-7\n",
      "κ = 5.170309418096027e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 245472\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 184104\n",
      "- Decrease !! with 61368\n",
      "New sample size = 184104\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 205\n",
      "0.05148145540600516\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0024586409580979562 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 205  and  max = 1000\n",
      "\n",
      "Iteration 205 -> 206\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.4744571409572955e-7\n",
      "κ = 3.6631516758931733e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 184104\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 150548\n",
      "- Decrease !! with 33556\n",
      "New sample size = 150548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 206\n",
      "0.05133897261211253\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002026324798463239 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 206  and  max = 1000\n",
      "\n",
      "Iteration 206 -> 207\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0801880623079539e-7\n",
      "κ = 1.5003599392678551e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 150548\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 112911\n",
      "- Decrease !! with 37637\n",
      "New sample size = 112911\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 207\n",
      "0.05150394537307972\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0014803630804511472 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 207  and  max = 1000\n",
      "\n",
      "Iteration 207 -> 208\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 3.90283984942357e-8\n",
      "κ = 2.0559706925669915e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 112911\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 188454\n",
      "- Increase !! with 75543\n",
      "New sample size = 188454\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 208\n",
      "0.05154543150859858\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0027024564881702813 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 208  and  max = 1000\n",
      "\n",
      "Iteration 208 -> 209\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.6614735091888893e-7\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 188454\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 141340\n",
      "- Decrease !! with 47114\n",
      "New sample size = 141340\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 209\n",
      "0.051807046419778464\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0015881860574384623 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 209  and  max = 1000\n",
      "\n",
      "Iteration 209 -> 210\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 5.240654753113659e-8\n",
      "κ = 1.2570265593533877e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 141340\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 106005\n",
      "- Decrease !! with 35335\n",
      "New sample size = 106005\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 210\n",
      "0.05158519955208146\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002112202763552431 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 210  and  max = 1000\n",
      "\n",
      "Iteration 210 -> 211\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.0281639034670809e-7\n",
      "κ = 3.4782096203158954e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 106005\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 151089\n",
      "- Increase !! with 45084\n",
      "New sample size = 151089\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 211\n",
      "0.05187871190890285\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0020620893459860085 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 211  and  max = 1000\n",
      "\n",
      "Iteration 211 -> 212\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.51636129789553e-8\n",
      "κ = 1.0835672029814525e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 151089\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 215873\n",
      "- Increase !! with 64784\n",
      "New sample size = 215873\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 212\n",
      "0.051677023859017734\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002034695828160365 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 212  and  max = 1000\n",
      "\n",
      "Iteration 212 -> 213\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.155304943788469e-8\n",
      "κ = 1.9486649430292775e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 215873\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 321374\n",
      "- Increase !! with 105501\n",
      "New sample size = 321374\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 213\n",
      "0.051506674739780364\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.002149026336223292 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 213  and  max = 1000\n",
      "\n",
      "Iteration 213 -> 214\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.2227623753268906e-7\n",
      "κ = 2.4441487898194507e-9\n",
      "TCG on border\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 321374\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 241030\n",
      "- Decrease !! with 80344\n",
      "New sample size = 241030\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 214\n",
      "0.05159341147822251\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.001941236205054524 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 214  and  max = 1000\n",
      "\n",
      "Iteration 214 -> 215\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 7.308762802374715e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 241030\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 180772\n",
      "- Decrease !! with 60258\n",
      "New sample size = 180772\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region expanded (VERY good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 215\n",
      "0.05175882229051257\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0012075472661286567 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 215  and  max = 1000\n",
      "\n",
      "Iteration 215 -> 216\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 1.4113081873272693e-8\n",
      "TCG on border\n",
      "TCG stoped on iteration 1\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 180772\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 135579\n",
      "- Decrease !! with 45193\n",
      "New sample size = 135579\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 216\n",
      "0.051648342550214506\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0013103719584851275 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 216  and  max = 1000\n",
      "\n",
      "Iteration 216 -> 217\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 2.5886507848512946e-8\n",
      "κ = 1.7519061409639787e-9\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 135579\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 193609\n",
      "- Increase !! with 58030\n",
      "New sample size = 193609\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 217\n",
      "0.05114594767761138\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.0019871440319637816 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 217  and  max = 1000\n",
      "\n",
      "Iteration 217 -> 218\n",
      "computecand! AbstractStochasticModel -- Classic\n",
      "--- TCG classic \n",
      "κ = 9.172347769525878e-8\n",
      "κ = 8.620648287630769e-10\n",
      "TCG on border\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      "--------- Classic iter to Do ----------\n",
      "Nothing done \n",
      "-------------------------\n",
      "updateState! AbstractStochasticModel  -- Classic\n",
      " --- updateSampleSize! --- Ind / Common Variables : Geraldine.DynamicSampling{Geraldine.IndComRN,Int64}\n",
      "Current sample size = 193609\n",
      "potentialSampleSize for Dynamic sampling\n",
      " --- First Order Var sHs !!!\n",
      "Naive smoothing -- int = 0.75 / sup = 2.0\n",
      "New size = 197646\n",
      "- Increase !! with 4037\n",
      "New sample size = 197646\n",
      "compute gradient for Classic\n",
      "------- Classic updatePreviousValues --------\n",
      "Do nothing\n",
      "-------------------------\n",
      "step accepted, region reduced (good accuracy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 218\n",
      "0.05110815494775076\n",
      "--------------------------------------------------------------------------------\n",
      "Tests arret !!!!\n",
      " Test is Grad Optimal ? ‖g‖ = 0.001862532096991342 and ϵ = 1.0000000000000004e-6\n",
      "Nmax reached ? \n",
      "k = 218  and  max = 1000\n",
      "tmaxReached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"here's a state\"\"here's an Accumulator\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "\n",
    "                        # Test 1 : BHHH / sHs\n",
    "\n",
    "# --- Hessian Approx\n",
    "Hessian = Geraldine.BHHHScores{TYPE}\n",
    "# Smoothing\n",
    "smoothing = Geraldine.NaiveSmoothing()\n",
    "# --- Sampling\n",
    "varStrategy = Geraldine.FirstOrderVar{Float64}(smoothing)\n",
    "\n",
    "samplingStrategy = Geraldine.DynamicSampling{Geraldine.IndComRN}(Sofia.Nobs(mo), varStrategy, \n",
    "                                                                    NMin = NMin, N0=N0, \n",
    "                                                                    increment=increment, \n",
    "                                                                    subSampling=subSampling)\n",
    "\n",
    "# BTR\n",
    "accBHHH =  Accum_2nd_sHs(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = 1000, TMax = 120.0, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp; Hessian = Hessian, sam=typeof(samplingStrategy))\n",
    "\n",
    "state, accumulatorBHHHshs = btr(mo, copy(x0) , samplingStrategy, accumulator = accBHHH, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "conservative-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Collecting results\n",
    " resultBHHHshs = Geraldine.structToDict(accumulatorBHHHshs)\n",
    "\n",
    "samplingBHHHshs = resultBHHHshs[:SamplingSizeAccumulator]\n",
    "fBHHHshs = resultBHHHshs[:ValueAccumulator]\n",
    "paramBHHHshs = resultBHHHshs[:ParamAccumulator];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unique-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "y1",
         "line": {
          "color": "rgba(0, 154, 250, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "y1",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219
         ],
         "xaxis": "x1",
         "y": [
          100,
          75,
          56,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          58,
          58,
          116,
          232,
          174,
          130,
          260,
          195,
          146,
          146,
          214,
          220,
          165,
          165,
          232,
          174,
          130,
          260,
          200,
          400,
          323,
          646,
          1034,
          775,
          581,
          435,
          582,
          745,
          558,
          487,
          974,
          730,
          1460,
          1095,
          1626,
          1566,
          2145,
          1608,
          1206,
          1303,
          2062,
          4124,
          3093,
          2319,
          2319,
          1739,
          3478,
          2608,
          3435,
          2677,
          2756,
          2067,
          2783,
          2087,
          1565,
          2468,
          2274,
          2157,
          2680,
          5360,
          4020,
          4109,
          3352,
          3530,
          2647,
          5294,
          3970,
          7940,
          5955,
          11910,
          8932,
          6699,
          5396,
          4173,
          3129,
          3189,
          2391,
          4782,
          3586,
          7172,
          5379,
          10758,
          21516,
          16137,
          12102,
          9076,
          18152,
          13614,
          27228,
          33221,
          24915,
          18686,
          37372,
          28029,
          21021,
          42042,
          74093,
          55569,
          41676,
          31257,
          62514,
          92681,
          69510,
          52132,
          39099,
          66009,
          115266,
          86449,
          64836,
          91252,
          68439,
          86027,
          64520,
          78563,
          58922,
          44191,
          33143,
          24857,
          18642,
          37284,
          50827,
          64529,
          48396,
          50554,
          78152,
          58614,
          43960,
          87920,
          65940,
          49455,
          98910,
          74182,
          103939,
          91289,
          168714,
          126535,
          94901,
          189802,
          142351,
          164624,
          123468,
          92601,
          185202,
          212398,
          159298,
          119473,
          89604,
          67203,
          50402,
          37801,
          63407,
          126814,
          95110,
          71332,
          94530,
          105568,
          79176,
          59382,
          118764,
          89073,
          66804,
          50103,
          100206,
          75154,
          56365,
          112730,
          84547,
          63410,
          126820,
          135691,
          101768,
          76326,
          57244,
          68662,
          77754,
          155508,
          116631,
          87473,
          134529,
          100896,
          201792,
          151344,
          302688,
          227016,
          170262,
          127696,
          182574,
          136930,
          128799,
          96599,
          129509,
          218199,
          163649,
          122736,
          245472,
          184104,
          150548,
          112911,
          188454,
          141340,
          106005,
          151089,
          215873,
          321374,
          241030,
          180772,
          135579,
          193609,
          197646
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        }
       ],
       "layout": {
        "annotations": [],
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 1.000)",
         "bordercolor": "rgba(0, 0, 0, 1.000)",
         "font": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tracegroupgap": 0,
         "x": 1,
         "y": 1
        },
        "margin": {
         "b": 20,
         "l": 0,
         "r": 0,
         "t": 20
        },
        "paper_bgcolor": "rgba(255, 255, 255, 1.000)",
        "plot_bgcolor": "rgba(255, 255, 255, 1.000)",
        "showlegend": true,
        "width": 600,
        "xaxis": {
         "anchor": "y1",
         "domain": [
          0.08063575386410031,
          0.9934383202099737
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          -5.54,
          225.54
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "0",
          "50",
          "100",
          "150",
          "200"
         ],
         "tickvals": [
          0,
          50,
          100,
          150,
          200
         ],
         "title": "",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        },
        "yaxis": {
         "anchor": "x1",
         "domain": [
          0.03762029746281716,
          0.9901574803149606
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          -9587.66,
          331013.66
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "0",
          "1×10⁵",
          "2×10⁵",
          "3×10⁵"
         ],
         "tickvals": [
          0,
          100000,
          200000,
          300000
         ],
         "title": "",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        }
       }
      },
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "    <head>\n",
       "        <title>Plots.jl</title>\n",
       "        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
       "    </head>\n",
       "    <body>\n",
       "            <div id=\"4a6653ee-8578-4e17-8f5c-ab578ba44dbc\" style=\"width:600px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('4a6653ee-8578-4e17-8f5c-ab578ba44dbc');\n",
       "    Plotly.plot(PLOT, [\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            1,\n",
       "            2,\n",
       "            3,\n",
       "            4,\n",
       "            5,\n",
       "            6,\n",
       "            7,\n",
       "            8,\n",
       "            9,\n",
       "            10,\n",
       "            11,\n",
       "            12,\n",
       "            13,\n",
       "            14,\n",
       "            15,\n",
       "            16,\n",
       "            17,\n",
       "            18,\n",
       "            19,\n",
       "            20,\n",
       "            21,\n",
       "            22,\n",
       "            23,\n",
       "            24,\n",
       "            25,\n",
       "            26,\n",
       "            27,\n",
       "            28,\n",
       "            29,\n",
       "            30,\n",
       "            31,\n",
       "            32,\n",
       "            33,\n",
       "            34,\n",
       "            35,\n",
       "            36,\n",
       "            37,\n",
       "            38,\n",
       "            39,\n",
       "            40,\n",
       "            41,\n",
       "            42,\n",
       "            43,\n",
       "            44,\n",
       "            45,\n",
       "            46,\n",
       "            47,\n",
       "            48,\n",
       "            49,\n",
       "            50,\n",
       "            51,\n",
       "            52,\n",
       "            53,\n",
       "            54,\n",
       "            55,\n",
       "            56,\n",
       "            57,\n",
       "            58,\n",
       "            59,\n",
       "            60,\n",
       "            61,\n",
       "            62,\n",
       "            63,\n",
       "            64,\n",
       "            65,\n",
       "            66,\n",
       "            67,\n",
       "            68,\n",
       "            69,\n",
       "            70,\n",
       "            71,\n",
       "            72,\n",
       "            73,\n",
       "            74,\n",
       "            75,\n",
       "            76,\n",
       "            77,\n",
       "            78,\n",
       "            79,\n",
       "            80,\n",
       "            81,\n",
       "            82,\n",
       "            83,\n",
       "            84,\n",
       "            85,\n",
       "            86,\n",
       "            87,\n",
       "            88,\n",
       "            89,\n",
       "            90,\n",
       "            91,\n",
       "            92,\n",
       "            93,\n",
       "            94,\n",
       "            95,\n",
       "            96,\n",
       "            97,\n",
       "            98,\n",
       "            99,\n",
       "            100,\n",
       "            101,\n",
       "            102,\n",
       "            103,\n",
       "            104,\n",
       "            105,\n",
       "            106,\n",
       "            107,\n",
       "            108,\n",
       "            109,\n",
       "            110,\n",
       "            111,\n",
       "            112,\n",
       "            113,\n",
       "            114,\n",
       "            115,\n",
       "            116,\n",
       "            117,\n",
       "            118,\n",
       "            119,\n",
       "            120,\n",
       "            121,\n",
       "            122,\n",
       "            123,\n",
       "            124,\n",
       "            125,\n",
       "            126,\n",
       "            127,\n",
       "            128,\n",
       "            129,\n",
       "            130,\n",
       "            131,\n",
       "            132,\n",
       "            133,\n",
       "            134,\n",
       "            135,\n",
       "            136,\n",
       "            137,\n",
       "            138,\n",
       "            139,\n",
       "            140,\n",
       "            141,\n",
       "            142,\n",
       "            143,\n",
       "            144,\n",
       "            145,\n",
       "            146,\n",
       "            147,\n",
       "            148,\n",
       "            149,\n",
       "            150,\n",
       "            151,\n",
       "            152,\n",
       "            153,\n",
       "            154,\n",
       "            155,\n",
       "            156,\n",
       "            157,\n",
       "            158,\n",
       "            159,\n",
       "            160,\n",
       "            161,\n",
       "            162,\n",
       "            163,\n",
       "            164,\n",
       "            165,\n",
       "            166,\n",
       "            167,\n",
       "            168,\n",
       "            169,\n",
       "            170,\n",
       "            171,\n",
       "            172,\n",
       "            173,\n",
       "            174,\n",
       "            175,\n",
       "            176,\n",
       "            177,\n",
       "            178,\n",
       "            179,\n",
       "            180,\n",
       "            181,\n",
       "            182,\n",
       "            183,\n",
       "            184,\n",
       "            185,\n",
       "            186,\n",
       "            187,\n",
       "            188,\n",
       "            189,\n",
       "            190,\n",
       "            191,\n",
       "            192,\n",
       "            193,\n",
       "            194,\n",
       "            195,\n",
       "            196,\n",
       "            197,\n",
       "            198,\n",
       "            199,\n",
       "            200,\n",
       "            201,\n",
       "            202,\n",
       "            203,\n",
       "            204,\n",
       "            205,\n",
       "            206,\n",
       "            207,\n",
       "            208,\n",
       "            209,\n",
       "            210,\n",
       "            211,\n",
       "            212,\n",
       "            213,\n",
       "            214,\n",
       "            215,\n",
       "            216,\n",
       "            217,\n",
       "            218,\n",
       "            219\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"y1\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"y1\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(0, 154, 250, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            100.0,\n",
       "            75.0,\n",
       "            56.0,\n",
       "            52.0,\n",
       "            53.0,\n",
       "            54.0,\n",
       "            55.0,\n",
       "            56.0,\n",
       "            57.0,\n",
       "            58.0,\n",
       "            58.0,\n",
       "            58.0,\n",
       "            116.0,\n",
       "            232.0,\n",
       "            174.0,\n",
       "            130.0,\n",
       "            260.0,\n",
       "            195.0,\n",
       "            146.0,\n",
       "            146.0,\n",
       "            214.0,\n",
       "            220.0,\n",
       "            165.0,\n",
       "            165.0,\n",
       "            232.0,\n",
       "            174.0,\n",
       "            130.0,\n",
       "            260.0,\n",
       "            200.0,\n",
       "            400.0,\n",
       "            323.0,\n",
       "            646.0,\n",
       "            1034.0,\n",
       "            775.0,\n",
       "            581.0,\n",
       "            435.0,\n",
       "            582.0,\n",
       "            745.0,\n",
       "            558.0,\n",
       "            487.0,\n",
       "            974.0,\n",
       "            730.0,\n",
       "            1460.0,\n",
       "            1095.0,\n",
       "            1626.0,\n",
       "            1566.0,\n",
       "            2145.0,\n",
       "            1608.0,\n",
       "            1206.0,\n",
       "            1303.0,\n",
       "            2062.0,\n",
       "            4124.0,\n",
       "            3093.0,\n",
       "            2319.0,\n",
       "            2319.0,\n",
       "            1739.0,\n",
       "            3478.0,\n",
       "            2608.0,\n",
       "            3435.0,\n",
       "            2677.0,\n",
       "            2756.0,\n",
       "            2067.0,\n",
       "            2783.0,\n",
       "            2087.0,\n",
       "            1565.0,\n",
       "            2468.0,\n",
       "            2274.0,\n",
       "            2157.0,\n",
       "            2680.0,\n",
       "            5360.0,\n",
       "            4020.0,\n",
       "            4109.0,\n",
       "            3352.0,\n",
       "            3530.0,\n",
       "            2647.0,\n",
       "            5294.0,\n",
       "            3970.0,\n",
       "            7940.0,\n",
       "            5955.0,\n",
       "            11910.0,\n",
       "            8932.0,\n",
       "            6699.0,\n",
       "            5396.0,\n",
       "            4173.0,\n",
       "            3129.0,\n",
       "            3189.0,\n",
       "            2391.0,\n",
       "            4782.0,\n",
       "            3586.0,\n",
       "            7172.0,\n",
       "            5379.0,\n",
       "            10758.0,\n",
       "            21516.0,\n",
       "            16137.0,\n",
       "            12102.0,\n",
       "            9076.0,\n",
       "            18152.0,\n",
       "            13614.0,\n",
       "            27228.0,\n",
       "            33221.0,\n",
       "            24915.0,\n",
       "            18686.0,\n",
       "            37372.0,\n",
       "            28029.0,\n",
       "            21021.0,\n",
       "            42042.0,\n",
       "            74093.0,\n",
       "            55569.0,\n",
       "            41676.0,\n",
       "            31257.0,\n",
       "            62514.0,\n",
       "            92681.0,\n",
       "            69510.0,\n",
       "            52132.0,\n",
       "            39099.0,\n",
       "            66009.0,\n",
       "            115266.0,\n",
       "            86449.0,\n",
       "            64836.0,\n",
       "            91252.0,\n",
       "            68439.0,\n",
       "            86027.0,\n",
       "            64520.0,\n",
       "            78563.0,\n",
       "            58922.0,\n",
       "            44191.0,\n",
       "            33143.0,\n",
       "            24857.0,\n",
       "            18642.0,\n",
       "            37284.0,\n",
       "            50827.0,\n",
       "            64529.0,\n",
       "            48396.0,\n",
       "            50554.0,\n",
       "            78152.0,\n",
       "            58614.0,\n",
       "            43960.0,\n",
       "            87920.0,\n",
       "            65940.0,\n",
       "            49455.0,\n",
       "            98910.0,\n",
       "            74182.0,\n",
       "            103939.0,\n",
       "            91289.0,\n",
       "            168714.0,\n",
       "            126535.0,\n",
       "            94901.0,\n",
       "            189802.0,\n",
       "            142351.0,\n",
       "            164624.0,\n",
       "            123468.0,\n",
       "            92601.0,\n",
       "            185202.0,\n",
       "            212398.0,\n",
       "            159298.0,\n",
       "            119473.0,\n",
       "            89604.0,\n",
       "            67203.0,\n",
       "            50402.0,\n",
       "            37801.0,\n",
       "            63407.0,\n",
       "            126814.0,\n",
       "            95110.0,\n",
       "            71332.0,\n",
       "            94530.0,\n",
       "            105568.0,\n",
       "            79176.0,\n",
       "            59382.0,\n",
       "            118764.0,\n",
       "            89073.0,\n",
       "            66804.0,\n",
       "            50103.0,\n",
       "            100206.0,\n",
       "            75154.0,\n",
       "            56365.0,\n",
       "            112730.0,\n",
       "            84547.0,\n",
       "            63410.0,\n",
       "            126820.0,\n",
       "            135691.0,\n",
       "            101768.0,\n",
       "            76326.0,\n",
       "            57244.0,\n",
       "            68662.0,\n",
       "            77754.0,\n",
       "            155508.0,\n",
       "            116631.0,\n",
       "            87473.0,\n",
       "            134529.0,\n",
       "            100896.0,\n",
       "            201792.0,\n",
       "            151344.0,\n",
       "            302688.0,\n",
       "            227016.0,\n",
       "            170262.0,\n",
       "            127696.0,\n",
       "            182574.0,\n",
       "            136930.0,\n",
       "            128799.0,\n",
       "            96599.0,\n",
       "            129509.0,\n",
       "            218199.0,\n",
       "            163649.0,\n",
       "            122736.0,\n",
       "            245472.0,\n",
       "            184104.0,\n",
       "            150548.0,\n",
       "            112911.0,\n",
       "            188454.0,\n",
       "            141340.0,\n",
       "            106005.0,\n",
       "            151089.0,\n",
       "            215873.0,\n",
       "            321374.0,\n",
       "            241030.0,\n",
       "            180772.0,\n",
       "            135579.0,\n",
       "            193609.0,\n",
       "            197646.0\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    }\n",
       "]\n",
       ", {\n",
       "    \"showlegend\": true,\n",
       "    \"xaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            0.0,\n",
       "            50.0,\n",
       "            100.0,\n",
       "            150.0,\n",
       "            200.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            -5.54,\n",
       "            225.54\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.08063575386410031,\n",
       "            0.9934383202099737\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"0\",\n",
       "            \"50\",\n",
       "            \"100\",\n",
       "            \"150\",\n",
       "            \"200\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"y1\"\n",
       "    },\n",
       "    \"paper_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"annotations\": [],\n",
       "    \"height\": 400,\n",
       "    \"margin\": {\n",
       "        \"l\": 0,\n",
       "        \"b\": 20,\n",
       "        \"r\": 0,\n",
       "        \"t\": 20\n",
       "    },\n",
       "    \"plot_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"yaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            0.0,\n",
       "            100000.0,\n",
       "            200000.0,\n",
       "            300000.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            -9587.66,\n",
       "            331013.66\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.03762029746281716,\n",
       "            0.9901574803149606\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"0\",\n",
       "            \"1×10⁵\",\n",
       "            \"2×10⁵\",\n",
       "            \"3×10⁵\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"x1\"\n",
       "    },\n",
       "    \"legend\": {\n",
       "        \"tracegroupgap\": 0,\n",
       "        \"bordercolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "        \"font\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"y\": 1.0,\n",
       "        \"x\": 1.0\n",
       "    },\n",
       "    \"width\": 600\n",
       "}\n",
       ");\n",
       "    </script>\n",
       "\n",
       "    </body>\n",
       "</html>\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(samplingBHHHshs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "proved-arthur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 0 -- Inexact Restoration : \n",
      "------ INEXACT Restoration btr ---------- : \n",
      " --- sampling : Geraldine.InexactRestoration{Geraldine.IndComRN,Int64}\n",
      "-------------------------\n",
      "initializeState! AbstractStochasticModel -- Inexact Restoration\n",
      "initializeSampling InexactRestoration! Ind / Com RN\n",
      "\n",
      "k = 0 -> 1\n",
      "N previous = 100\n",
      "N tilde = 120\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 120\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 100\n",
      "Length shu = 100\n",
      "- Increase !! with 20\n",
      "N = 120\n",
      "Length shu N = 120\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 0  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.3327794167451117\n",
      "κ = 0.03732634367380849\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.1476686381715282\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1\n",
      "1.6094379124340996\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 1 -> 2\n",
      "N previous = 120\n",
      "N tilde = 144\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 144\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 120\n",
      "Length shu = 120\n",
      "- Increase !! with 24\n",
      "N = 144\n",
      "Length shu N = 144\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 1  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 0.07761137695927656\n",
      "κ = 0.013748931842748889\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0111601067411684\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "0.7068602943700546\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 2 -> 3\n",
      "N previous = 144\n",
      "N tilde = 173\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 173\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 144\n",
      "Length shu = 144\n",
      "- Increase !! with 29\n",
      "N = 173\n",
      "Length shu N = 173\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 2  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 0.011499600938373856\n",
      "κ = 0.0038974039109710285\n",
      "κ = 0.0011832685031271516\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0234816781635805\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "0.4330514624172602\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 3 -> 4\n",
      "N previous = 173\n",
      "N tilde = 208\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 208\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 173\n",
      "Length shu = 173\n",
      "- Increase !! with 35\n",
      "N = 208\n",
      "Length shu N = 208\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 3  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 0.0015909894877139986\n",
      "κ = 0.0007441743594115828\n",
      "κ = 0.0012421510119461454\n",
      "κ = 0.00025064997645022187\n",
      "κ = 0.0001402591806470148\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.009898829944983\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "0.2615965633643919\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 4 -> 5\n",
      "N previous = 208\n",
      "N tilde = 250\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 250\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 208\n",
      "Length shu = 208\n",
      "- Increase !! with 42\n",
      "N = 250\n",
      "Length shu N = 250\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 4  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 0.0004838347842141493\n",
      "κ = 0.00029052779456369517\n",
      "κ = 0.00013601186621885268\n",
      "κ = 0.00018509018738320585\n",
      "κ = 0.00014224280888670634\n",
      "κ = 7.967625385609163e-5\n",
      "κ = 6.818754488605617e-6\n",
      "TCG stoped on iteration 7\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0058216902637322\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "0.1620300427302098\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 5 -> 6\n",
      "N previous = 250\n",
      "N tilde = 300\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 300\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 250\n",
      "Length shu = 250\n",
      "- Increase !! with 50\n",
      "N = 300\n",
      "Length shu N = 300\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 5  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 5.021712413765348e-5\n",
      "κ = 4.4241861792211946e-5\n",
      "κ = 2.4649431199106207e-5\n",
      "κ = 1.1037456249915553e-5\n",
      "κ = 5.5177184665349835e-5\n",
      "κ = 6.586782452905477e-5\n",
      "κ = 5.8392757010854826e-6\n",
      "κ = 6.735824681917151e-7\n",
      "TCG stoped on iteration 8\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9994846597293738\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "0.10492021848435693\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 6 -> 7\n",
      "N previous = 300\n",
      "N tilde = 360\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 360\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 300\n",
      "Length shu = 300\n",
      "- Increase !! with 60\n",
      "N = 360\n",
      "Length shu N = 360\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 6  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.7935278168727618e-5\n",
      "κ = 1.613981240880701e-5\n",
      "κ = 4.836104211433419e-6\n",
      "κ = 2.5645984500843535e-6\n",
      "κ = 7.059915171897987e-7\n",
      "κ = 3.003820163327609e-7\n",
      "κ = 4.146651250660326e-6\n",
      "κ = 6.105295037318677e-6\n",
      "κ = 5.952221296377182e-7\n",
      "κ = 2.1596220052916774e-7\n",
      "TCG stoped on iteration 10\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9989269421057355\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "0.061221113149814196\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 7 -> 8\n",
      "N previous = 360\n",
      "N tilde = 432\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 432\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 360\n",
      "Length shu = 360\n",
      "- Increase !! with 72\n",
      "N = 432\n",
      "Length shu N = 432\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 7  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.3219052742080355e-5\n",
      "κ = 5.150905145641559e-6\n",
      "κ = 1.4555299247434688e-6\n",
      "κ = 7.530345507637196e-7\n",
      "κ = 3.3389260050035294e-8\n",
      "κ = 3.0152341402548144e-8\n",
      "κ = 2.2719474258886875e-7\n",
      "κ = 1.2049763504260695e-6\n",
      "κ = 1.1361326840386784e-7\n",
      "TCG stoped on iteration 9\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9994972524077498\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "0.04511775856106371\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 8 -> 9\n",
      "N previous = 432\n",
      "N tilde = 519\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 519\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 432\n",
      "Length shu = 432\n",
      "- Increase !! with 87\n",
      "N = 519\n",
      "Length shu N = 519\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 8  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.5460159931597297e-5\n",
      "κ = 1.1875257249435602e-6\n",
      "κ = 1.455953663134885e-6\n",
      "κ = 3.638884462663403e-7\n",
      "κ = 1.4616697213035812e-7\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9977099981956967\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "0.04699916020685045\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 9 -> 10\n",
      "N previous = 519\n",
      "N tilde = 623\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 623\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 519\n",
      "Length shu = 519\n",
      "- Increase !! with 104\n",
      "N = 623\n",
      "Length shu N = 623\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 9  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.6374870541336245e-5\n",
      "κ = 2.2714361221390633e-6\n",
      "κ = 1.2804367185020248e-6\n",
      "κ = 1.2571607700650633e-7\n",
      "κ = 7.112937843181825e-8\n",
      "TCG stoped on iteration 5\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9987360166583527\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "0.042739646545856574\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 10 -> 11\n",
      "N previous = 623\n",
      "N tilde = 748\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 748\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 623\n",
      "Length shu = 623\n",
      "- Increase !! with 125\n",
      "N = 748\n",
      "Length shu N = 748\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 10  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 6.4178590315883755e-6\n",
      "κ = 1.4471797850389145e-6\n",
      "κ = 4.674928001396503e-7\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.998916103423576\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11\n",
      "0.040447395134919586\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 11 -> 12\n",
      "N previous = 748\n",
      "N tilde = 898\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 898\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 748\n",
      "Length shu = 748\n",
      "- Increase !! with 150\n",
      "N = 898\n",
      "Length shu N = 898\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 11  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 8.986100878582894e-6\n",
      "κ = 1.9884644982018893e-6\n",
      "κ = 6.272215623348743e-8\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9992452781914957\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12\n",
      "0.04428949820131442\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 12 -> 13\n",
      "N previous = 898\n",
      "N tilde = 1078\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 1078\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 898\n",
      "Length shu = 898\n",
      "- Increase !! with 180\n",
      "N = 1078\n",
      "Length shu N = 1078\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 12  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.7115553709412185e-6\n",
      "κ = 1.6530284813955023e-7\n",
      "κ = 3.070156059416557e-8\n",
      "κ = 5.928115474634857e-9\n",
      "κ = 4.931344324864539e-9\n",
      "κ = 4.444579656678009e-9\n",
      "κ = 3.783601813971758e-8\n",
      "κ = 1.3926517044650943e-7\n",
      "κ = 3.197795251755614e-8\n",
      "TCG stoped on iteration 9\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.000136377261464\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13\n",
      "0.03974318593942984\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 13 -> 14\n",
      "N previous = 1078\n",
      "N tilde = 1294\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 1294\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 1078\n",
      "Length shu = 1078\n",
      "- Increase !! with 216\n",
      "N = 1294\n",
      "Length shu N = 1294\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 13  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.7313969418301542e-6\n",
      "κ = 3.726342402802901e-7\n",
      "κ = 1.860346012675897e-7\n",
      "κ = 4.543972382839717e-8\n",
      "TCG stoped on iteration 4\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9993619985277079\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14\n",
      "0.0422717957335749\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 14 -> 15\n",
      "N previous = 1294\n",
      "N tilde = 1553\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 1553\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 1294\n",
      "Length shu = 1294\n",
      "- Increase !! with 259\n",
      "N = 1553\n",
      "Length shu N = 1553\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 14  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 7.834439726875657e-7\n",
      "κ = 4.769481060563767e-7\n",
      "κ = 4.148771393041298e-8\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9991476647740364\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15\n",
      "0.0424061022466032\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 15 -> 16\n",
      "N previous = 1553\n",
      "N tilde = 1864\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 1864\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 1553\n",
      "Length shu = 1553\n",
      "- Increase !! with 311\n",
      "N = 1864\n",
      "Length shu N = 1864\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 15  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.8848495703243297e-6\n",
      "κ = 4.046759081899723e-7\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9997694308011964\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16\n",
      "0.04766834397420616\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 16 -> 17\n",
      "N previous = 1864\n",
      "N tilde = 2237\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 2237\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 1864\n",
      "Length shu = 1864\n",
      "- Increase !! with 373\n",
      "N = 2237\n",
      "Length shu N = 2237\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 16  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 3.6184063079597166e-7\n",
      "κ = 5.212151208912645e-8\n",
      "κ = 6.222557431572751e-9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999964001696345\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17\n",
      "0.047487385217154156\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 17 -> 18\n",
      "N previous = 2237\n",
      "N tilde = 2685\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 2685\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 2237\n",
      "Length shu = 2237\n",
      "- Increase !! with 448\n",
      "N = 2685\n",
      "Length shu N = 2685\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 17  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 3.633125876858368e-7\n",
      "κ = 6.30570342424198e-8\n",
      "κ = 7.393019807930397e-9\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9998723059393209\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18\n",
      "0.04854412247923557\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 18 -> 19\n",
      "N previous = 2685\n",
      "N tilde = 3222\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 3222\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 2685\n",
      "Length shu = 2685\n",
      "- Increase !! with 537\n",
      "N = 3222\n",
      "Length shu N = 3222\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 18  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 5.919807520786572e-7\n",
      "κ = 2.677306241405399e-8\n",
      "κ = 1.195515360105892e-8\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9997341860102078\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19\n",
      "0.04532560643710457\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 19 -> 20\n",
      "N previous = 3222\n",
      "N tilde = 3867\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 3867\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 3222\n",
      "Length shu = 3222\n",
      "- Increase !! with 645\n",
      "N = 3867\n",
      "Length shu N = 3867\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 19  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 8.315213964924688e-7\n",
      "κ = 7.752909385512674e-8\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999929110539981\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 20\n",
      "0.044433142152460074\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 20 -> 21\n",
      "N previous = 3867\n",
      "N tilde = 4641\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 4641\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 3867\n",
      "Length shu = 3867\n",
      "- Increase !! with 774\n",
      "N = 4641\n",
      "Length shu N = 4641\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 20  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 4.362156713926629e-7\n",
      "κ = 4.5372115132192916e-8\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999984979049914\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 21\n",
      "0.04537241784164432\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 21 -> 22\n",
      "N previous = 4641\n",
      "N tilde = 5570\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 5570\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 4641\n",
      "Length shu = 4641\n",
      "- Increase !! with 929\n",
      "N = 5570\n",
      "Length shu N = 5570\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 21  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.7368532530416667e-7\n",
      "κ = 1.711662106467023e-8\n",
      "κ = 1.1027402816005708e-9\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999902459554436\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 22\n",
      "0.04564668141980862\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 22 -> 23\n",
      "N previous = 5570\n",
      "N tilde = 6684\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 6684\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 5570\n",
      "Length shu = 5570\n",
      "- Increase !! with 1114\n",
      "N = 6684\n",
      "Length shu N = 6684\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 22  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.1244483544302594e-7\n",
      "κ = 4.759358560211156e-9\n",
      "κ = 1.9873738550364785e-10\n",
      "κ = 8.683824064432032e-11\n",
      "κ = 1.6302890117735047e-9\n",
      "κ = 6.030386257786799e-8\n",
      "κ = 1.2876209740130545e-9\n",
      "TCG stoped on iteration 7\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0000151401461281\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 23\n",
      "0.04527905958680298\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 23 -> 24\n",
      "N previous = 6684\n",
      "N tilde = 8021\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 8021\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 6684\n",
      "Length shu = 6684\n",
      "- Increase !! with 1337\n",
      "N = 8021\n",
      "Length shu N = 8021\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 23  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.287435558036164e-7\n",
      "κ = 3.630783632363027e-9\n",
      "κ = 3.5824454715721934e-10\n",
      "TCG stoped on iteration 3\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999868034072777\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 24\n",
      "0.04564702187848836\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 24 -> 25\n",
      "N previous = 8021\n",
      "N tilde = 9626\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 9626\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 8021\n",
      "Length shu = 8021\n",
      "- Increase !! with 1605\n",
      "N = 9626\n",
      "Length shu N = 9626\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 24  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 4.656022385433798e-8\n",
      "κ = 1.872731110115354e-9\n",
      "κ = 1.106332473069564e-10\n",
      "κ = 1.1793421165267429e-11\n",
      "κ = 2.386468842835056e-11\n",
      "κ = 9.641030031638024e-9\n",
      "κ = 5.865790278810932e-10\n",
      "TCG stoped on iteration 7\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999955312578009\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 25\n",
      "0.0478821984280334\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 25 -> 26\n",
      "N previous = 9626\n",
      "N tilde = 11552\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 11552\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 9626\n",
      "Length shu = 9626\n",
      "- Increase !! with 1926\n",
      "N = 11552\n",
      "Length shu N = 11552\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 25  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.3986386141438928e-7\n",
      "κ = 4.336950111665947e-9\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999993405729337\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 26\n",
      "0.0468390145554403\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 26 -> 27\n",
      "N previous = 11552\n",
      "N tilde = 13863\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 13863\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 11552\n",
      "Length shu = 11552\n",
      "- Increase !! with 2311\n",
      "N = 13863\n",
      "Length shu N = 13863\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 26  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.0789274265680641e-7\n",
      "κ = 6.536693013446132e-9\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.999980397296281\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 27\n",
      "0.04648859168411187\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 27 -> 28\n",
      "N previous = 13863\n",
      "N tilde = 16636\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 16636\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 13863\n",
      "Length shu = 13863\n",
      "- Increase !! with 2773\n",
      "N = 16636\n",
      "Length shu N = 16636\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 27  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 5.50795280144121e-8\n",
      "κ = 1.6632423614629553e-9\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999982426433073\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 28\n",
      "0.046218870321302064\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 28 -> 29\n",
      "N previous = 16636\n",
      "N tilde = 19964\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 19964\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 16636\n",
      "Length shu = 16636\n",
      "- Increase !! with 3328\n",
      "N = 19964\n",
      "Length shu N = 19964\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 28  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 7.334974144752605e-8\n",
      "κ = 1.6054432875845182e-9\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999973836558658\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 29\n",
      "0.04590728867946906\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 29 -> 30\n",
      "N previous = 19964\n",
      "N tilde = 23957\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 23957\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 19964\n",
      "Length shu = 19964\n",
      "- Increase !! with 3993\n",
      "N = 23957\n",
      "Length shu N = 23957\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 29  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 4.682431849734663e-8\n",
      "κ = 1.2679237857405433e-9\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0000004909114897\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 30\n",
      "0.0454968780874936\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 30 -> 31\n",
      "N previous = 23957\n",
      "N tilde = 28749\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 28749\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 23957\n",
      "Length shu = 23957\n",
      "- Increase !! with 4792\n",
      "N = 28749\n",
      "Length shu N = 28749\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 30  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 6.551592355113308e-8\n",
      "κ = 1.0230493011323404e-9\n",
      "κ = 2.4421244491243775e-11\n",
      "κ = 4.273963809668086e-12\n",
      "κ = 1.9070401534349028e-9\n",
      "κ = 2.5891582357125287e-9\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0000023834511667\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 31\n",
      "0.04455962703299499\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 31 -> 32\n",
      "N previous = 28749\n",
      "N tilde = 34499\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 34499\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 28749\n",
      "Length shu = 28749\n",
      "- Increase !! with 5750\n",
      "N = 34499\n",
      "Length shu N = 34499\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 31  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 3.6578709539184166e-8\n",
      "κ = 5.374481562619057e-10\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999987879312114\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 32\n",
      "0.04423526801749126\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 32 -> 33\n",
      "N previous = 34499\n",
      "N tilde = 41399\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 41399\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 34499\n",
      "Length shu = 34499\n",
      "- Increase !! with 6900\n",
      "N = 41399\n",
      "Length shu N = 41399\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 32  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.48375160401797e-8\n",
      "κ = 6.139624446337083e-10\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.999998542232692\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 33\n",
      "0.044801347093890324\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 33 -> 34\n",
      "N previous = 41399\n",
      "N tilde = 49679\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 49679\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 41399\n",
      "Length shu = 41399\n",
      "- Increase !! with 8280\n",
      "N = 49679\n",
      "Length shu N = 49679\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 33  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 3.223560601976308e-8\n",
      "κ = 2.9462981343015657e-10\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999993002584893\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 34\n",
      "0.04426970444585274\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 34 -> 35\n",
      "N previous = 49679\n",
      "N tilde = 59615\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 59615\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 49679\n",
      "Length shu = 49679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Increase !! with 9936\n",
      "N = 59615\n",
      "Length shu N = 59615\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 34  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 3.401755675956129e-8\n",
      "κ = 2.0601789761650701e-10\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999994368345821\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 35\n",
      "0.044125971216770116\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 35 -> 36\n",
      "N previous = 59615\n",
      "N tilde = 71538\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 71538\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 59615\n",
      "Length shu = 59615\n",
      "- Increase !! with 11923\n",
      "N = 71538\n",
      "Length shu N = 71538\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 35  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.883728938702614e-8\n",
      "κ = 1.2107373785217117e-10\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0000002136559138\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 36\n",
      "0.04405156975687844\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 36 -> 37\n",
      "N previous = 71538\n",
      "N tilde = 85846\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 85846\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 71538\n",
      "Length shu = 71538\n",
      "- Increase !! with 14308\n",
      "N = 85846\n",
      "Length shu N = 85846\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 36  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.53926816826322e-8\n",
      "κ = 1.8724906682866475e-10\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999998955547499\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 37\n",
      "0.04398049946376782\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 37 -> 38\n",
      "N previous = 85846\n",
      "N tilde = 103016\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 103016\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 85846\n",
      "Length shu = 85846\n",
      "- Increase !! with 17170\n",
      "N = 103016\n",
      "Length shu N = 103016\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 37  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.9662316064229174e-8\n",
      "κ = 2.9564650138777873e-10\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999993171320052\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 38\n",
      "0.04394476312616806\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 38 -> 39\n",
      "N previous = 103016\n",
      "N tilde = 123620\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 123620\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 103016\n",
      "Length shu = 103016\n",
      "- Increase !! with 20604\n",
      "N = 123620\n",
      "Length shu N = 123620\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 38  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.7134299228555386e-8\n",
      "κ = 8.823035439612837e-11\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0000003385469303\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 39\n",
      "0.04427853574969267\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 39 -> 40\n",
      "N previous = 123620\n",
      "N tilde = 148344\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 148344\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 123620\n",
      "Length shu = 123620\n",
      "- Increase !! with 24724\n",
      "N = 148344\n",
      "Length shu N = 148344\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 39  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 3.305925954206269e-9\n",
      "κ = 3.7920682788682434e-11\n",
      "κ = 5.414333889938092e-13\n",
      "κ = 4.040397843703831e-12\n",
      "κ = 1.3988164845307536e-9\n",
      "κ = 2.798534781462566e-11\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.000000015738769\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 40\n",
      "0.04428007531534957\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 40 -> 41\n",
      "N previous = 148344\n",
      "N tilde = 178013\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 178013\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 148344\n",
      "Length shu = 148344\n",
      "- Increase !! with 29669\n",
      "N = 178013\n",
      "Length shu N = 178013\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 40  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 5.653514710597266e-9\n",
      "κ = 3.071998744364919e-11\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999999731537528\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 41\n",
      "0.04420282872586861\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 41 -> 42\n",
      "N previous = 178013\n",
      "N tilde = 213616\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 213616\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 178013\n",
      "Length shu = 178013\n",
      "- Increase !! with 35603\n",
      "N = 213616\n",
      "Length shu N = 213616\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 41  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.3691030804991494e-9\n",
      "κ = 1.9222347575838204e-11\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.000000004950712\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 42\n",
      "0.044360460699794796\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 42 -> 43\n",
      "N previous = 213616\n",
      "N tilde = 256340\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 256340\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 213616\n",
      "Length shu = 213616\n",
      "- Increase !! with 42724\n",
      "N = 256340\n",
      "Length shu N = 256340\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 42  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.3725876118343007e-9\n",
      "κ = 1.5769345870367325e-11\n",
      "κ = 2.4356811185969876e-13\n",
      "κ = 6.1777185401575505e-15\n",
      "κ = 1.2829623710730872e-11\n",
      "κ = 9.11036891901459e-12\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0000000024641467\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 43\n",
      "0.04431672556753444\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 43 -> 44\n",
      "N previous = 256340\n",
      "N tilde = 307608\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 307608\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 256340\n",
      "Length shu = 256340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Increase !! with 51268\n",
      "N = 307608\n",
      "Length shu N = 307608\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 43  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.4856517950589158e-9\n",
      "κ = 2.2852854875505696e-11\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.0000000313080428\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 44\n",
      "0.04420633755028145\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 44 -> 45\n",
      "N previous = 307608\n",
      "N tilde = 369130\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 369130\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 307608\n",
      "Length shu = 307608\n",
      "- Increase !! with 61522\n",
      "N = 369130\n",
      "Length shu N = 369130\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 44  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 6.5995150620993524e-9\n",
      "κ = 6.476899368275733e-11\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999999475770995\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 45\n",
      "0.04409948092839298\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 45 -> 46\n",
      "N previous = 369130\n",
      "N tilde = 442956\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 442956\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 369130\n",
      "Length shu = 369130\n",
      "- Increase !! with 73826\n",
      "N = 442956\n",
      "Length shu N = 442956\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 45  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 9.009301461865394e-10\n",
      "κ = 2.5588049726033882e-11\n",
      "κ = 1.9646557662823207e-13\n",
      "κ = 6.18772595708815e-14\n",
      "κ = 1.234326904913071e-10\n",
      "κ = 4.594537582106468e-12\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999999627251012\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 46\n",
      "0.044007232708638246\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 46 -> 47\n",
      "N previous = 442956\n",
      "N tilde = 531548\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 531548\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 442956\n",
      "Length shu = 442956\n",
      "- Increase !! with 88592\n",
      "N = 531548\n",
      "Length shu N = 531548\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 46  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 2.5696117479411585e-9\n",
      "κ = 2.3719035158118445e-11\n",
      "κ = 3.668835003009364e-13\n",
      "κ = 1.4742670949499115e-13\n",
      "κ = 1.0119147578356994e-10\n",
      "κ = 2.7127968364686035e-11\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999999999943417\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 47\n",
      "0.04441280267987212\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 47 -> 48\n",
      "N previous = 531548\n",
      "N tilde = 637858\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 637858\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 531548\n",
      "Length shu = 531548\n",
      "- Increase !! with 106310\n",
      "N = 637858\n",
      "Length shu N = 637858\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 47  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.5495673645016146e-9\n",
      "κ = 7.549806521104015e-12\n",
      "κ = 8.511048686042349e-14\n",
      "κ = 1.4583543409534636e-13\n",
      "κ = 9.296535698843022e-11\n",
      "κ = 1.4563590845368199e-12\n",
      "TCG stoped on iteration 6\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 1.000000027463184\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 48\n",
      "0.044561550620621344\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 48 -> 49\n",
      "N previous = 637858\n",
      "N tilde = 765430\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 765430\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 637858\n",
      "Length shu = 637858\n",
      "- Increase !! with 127572\n",
      "N = 765430\n",
      "Length shu N = 765430\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 48  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 3.0878690993882653e-9\n",
      "κ = 6.8909432065474915e-12\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999999718006385\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 49\n",
      "0.044540592657566304\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 49 -> 50\n",
      "N previous = 765430\n",
      "N tilde = 918516\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 918516\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 765430\n",
      "Length shu = 765430\n",
      "- Increase !! with 153086\n",
      "N = 918516\n",
      "Length shu N = 918516\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 49  and  max = 50\n",
      "computecand! AbstractStochasticModel -- Inexact Restoration\n",
      "--- TCG classic \n",
      "κ = 1.551889506685243e-9\n",
      "κ = 8.991565524541226e-12\n",
      "TCG stoped on iteration 2\n",
      "-------------------------\n",
      " - follow Up \n",
      "Step accpeted !!! ρ = 0.9999999850751307\n",
      " ---  END internal Loop \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 50\n",
      "0.04454319163403616\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "k = 50 -> 51\n",
      "N previous = 918516\n",
      "N tilde = 1000000\n",
      "\n",
      " ---  START internal Loop ---- \n",
      " ---- ------ internal Tau : 0 -------------------\n",
      "N final = 1000000\n",
      " --- updateSample ! InexactRestoration --- Ind / Common Variables\n",
      "Nprevious = 918516\n",
      "Length shu = 918516\n",
      "- Increase !! with 81484\n",
      "N = 1000000\n",
      "Length shu N = 1000000\n",
      "updateState! AbstractStochasticModel  -- Inexact Restoration\n",
      "Tests arret !!!!\n",
      " -- Optimality Inexact Restoration\n",
      "Nmax reached ? \n",
      "k = 50  and  max = 50\n",
      "nmaxReached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"here's a state\"\"here's an Accumulator\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "samplingStrategyIR = Geraldine.InexactRestoration{Geraldine.IndComRN}(Sofia.Nobs(mo), 1.2, \n",
    "                                                                     N0=N0, \n",
    "                                                                    subSampling=subSampling)\n",
    "\n",
    "# BTR\n",
    "accBtrIR =  Accum_2nd_full(xstar)\n",
    "\n",
    "sp = Geraldine.StopParam(;NMax = 50, TMax = 120.0, eps_g = epsOptimisation);\n",
    "\n",
    "btr =  Geraldine.BTRStruct(sp;Hessian = Geraldine.UncomputedHessian{Float64}, sam=typeof(samplingStrategyIR))\n",
    "\n",
    "state, accumulatorBtrIR = btr(mo, copy(x0), samplingStrategyIR, accumulator = accBtrIR, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "affected-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting results\n",
    "resultIR = Geraldine.structToDict(accumulatorBtrIR)\n",
    "\n",
    "samplingIR = resultIR[:SamplingSizeAccumulator]\n",
    "fIR = resultIR[:ValueAccumulator]\n",
    "paramIR = resultIR[:ParamAccumulator];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "smooth-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 10 entries:\n",
       "  :NormStepAccumulator                => [1.39442, 1.30267, 1.47623, 2.39774, 3…\n",
       "  :DeltaAccumulator                   => [10.0, 12.0, 14.4, 17.28, 20.736, 24.8…\n",
       "  Symbol(\"FieldAccumulator{Float64}\") => [2.0, 2.0, 3.0, 5.0, 7.0, 8.0, 10.0, 9…\n",
       "  :DistTo                             => [43.2435, 41.9419, 40.7975, 39.3594, 3…\n",
       "  :IsAcceptedAccumulator              => Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  …\n",
       "  :ValueAccumulator                   => [1.60944, 1.60944, 0.70686, 0.433051, …\n",
       "  :ParamAccumulator                   => Array{T,1} where T[[0.0, 0.0, 0.0, 0.0…\n",
       "  :SamplingSizeAccumulator            => ([100, 120, 144, 173, 208, 250, 300, 3…\n",
       "  :Times                              => [0.0, 0.313142, 0.629867, 0.910478, 1.…\n",
       "  :IterAccumulator                    => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9  …  41, …"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "serious-present",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip8400\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip8400)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip8401\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip8400)\" d=\"\n",
       "M261.188 1487.47 L2352.76 1487.47 L2352.76 47.2441 L261.188 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip8402\">\n",
       "    <rect x=\"261\" y=\"47\" width=\"2093\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  280.92,1487.47 280.92,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  675.555,1487.47 675.555,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1070.19,1487.47 1070.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1464.83,1487.47 1464.83,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1859.46,1487.47 1859.46,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2254.1,1487.47 2254.1,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  261.188,1446.86 2352.76,1446.86 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  261.188,1150.98 2352.76,1150.98 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  261.188,855.1 2352.76,855.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  261.188,559.219 2352.76,559.219 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  261.188,263.338 2352.76,263.338 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  261.188,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  261.188,1487.47 261.188,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  280.92,1487.47 280.92,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  675.555,1487.47 675.555,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1070.19,1487.47 1070.19,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1464.83,1487.47 1464.83,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1859.46,1487.47 1859.46,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2254.1,1487.47 2254.1,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  261.188,1446.86 286.287,1446.86 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  261.188,1150.98 286.287,1150.98 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  261.188,855.1 286.287,855.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  261.188,559.219 286.287,559.219 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  261.188,263.338 286.287,263.338 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 280.92, 1541.47)\" x=\"280.92\" y=\"1541.47\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 675.555, 1541.47)\" x=\"675.555\" y=\"1541.47\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1070.19, 1541.47)\" x=\"1070.19\" y=\"1541.47\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1464.83, 1541.47)\" x=\"1464.83\" y=\"1541.47\">30</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1859.46, 1541.47)\" x=\"1859.46\" y=\"1541.47\">40</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2254.1, 1541.47)\" x=\"2254.1\" y=\"1541.47\">50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 237.188, 1464.36)\" x=\"237.188\" y=\"1464.36\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 107.046, 1174.71)\" x=\"107.046\" y=\"1174.71\">2×10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 215.444, 1147.3)\" x=\"215.444\" y=\"1147.3\">5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 107.046, 878.827)\" x=\"107.046\" y=\"878.827\">4×10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 215.444, 851.417)\" x=\"215.444\" y=\"851.417\">5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 107.046, 582.947)\" x=\"107.046\" y=\"582.947\">6×10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 215.444, 555.536)\" x=\"215.444\" y=\"555.536\">5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 107.046, 287.066)\" x=\"107.046\" y=\"287.066\">8×10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 215.444, 259.656)\" x=\"215.444\" y=\"259.656\">5</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip8402)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  320.383,1446.71 359.847,1446.68 399.31,1446.65 438.774,1446.61 478.238,1446.55 517.701,1446.49 557.165,1446.42 596.628,1446.33 636.092,1446.22 675.555,1446.09 \n",
       "  715.019,1445.94 754.482,1445.75 793.946,1445.53 833.409,1445.27 872.873,1444.95 912.337,1444.56 951.8,1444.1 991.264,1443.55 1030.73,1442.89 1070.19,1442.09 \n",
       "  1109.65,1441.14 1149.12,1440 1188.58,1438.62 1228.04,1436.97 1267.51,1435 1306.97,1432.62 1346.44,1429.77 1385.9,1426.35 1425.36,1422.25 1464.83,1417.33 \n",
       "  1504.29,1411.42 1543.75,1404.33 1583.22,1395.82 1622.68,1385.62 1662.14,1373.37 1701.61,1358.67 1741.07,1341.03 1780.53,1319.86 1820,1294.46 1859.46,1263.98 \n",
       "  1898.93,1227.4 1938.39,1183.51 1977.85,1130.84 2017.32,1067.63 2056.78,991.785 2096.24,900.769 2135.71,791.551 2175.17,660.487 2214.63,503.212 2254.1,314.481 \n",
       "  2293.56,88.0053 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip8400)\" d=\"\n",
       "M1989.93 251.724 L2280.76 251.724 L2280.76 130.764 L1989.93 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.93,251.724 2280.76,251.724 2280.76,130.764 1989.93,130.764 1989.93,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8400)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.93,191.244 2157.93,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip8400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2181.93, 208.744)\" x=\"2181.93\" y=\"208.744\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(samplingIR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "attended-render",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip8800\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip8800)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip8801\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip8800)\" d=\"\n",
       "M247.807 1487.47 L2352.76 1487.47 L2352.76 47.2441 L247.807 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip8802\">\n",
       "    <rect x=\"247\" y=\"47\" width=\"2106\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  267.665,1487.47 267.665,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  664.825,1487.47 664.825,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1061.99,1487.47 1061.99,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1459.15,1487.47 1459.15,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1856.31,1487.47 1856.31,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2253.47,1487.47 2253.47,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  247.807,1446.86 2352.76,1446.86 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  247.807,1148.23 2352.76,1148.23 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  247.807,849.592 2352.76,849.592 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  247.807,550.956 2352.76,550.956 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  247.807,252.32 2352.76,252.32 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.807,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.807,1487.47 247.807,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  267.665,1487.47 267.665,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  664.825,1487.47 664.825,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1061.99,1487.47 1061.99,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1459.15,1487.47 1459.15,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1856.31,1487.47 1856.31,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2253.47,1487.47 2253.47,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.807,1446.86 273.066,1446.86 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.807,1148.23 273.066,1148.23 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.807,849.592 273.066,849.592 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.807,550.956 273.066,550.956 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  247.807,252.32 273.066,252.32 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 267.665, 1541.47)\" x=\"267.665\" y=\"1541.47\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 664.825, 1541.47)\" x=\"664.825\" y=\"1541.47\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1061.99, 1541.47)\" x=\"1061.99\" y=\"1541.47\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1459.15, 1541.47)\" x=\"1459.15\" y=\"1541.47\">30</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1856.31, 1541.47)\" x=\"1856.31\" y=\"1541.47\">40</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2253.47, 1541.47)\" x=\"2253.47\" y=\"1541.47\">50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 223.807, 1464.36)\" x=\"223.807\" y=\"1464.36\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 93.6653, 1171.95)\" x=\"93.6653\" y=\"1171.95\">2×10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 202.062, 1144.54)\" x=\"202.062\" y=\"1144.54\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 93.6653, 873.319)\" x=\"93.6653\" y=\"873.319\">4×10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 202.062, 845.909)\" x=\"202.062\" y=\"845.909\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 93.6653, 574.684)\" x=\"93.6653\" y=\"574.684\">6×10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 202.062, 547.273)\" x=\"202.062\" y=\"547.273\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 93.6653, 276.048)\" x=\"93.6653\" y=\"276.048\">8×10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 202.062, 248.638)\" x=\"202.062\" y=\"248.638\">4</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip8802)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  307.381,1446.71 347.097,1446.68 386.813,1446.65 426.529,1446.6 466.245,1446.55 505.961,1446.49 545.677,1446.42 585.393,1446.33 625.109,1446.22 664.825,1446.09 \n",
       "  704.541,1445.94 744.257,1445.75 783.973,1445.53 823.689,1445.27 863.405,1444.95 903.121,1444.56 942.837,1444.1 982.553,1443.55 1022.27,1442.89 1061.99,1442.09 \n",
       "  1101.7,1441.14 1141.42,1439.99 1181.13,1438.62 1220.85,1436.97 1260.57,1434.99 1300.28,1432.62 1340,1429.77 1379.71,1426.35 1419.43,1422.25 1459.15,1417.33 \n",
       "  1498.86,1411.42 1538.58,1404.33 1578.29,1395.82 1618.01,1385.61 1657.73,1373.37 1697.44,1358.67 1737.16,1341.03 1776.87,1319.86 1816.59,1294.46 1856.31,1263.98 \n",
       "  1896.02,1227.4 1935.74,1183.51 1975.45,1130.84 2015.17,1067.63 2054.89,991.784 2094.6,900.768 2134.32,791.55 2174.03,660.487 2213.75,503.212 2253.47,314.482 \n",
       "  2293.18,88.0053 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip8800)\" d=\"\n",
       "M1989.93 251.724 L2280.76 251.724 L2280.76 130.764 L1989.93 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.93,251.724 2280.76,251.724 2280.76,130.764 1989.93,130.764 1989.93,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip8800)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.93,191.244 2157.93,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip8800)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2181.93, 208.744)\" x=\"2181.93\" y=\"208.744\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(resultIR[:DeltaAccumulator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vocal-pakistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip9200\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip9200)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip9201\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip9200)\" d=\"\n",
       "M113.754 1487.47 L2352.76 1487.47 L2352.76 47.2441 L113.754 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip9202\">\n",
       "    <rect x=\"113\" y=\"47\" width=\"2240\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  134.015,1487.47 134.015,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  565.09,1487.47 565.09,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  996.164,1487.47 996.164,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1427.24,1487.47 1427.24,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1858.31,1487.47 1858.31,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2289.39,1487.47 2289.39,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  113.754,1448.18 2352.76,1448.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  113.754,1130.14 2352.76,1130.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  113.754,812.1 2352.76,812.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  113.754,494.058 2352.76,494.058 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  113.754,176.017 2352.76,176.017 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  113.754,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  113.754,1487.47 113.754,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  134.015,1487.47 134.015,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  565.09,1487.47 565.09,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  996.164,1487.47 996.164,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1427.24,1487.47 1427.24,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1858.31,1487.47 1858.31,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2289.39,1487.47 2289.39,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  113.754,1448.18 140.622,1448.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  113.754,1130.14 140.622,1130.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  113.754,812.1 140.622,812.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  113.754,494.058 140.622,494.058 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  113.754,176.017 140.622,176.017 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 134.015, 1541.47)\" x=\"134.015\" y=\"1541.47\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 565.09, 1541.47)\" x=\"565.09\" y=\"1541.47\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 996.164, 1541.47)\" x=\"996.164\" y=\"1541.47\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1427.24, 1541.47)\" x=\"1427.24\" y=\"1541.47\">30</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1858.31, 1541.47)\" x=\"1858.31\" y=\"1541.47\">40</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2289.39, 1541.47)\" x=\"2289.39\" y=\"1541.47\">50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 89.7545, 1465.68)\" x=\"89.7545\" y=\"1465.68\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 89.7545, 1147.64)\" x=\"89.7545\" y=\"1147.64\">2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 89.7545, 829.6)\" x=\"89.7545\" y=\"829.6\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 89.7545, 511.558)\" x=\"89.7545\" y=\"511.558\">6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 89.7545, 193.517)\" x=\"89.7545\" y=\"193.517\">8</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip9202)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  177.122,1226.44 220.23,1241.03 263.337,1213.43 306.445,1066.89 349.552,935.405 392.66,504.804 435.767,173.087 478.875,88.0053 521.982,1321.07 565.09,1344.64 \n",
       "  608.197,1360.67 651.304,1362.48 694.412,110.759 737.519,1354.22 780.627,1368.58 823.734,1380.69 866.842,1430.57 909.949,1415.11 953.057,1406.82 996.164,1418.17 \n",
       "  1039.27,1429.32 1082.38,1429.24 1125.49,845.517 1168.59,1432.02 1211.7,1121.18 1254.81,1436.33 1297.92,1433.02 1341.02,1439.5 1384.13,1438.39 1427.24,1441.48 \n",
       "  1470.35,1161.35 1513.45,1440.08 1556.56,1441.52 1599.67,1441.04 1642.78,1441.15 1685.88,1442.1 1728.99,1442.15 1772.1,1442.48 1815.21,1443.71 1858.31,1335.48 \n",
       "  1901.42,1445.4 1944.53,1446.42 1987.64,1426.47 2030.74,1446.46 2073.85,1445.15 2116.96,1407.57 2160.07,1395.28 2203.17,1414.84 2246.28,1446.09 2289.39,1446.71 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip9200)\" d=\"\n",
       "M1989.93 251.724 L2280.76 251.724 L2280.76 130.764 L1989.93 130.764  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.93,251.724 2280.76,251.724 2280.76,130.764 1989.93,130.764 1989.93,251.724 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9200)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.93,191.244 2157.93,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip9200)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2181.93, 208.744)\" x=\"2181.93\" y=\"208.744\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(resultIR[:NormStepAccumulator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "attended-rings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "BHHH sHs",
         "line": {
          "color": "rgba(0, 154, 250, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "BHHH sHs",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.028951099,
          0.031026,
          0.046391100000000005,
          0.1452564,
          0.30891280000000004,
          0.43125250000000004,
          0.5498359,
          0.7212557,
          0.8437945,
          0.9149322000000001,
          0.9213070000000001,
          1.1209484,
          1.2817927,
          1.2860497000000002,
          1.2889731,
          1.4560411000000002,
          1.4595765,
          1.5123583,
          1.514334799,
          1.6843022,
          1.8008465,
          1.878759,
          1.9159902990000002,
          2.0737358,
          2.0784138000000003,
          2.109887,
          2.2426001,
          2.3217861,
          2.4607755,
          2.4928903,
          2.7060979,
          2.8673978,
          2.9188357000000003,
          2.9598429000000004,
          2.9946921,
          3.1354713000000003,
          3.3215253000000002,
          3.4075921,
          3.4135421000000004,
          3.6062049000000003,
          3.6602147,
          3.8250037000000003,
          3.8481139000000004,
          4.0014859000000005,
          4.113540100000001,
          4.3638959,
          4.4281856,
          4.457624200000001,
          4.590722100000001,
          4.736018799,
          4.9618928,
          4.992293,
          5.0691844,
          5.075886199,
          5.121241099000001,
          5.2543785000000005,
          5.296353300000001,
          5.419961000000001,
          5.489815800000001,
          5.703805,
          5.774078,
          5.9139682,
          6.0668791,
          6.184329799,
          6.3563846,
          6.4154127,
          6.503029199,
          6.6810131,
          6.863114099000001,
          7.0019406,
          7.174456,
          7.2837003000000005,
          7.4083503,
          7.456937000000001,
          7.682263600000001,
          7.7911985,
          7.969227200000001,
          8.065038000000001,
          8.2698902,
          8.403718600000001,
          8.5425479,
          8.676073699,
          8.760623200000001,
          8.865948900000001,
          9.1326626,
          9.161282700000001,
          9.333368,
          9.4699924,
          9.6516239,
          9.7506623,
          9.925135200000001,
          10.3040417,
          10.4221456,
          10.564974300000001,
          10.6427783,
          10.9171581,
          11.055684600000001,
          11.4856052,
          11.9150305,
          12.229078299000001,
          12.447800500000001,
          12.925536899,
          13.284064999000002,
          13.5310103,
          14.033294600000001,
          14.7347838,
          15.2088885,
          15.6779951,
          16.005467799,
          16.5789186,
          17.352063700000002,
          18.007499000000003,
          18.499450299,
          18.816471200000002,
          19.454051699,
          20.3459788,
          21.118444200000003,
          21.6022921,
          22.541036299,
          23.149169500000003,
          24.0127841,
          24.589009400000002,
          25.3130853,
          25.898917200000003,
          26.377033200000003,
          26.735717500000003,
          26.9944385,
          27.2482526,
          27.7108035,
          28.3205646,
          28.985231399000003,
          29.432001900000003,
          29.9909517,
          30.712026400000003,
          31.2507948,
          31.677040700000003,
          32.467490899000005,
          33.194005799,
          33.6881871,
          34.514043499,
          35.1594895,
          36.0226532,
          36.801492999000004,
          38.1946061,
          39.2485611,
          40.0125137,
          41.4176056,
          42.612678499000005,
          44.089058199,
          45.231945199,
          46.0790396,
          47.5242379,
          49.2687851,
          50.56918700000001,
          51.6125929,
          52.459180399000005,
          53.1037334,
          53.5912458,
          53.967686400000005,
          54.6097849,
          55.64872020000001,
          56.463711700000005,
          57.102518199,
          58.012054000000006,
          58.989840400000006,
          59.6863875,
          60.219311000000005,
          61.215764500000006,
          62.011559499,
          62.6141578,
          63.176583,
          64.0497915,
          64.69464620000001,
          65.2794674,
          66.2769765,
          67.0448143,
          67.683318799,
          68.76704570000001,
          69.907879599,
          70.781227199,
          71.4324757,
          72.0224633,
          72.72717940000001,
          73.46209389900001,
          74.66591910000001,
          75.59207430000001,
          76.33412410000001,
          77.5087955,
          78.388967799,
          79.8655925,
          81.109682799,
          83.28142410000001,
          85.300773,
          87.2266438,
          88.3650305,
          89.810261799,
          91.04032589900001,
          92.1248297,
          92.9489104,
          94.04960549900001,
          95.65968170000001,
          97.0533087,
          98.132065299,
          99.88273059900001,
          101.3416933,
          102.62263490000001,
          103.6486423,
          105.18757570000001,
          106.4483986,
          107.410989599,
          108.67118310000001,
          110.3070107,
          112.6945663,
          114.61384190000001,
          116.16653329900001,
          117.22802220000001,
          118.77376480000001,
          120.41259639900001
         ],
         "xaxis": "x1",
         "y": [
          43.243496620879306,
          43.18590621572114,
          43.09956835229021,
          42.96783855629635,
          42.768399150183896,
          42.46945545851414,
          42.018294224409736,
          41.34099588842537,
          40.32886059900783,
          38.81925494424295,
          38.81925494424295,
          38.81925494424295,
          38.418095364300505,
          37.999855654711475,
          37.7227176697646,
          37.53170536098115,
          37.171556292478265,
          37.0495710079372,
          36.714379527487694,
          36.714379527487694,
          36.572000867708745,
          36.465250390661694,
          36.17787185777916,
          36.17787185777916,
          36.04004602310698,
          35.919519668182225,
          35.82254048453125,
          35.58050551543698,
          35.48982704280461,
          35.28895360589955,
          35.1674079524948,
          35.0031723303484,
          34.758668290253055,
          34.66424637724405,
          34.50621276633283,
          34.34560062580966,
          34.229081683298816,
          34.1506588303662,
          34.036676079386936,
          33.83890267192525,
          33.419362237836644,
          33.352357291175,
          33.07545140900681,
          33.00688741188622,
          32.8745135551243,
          32.7700697120328,
          32.64434357009444,
          32.55420215058093,
          32.460564317389355,
          32.3702504852056,
          32.22692740206002,
          32.0437360849622,
          31.973604491066464,
          31.866164855875436,
          31.866164855875436,
          31.790857641120585,
          31.568152581127347,
          31.52957751117503,
          31.30161798770382,
          31.210749399609394,
          31.12327668410524,
          30.99999147326802,
          30.916147641936465,
          30.83997109962959,
          30.736810654444863,
          30.634412118757407,
          30.55959536446994,
          30.44654122029495,
          30.270397664274313,
          30.067983969513197,
          30.02036305619446,
          29.929919641742543,
          29.825165132578785,
          29.739332582826577,
          29.649513014160917,
          29.443380583615806,
          29.398862607450887,
          29.231010836723872,
          29.197431771790693,
          28.97405320570511,
          28.921920519982226,
          28.801263418449988,
          28.71871014777222,
          28.63606035226542,
          28.560200537007272,
          28.508426315971136,
          28.42470845984069,
          28.305208086731696,
          28.27734187413566,
          28.152319294836726,
          28.10883777751775,
          27.911944359493525,
          27.768201016487872,
          27.716178348883126,
          27.631844020061422,
          27.502850492050694,
          27.302386655467334,
          27.265101069142126,
          27.012598054621655,
          26.90626016268151,
          26.86045953850945,
          26.73457131074285,
          26.4789478122845,
          26.432696421165076,
          26.28887489628087,
          26.094709712842803,
          25.993359647002688,
          25.951777568879965,
          25.84882078602034,
          25.621980551454506,
          25.48308140554369,
          25.3682035951309,
          25.32977083687996,
          25.22676824475649,
          25.08818280766363,
          24.92897249307845,
          24.822336444241518,
          24.78206301903842,
          24.679198735369145,
          24.449976583780057,
          24.32961434977839,
          24.236517010463544,
          24.159072504837912,
          24.081346063267798,
          24.048773904034274,
          23.98431121008631,
          23.930353624852238,
          23.87612690900907,
          23.78589163660954,
          23.59862561210218,
          23.500819895516834,
          23.416917086325107,
          23.343988427466368,
          23.25513891773298,
          23.172720104115445,
          23.13948293190087,
          23.078608162833895,
          22.909484403619977,
          22.882807145593212,
          22.810630357718555,
          22.703316899836466,
          22.67939947689285,
          22.52169004693593,
          22.44028368001841,
          22.371666917113593,
          22.34315040895623,
          22.281483540702254,
          22.123680839704015,
          22.06377429738082,
          21.990939334055202,
          21.960324898863114,
          21.89828577611098,
          21.729145459063993,
          21.66264217692618,
          21.605043276114184,
          21.5370253549851,
          21.475324943846886,
          21.448582103449166,
          21.403802573507924,
          21.330369609910225,
          21.173398480203222,
          21.0835147077509,
          21.00080565243607,
          20.911787653457157,
          20.824845615844577,
          20.772329540982202,
          20.745032000063212,
          20.692113586956495,
          20.566973514044324,
          20.542024469127526,
          20.48056304752617,
          20.345613620850838,
          20.25179119008625,
          20.17012174672612,
          20.08789069890564,
          20.0120848651983,
          19.98695653291627,
          19.937722039538077,
          19.816377071051143,
          19.751086699674847,
          19.725200759623394,
          19.674246388168722,
          19.555867206863205,
          19.465428633144395,
          19.387637184693915,
          19.31512559294453,
          19.292638398679202,
          19.248219369794786,
          19.14012793974831,
          19.074612469418355,
          19.005021912341537,
          18.942257364584357,
          18.886009604022913,
          18.865073755285106,
          18.794890681158837,
          18.647765201207328,
          18.553230007127137,
          18.479220464592903,
          18.406069459938365,
          18.335072276343237,
          18.27259249602427,
          18.2187578711812,
          18.19621400017312,
          18.151576783708034,
          18.04524225847387,
          17.998069354595817,
          17.941824582772636,
          17.881923876164525,
          17.818354257052,
          17.802664764042046,
          17.72263712394546,
          17.661254651082913,
          17.607457256027704,
          17.56207324042588,
          17.522413385843,
          17.503657524353528,
          17.45877892266684,
          17.38623009924475,
          17.339652168087916
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        },
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "BHHH tv",
         "line": {
          "color": "rgba(227, 111, 71, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "BHHH tv",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.17369410000000002,
          0.18485029900000002,
          0.2063202,
          0.3876198,
          0.532660499,
          0.6470128,
          0.785217,
          0.8842850000000001,
          1.0164695990000001,
          1.0527704,
          1.1737328,
          1.2018503,
          1.3008493,
          1.419470999,
          1.434797499,
          1.436035599,
          1.5419207000000001,
          1.645865399,
          1.8780564000000002,
          2.0374865
         ],
         "xaxis": "x1",
         "y": [
          43.243496620879306,
          43.18590621572114,
          43.100474406358835,
          42.97398929207457,
          42.78113566034097,
          42.48917007819054,
          42.05128860568391,
          41.390292687468154,
          40.40337145140512,
          38.94878703151555,
          38.94878703151555,
          38.55571835638938,
          38.19337310193117,
          37.895846910455234,
          37.4492345064511,
          37.17918842548385,
          37.17918842548385,
          36.99195733535648,
          36.840053429990796,
          36.68988469326428,
          36.48819567073133
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        },
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "Hes tv",
         "line": {
          "color": "rgba(62, 164, 78, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "Hes tv",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.209733299,
          0.249059,
          0.29550249900000003,
          0.408523499,
          0.568902099,
          0.7076244,
          0.8469837,
          0.9578208990000001,
          1.121287999,
          1.1397665000000001,
          1.1683168000000002,
          1.4055315000000002,
          1.580116199,
          1.7767686,
          1.9659655,
          2.137157099,
          2.434360099,
          2.4969266,
          2.5378836000000002,
          2.559651599
         ],
         "xaxis": "x1",
         "y": [
          43.243496620879306,
          43.18590621572114,
          43.09973452725706,
          42.96950438391258,
          42.77454112524566,
          42.482427467821815,
          42.03991953825041,
          40.78149849120286,
          38.97104676546119,
          36.540772738691,
          36.540772738691,
          36.540772738691,
          36.163907410522796,
          35.82017492584406,
          35.49781304133694,
          35.20798020173169,
          34.83117665656368,
          34.19754666625386,
          32.866346861510564,
          31.424583144551704,
          27.845214615020552
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        },
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "IR",
         "line": {
          "color": "rgba(195, 113, 210, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "IR",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.8762630990000001,
          1.0486858000000001,
          1.198554799,
          1.4055425000000001,
          1.6074843,
          1.7540329000000001,
          1.9502664,
          2.120530799,
          2.3026288000000004,
          2.4838987,
          2.589203699,
          2.8049155000000003,
          2.9320727,
          2.9714974,
          3.0842569990000004,
          3.2111636000000003,
          3.3506341,
          3.4907365990000003,
          3.5961006,
          3.7930689990000004,
          3.9248878990000002,
          3.9427361000000003,
          4.0593007000000005,
          4.2319334,
          4.429452099000001,
          4.5600225000000005,
          4.725327500000001,
          4.8614445,
          5.028804599,
          5.057801099000001,
          5.1871974000000005,
          5.316583799,
          5.4919947,
          5.6551524,
          5.7748869,
          5.939776800000001,
          6.0916978,
          6.305307,
          6.4327899,
          6.6218253,
          6.754254400000001,
          6.9158511,
          7.0894127000000005,
          7.1071375990000005,
          7.256495200000001,
          7.379185400000001,
          7.4931412,
          7.610903400000001,
          7.804367899000001,
          7.9097856,
          8.0520805,
          8.0843684,
          8.255606099000001,
          8.404055000000001,
          8.534606100000001,
          8.652867200000001,
          8.8525389,
          8.9779918,
          9.0330385,
          9.154501699,
          9.294238,
          9.452529699000001,
          9.564264000000001,
          9.6841585,
          9.7079369,
          9.8561408,
          9.9549514,
          10.0876713,
          10.214286899000001,
          10.3141572,
          10.436802400000001,
          10.581230599000001,
          10.750874099,
          10.9673554,
          11.035861799000001,
          11.153172900000001,
          11.256066200000001,
          11.4354321,
          11.554885800000001,
          11.760837800000001,
          11.9074544,
          11.939724100000001,
          12.0981977,
          12.2370932,
          12.359006500000001,
          12.470793599,
          12.6100659,
          12.614076999,
          12.733841399000001,
          12.893728900000001,
          13.0106827,
          13.129425000000001,
          13.276799,
          13.377885500000001,
          13.4825286,
          13.485190600000001,
          13.595366100000001,
          13.693931099,
          13.811805199,
          13.992859200000002,
          14.093696900000001,
          14.2117286,
          14.392397500000001,
          14.436712000000002,
          14.554985,
          14.7084349,
          14.868963599,
          15.058553700000001,
          15.254578500000001,
          15.272606799,
          15.470820900000001,
          15.6235628,
          15.7617188,
          15.8960138,
          16.019628700000002,
          16.1899158,
          16.2949391,
          16.2975983,
          16.475478499,
          16.6154526,
          16.7727015,
          16.929238599,
          17.0545878,
          17.1789908,
          17.298726299000002,
          17.330182699,
          17.481676,
          17.6211515,
          17.7643612,
          17.9288725,
          18.0347847,
          18.153686,
          18.345438700000003,
          18.4789888,
          18.510538200000003,
          18.6573628,
          18.822969500000003,
          18.977780299000003,
          19.1493842,
          19.255051,
          19.4098201,
          19.531427199,
          19.577500499000003,
          19.7120649,
          19.826514499,
          19.9572505,
          20.057918100000002,
          20.191079399,
          20.3242845,
          20.4443559,
          20.6102884,
          20.613573999,
          20.7131846,
          20.8543834,
          21.008808999000003,
          21.2353747,
          21.338163799,
          21.437728,
          21.5413093,
          21.603071099,
          21.7401076,
          21.937923299,
          22.053801799000002,
          22.1756645,
          22.275311699000003,
          22.378481500000003,
          22.480401299,
          22.5810371,
          22.5835721,
          22.701059200000003,
          22.863661800000003,
          22.962971699,
          23.0656633,
          23.182425799,
          23.379449100000002,
          23.565456400000002,
          23.589639899,
          23.719011799,
          23.8405302,
          23.963405100000003,
          24.099289300000002,
          24.200761,
          24.388312300000003,
          24.5367651,
          24.674922900000002,
          24.745222300000002,
          24.9344566,
          25.034576099000002,
          25.1377513,
          25.2876085,
          25.471190499000002,
          25.626517200000002,
          25.795855500000002,
          25.814067,
          25.915367800000002,
          26.065248500000003,
          26.279377200000003,
          26.3962274,
          26.5304046,
          26.6959309,
          26.8378544,
          26.9760533,
          26.996555800000003,
          27.108435799000002,
          27.247860899000003,
          27.3870554,
          27.5193762,
          27.640779299000002,
          27.792832099,
          27.917137299,
          27.9420463,
          28.1419587,
          28.260902799,
          28.3788112,
          28.492030300000003,
          28.617063,
          28.718584099,
          28.8421325,
          28.980437100000003,
          29.0163271,
          29.144952999,
          29.267283600000003,
          29.369866000000002,
          29.5468797,
          29.6499625,
          29.7523687,
          29.9039444,
          29.925316199,
          30.110689200000003,
          30.267326,
          30.434168699,
          30.569648,
          30.696987399,
          30.8558932,
          31.009389399000003,
          31.134481299,
          31.188471899000003,
          31.3425797,
          31.4772734,
          31.6249143,
          31.7254994,
          31.826300699,
          31.9845705,
          32.0852755,
          32.1131268,
          32.2546004,
          32.375701500000005,
          32.475638299,
          32.6022491,
          32.7283665,
          32.864000999000005,
          33.008385600000004,
          33.1872866,
          33.203317199000004,
          33.340807799000004,
          33.4416802,
          33.571251700000005,
          33.672282499000005,
          33.771924699,
          33.9209472,
          34.026757299,
          34.0296678,
          34.149349999,
          34.248158899,
          34.348682399000005,
          34.463278399000004,
          34.665905599000006,
          34.789110499,
          34.9457979,
          35.1072654,
          35.140640000000005,
          35.2497983,
          35.437699799,
          35.580553,
          35.725785199,
          35.959918900000005,
          36.0814557,
          36.252656,
          36.2826855,
          36.4323558,
          36.5773643,
          36.740892800000005,
          36.914163399,
          37.069955499,
          37.1920469,
          37.3377385,
          37.502714100000006,
          37.5367577,
          37.637187899000004,
          37.788008299000005,
          37.976814100000006,
          38.0944591,
          38.206459999,
          38.3857561,
          38.5013062,
          38.5599514,
          38.714640199,
          38.836751500000005,
          38.978321400000006,
          39.144853299000005,
          39.2461502,
          39.3492894,
          39.450985599,
          39.5559012,
          39.5782206,
          39.678205399,
          39.8038838,
          39.9064982,
          40.0084285,
          40.158839900000004,
          40.266447400000004,
          40.370611600000004,
          40.3733451,
          40.475327,
          40.606900299,
          40.818207900000004,
          40.9768503,
          41.0970486,
          41.21528,
          41.344913999,
          41.526230399,
          41.632324699,
          41.757385999,
          41.8557949,
          41.972371800000005,
          42.100321,
          42.227045199,
          42.396405899,
          42.517423999,
          42.565954100000006,
          42.670822499,
          42.822599299000004,
          42.9530248,
          43.093682799,
          43.2956556,
          43.4592296,
          43.5617467,
          43.742953899,
          43.795401499,
          43.936556700000004,
          44.0578659,
          44.211426100000004,
          44.349674500000006,
          44.452213500000006,
          44.570105500000004,
          44.6929243,
          44.709913400000005,
          44.8507881,
          44.9925957,
          45.1285886,
          45.2844211,
          45.45366,
          45.610999400000004,
          45.8169641,
          45.9854563,
          46.056301999000006,
          46.1749597,
          46.381682899000005,
          46.5040672,
          46.646099699000004,
          46.805627900000005,
          46.945877,
          47.047068699,
          47.109970800000006,
          47.273971,
          47.39641,
          47.526514600000006,
          47.625299399000006,
          47.726553900000006,
          47.827934699000004,
          47.94847600000001,
          48.0550744,
          48.058249200000006,
          48.157116599000005,
          48.357981300000006,
          48.513547399000004,
          48.653254999000005,
          48.78309,
          48.8854333,
          49.0286495,
          49.0316605,
          49.128433399,
          49.244871399000004,
          49.3449704,
          49.495848900000006,
          49.617505200000004,
          49.7182959,
          49.820784100000004,
          49.926950700000006,
          49.9747111,
          50.121713,
          50.271141300000004,
          50.439939399000004,
          50.626067600000006,
          50.782987499,
          50.9644727,
          51.082284,
          51.0845299,
          51.2215471,
          51.3356423,
          51.4343275,
          51.5418414,
          51.699710199,
          51.837729700000004,
          51.939813400000006,
          52.0683458,
          52.117494499,
          52.2897158,
          52.426822799,
          52.5644222,
          52.726962599000004,
          52.943947800000004,
          53.0984095,
          53.2152625,
          53.2636514,
          53.4140701,
          53.530469200000006,
          53.658740200000004,
          53.813616799,
          53.9140522,
          54.030796200000005,
          54.143422400000006,
          54.28597490000001,
          54.288557100000006,
          54.407219100000006,
          54.527783500000005,
          54.6653522,
          54.79078560000001,
          54.942377799000006,
          55.048758400000004,
          55.152296400000004,
          55.154830299000004,
          55.255788499000005,
          55.375555000000006,
          55.5407554,
          55.658826000000005,
          55.7817385,
          55.8844982,
          55.9880581,
          56.1443097,
          56.2490552,
          56.394463999,
          56.514740299,
          56.70048159900001,
          56.8488976,
          56.9996233,
          57.1436895,
          57.266783200000006,
          57.271756999000004,
          57.417186300000004,
          57.539357300000006,
          57.658060500000005,
          57.815261399,
          57.9726458,
          58.128579199,
          58.244838,
          58.3836687,
          58.4545073,
          58.611424899000006,
          58.726597500000004,
          58.863513099,
          58.985052800000005,
          59.1320756,
          59.2473381,
          59.4309705,
          59.4606384,
          59.5947638,
          59.710581100000006,
          59.8127403,
          59.9370398,
          60.0394969,
          60.1410131,
          60.24152050000001,
          60.424257100000005,
          60.439157800000004,
          60.619068000000006,
          60.79908270000001,
          60.932639599000005,
          61.053765299000005,
          61.2264313,
          61.3513413,
          61.5464087,
          61.561027399000004,
          61.702958399,
          61.816301799,
          61.970145300000006,
          62.110882899,
          62.224248499000005,
          62.3828776,
          62.511225100000004,
          62.616609099,
          62.701220500000005,
          62.8416435,
          63.037250900000004,
          63.164780400000005,
          63.281649599000005,
          63.400617699,
          63.55545389900001,
          63.6782952,
          63.74183089900001,
          63.873128099000006,
          64.0204621,
          64.20040130000001,
          64.33640479900001,
          64.4683129,
          64.6178531,
          64.8303186,
          64.9711158,
          64.97362929900001,
          65.1354688,
          65.24864039900001,
          65.383938099,
          65.5335022,
          65.7201563,
          65.918757399,
          66.1228178,
          66.249435999,
          66.405831199,
          66.57299729900001,
          66.6745393,
          66.819403799,
          66.9223699,
          67.04304450000001,
          67.2009848,
          67.376760699,
          67.397575999,
          67.5540613,
          67.653668599,
          67.7531613,
          67.854878,
          68.0068612,
          68.128979,
          68.2431846,
          68.2911313,
          68.4074324,
          68.5545305,
          68.65464010000001,
          68.7913453,
          68.892582,
          69.02815410000001,
          69.16499300000001,
          69.26688440000001,
          69.2694352,
          69.36885310000001,
          69.5495466,
          69.6616934,
          69.7639439,
          69.9053985,
          70.05361470000001,
          70.2677098,
          70.3175801,
          70.466268099,
          70.6206952,
          70.75054970000001,
          70.85997199900001,
          71.02545140000001,
          71.1857906,
          71.40823610000001,
          71.5912656,
          71.62136860000001,
          71.72382610000001,
          71.83587049900001,
          71.938457799,
          72.037382099,
          72.155878199,
          72.261161,
          72.3643576,
          72.3672909,
          72.4682184,
          72.567692799,
          72.669709,
          72.8051128,
          72.90335110000001,
          73.044337,
          73.1493756,
          73.318201,
          73.35915870000001,
          73.46000360000001,
          73.558442799,
          73.69868619900001,
          73.820330599,
          73.9555375,
          74.09374000000001,
          74.230623099,
          74.2703607,
          74.4015018,
          74.5001963,
          74.64895909900001,
          74.752080499,
          74.89417319900001,
          74.9927727,
          75.1167944,
          75.220640699,
          75.223292799,
          75.40719560000001,
          75.5198654,
          75.6270564,
          75.7909736,
          75.985805299,
          76.1305918,
          76.3369277,
          76.3773541,
          76.54678990000001,
          76.7161123,
          76.8845407,
          77.1381762,
          77.261719,
          77.43194960000001,
          77.5692379,
          77.6715188,
          77.6740898,
          77.7730083,
          77.89229920000001,
          77.9933618,
          78.15038119900001,
          78.31347120000001,
          78.4697245,
          78.6144472,
          78.6663218,
          78.7967715,
          78.91025880000001,
          79.1427117,
          79.277887699,
          79.3901943,
          79.5260444,
          79.664208599,
          79.81207640000001,
          79.8157367,
          79.9147355,
          80.0534142,
          80.16924180000001,
          80.30394270000001,
          80.4488395,
          80.55837449900001,
          80.7418703,
          80.7750944,
          80.89469309900001,
          80.996731099,
          81.190382799,
          81.3992149,
          81.5578126,
          81.737806,
          81.8557244,
          82.00589430000001,
          82.0283187,
          82.19674570000001,
          82.3081308,
          82.43020809900001,
          82.55090940000001,
          82.6723405,
          82.8184049,
          82.9604894,
          82.9629781,
          83.0608916,
          83.19657020000001,
          83.3323936,
          83.43185720000001,
          83.545423799,
          83.65731539900001,
          83.775333,
          83.918765499,
          83.9815573,
          84.127890699,
          84.25634480000001,
          84.42990249900001,
          84.55242050000001,
          84.6721334,
          84.7758154,
          84.9187086,
          84.9221174,
          85.1075989,
          85.20689850000001,
          85.307249,
          85.426127099,
          85.5258294,
          85.6926031,
          85.91295689900001,
          86.139066899,
          86.1426163,
          86.278217399,
          86.4126705,
          86.53774580000001,
          86.6532387,
          86.804618,
          86.9251515,
          87.0276951,
          87.0812873,
          87.206230499,
          87.31296660000001,
          87.4334944,
          87.57776940000001,
          87.70507400000001,
          87.806915,
          87.91069540000001,
          88.03222690000001,
          88.104285699,
          88.2566587,
          88.378642,
          88.4794217,
          88.58113789900001,
          88.7116154,
          88.81205650000001,
          88.96010549900001,
          88.97843049900001,
          89.0923717,
          89.206613499,
          89.4017678,
          89.50540430000001,
          89.62523610000001,
          89.78142890000001,
          89.9552646,
          90.11152170000001,
          90.114857799,
          90.235409199,
          90.38011479900001,
          90.5140356,
          90.6654388,
          90.79426620000001,
          90.9436264,
          91.079196999,
          91.14065860000001,
          91.2689917,
          91.3813123,
          91.54052730000001,
          91.6580423,
          91.7980189,
          91.9163436,
          92.0250432,
          92.1277433,
          92.15815710000001,
          92.26337229900001,
          92.367671199,
          92.472464,
          92.57658400000001,
          92.7368165,
          92.8887124,
          93.0063786,
          93.03119310000001,
          93.1538783,
          93.296017,
          93.4261587,
          93.526336799,
          93.6571876,
          93.7863564,
          93.931031,
          94.03577049900001,
          94.038270099,
          94.1784186,
          94.28610609900001,
          94.40210450000001,
          94.58581729900001,
          94.77111190000001,
          94.8880232,
          95.00914300000001,
          95.01220299900001,
          95.14761010000001,
          95.3638579,
          95.5163665,
          95.72570079900001,
          95.8324489,
          95.9620237,
          96.06491910000001,
          96.1690231,
          96.17155050000001,
          96.32702880000001,
          96.5544735,
          96.6553617,
          96.8046984,
          96.9066557,
          97.0063214,
          97.1089745,
          97.11144580000001,
          97.21205459900001,
          97.331306599,
          97.460770999,
          97.5763785,
          97.67760100000001,
          97.8022306,
          97.90595180000001,
          98.04851299900001,
          98.10592030000001,
          98.230675899,
          98.3408964,
          98.4943879,
          98.592598299,
          98.69692230000001,
          98.8167806,
          98.98849619900001,
          99.03005119900001,
          99.21935970000001,
          99.34005919900001,
          99.4627025,
          99.56323250000001,
          99.696291899,
          99.856624799,
          100.0102164,
          100.12721470000001,
          100.1298392,
          100.22985530000001,
          100.41425650000001,
          100.6033855,
          100.8082174,
          100.94961660000001,
          101.048834099,
          101.2198961,
          101.2235007,
          101.34451130000001,
          101.4681736,
          101.597803299,
          101.69744150000001,
          101.7995709,
          101.9051446,
          102.00825560000001,
          102.136412,
          102.15386160000001,
          102.312584899,
          102.4892712,
          102.64214580000001,
          102.81098119900001,
          102.931173199,
          103.04666319900001,
          103.149179899,
          103.15154550000001,
          103.274288399,
          103.4168946,
          103.5325916,
          103.71371369900001,
          103.815482899,
          103.95266570000001,
          104.1081209,
          104.23583550000001,
          104.26184140000001,
          104.45330100000001,
          104.60396840000001,
          104.717575099,
          104.91538820000001,
          105.0951036,
          105.3076439,
          105.46894160000001,
          105.52494680000001,
          105.70275430000001,
          105.87369020000001,
          105.99524779900001,
          106.157139599,
          106.304118,
          106.44933160000001,
          106.59254290000001,
          106.76454740000001,
          106.7669908,
          106.870322899,
          107.03564560000001,
          107.1717952,
          107.27748960000001,
          107.381208599,
          107.50906799900001,
          107.6404784,
          107.7010195,
          107.80699859900001,
          107.92796879900001,
          108.0607166,
          108.183244399,
          108.37857650000001,
          108.510558699,
          108.64851200000001,
          108.7770263,
          108.83577220000001,
          108.98201820000001,
          109.120123899,
          109.27961230000001,
          109.47314580000001,
          109.61442570000001,
          109.77785739900001,
          109.9151078,
          109.9175611,
          110.0412211,
          110.20201300000001,
          110.34034899900001,
          110.49549199900001,
          110.672542699,
          110.8598219,
          110.99110850000001,
          111.1333984,
          111.15187730000001,
          111.29687719900001,
          111.5317998,
          111.6729061,
          111.81300870000001,
          111.9655453,
          112.1097912,
          112.230401399,
          112.29628859900001,
          112.40273250000001,
          112.5082251,
          112.6416494,
          112.761759299,
          112.8646264,
          113.01206509900001,
          113.14327530000001,
          113.28914440000001,
          113.29200920000001,
          113.4249714,
          113.54358249900001,
          113.6850533,
          113.8037764,
          113.980180199,
          114.1675599,
          114.301893,
          114.333316299,
          114.47017840000001,
          114.6139756,
          114.73677180000001,
          114.90056240000001,
          115.09393370000001,
          115.208248999,
          115.351487699,
          115.521176599,
          115.556027399,
          115.713798799,
          115.8150224,
          115.94136390000001,
          116.04242749900001,
          116.162405199,
          116.2875322,
          116.412614,
          116.45074690000001,
          116.5770846,
          116.7162844,
          116.8503,
          117.05291930000001,
          117.19432610000001,
          117.36101279900001,
          117.53026720000001,
          117.6766484,
          117.67981440000001,
          117.79624500000001,
          117.93106730000001,
          118.1077279,
          118.30936890000001,
          118.4115022,
          118.51383510000001,
          118.61527729900001,
          118.61774019900001,
          118.71550880000001,
          118.8321518,
          118.991676999,
          119.12454349900001,
          119.263096699,
          119.363421099,
          119.54803430000001,
          119.6968291,
          119.6998734,
          119.8360983,
          120.03361020000001
         ],
         "xaxis": "x1",
         "y": [
          43.243496620879306,
          41.610493827977194,
          40.677730352516186,
          39.243765725753576,
          37.09109425274473,
          34.21923370745323,
          31.430819053534492,
          26.49771934240901,
          19.55673472738391,
          11.768468184689084,
          11.460979713835098,
          11.309269708863143,
          11.230073281542921,
          11.092432053388924,
          12.730678429981197,
          11.364919073416527,
          11.224402596248432,
          12.128022415696666,
          11.01984795340814,
          15.379011188811765,
          15.990876424188938,
          15.93208883036006,
          15.984100091566164,
          15.546782382963228,
          16.911607531495093,
          18.61669924458407,
          17.681524172871082,
          17.838646818118296,
          21.344839511288995,
          24.749402858510066,
          23.354623542285328,
          22.707441772622904,
          23.54859348834788,
          22.172948286388475,
          22.46812536337601,
          22.666772752813582,
          22.560005969375336,
          22.892730815866535,
          22.44619368902172,
          22.477885926907483,
          21.93834259248908,
          21.952475105164392,
          22.200712209343976,
          22.12948762547738,
          21.83889133795859,
          21.556814757860156,
          22.002922991903244,
          21.611475228090004,
          21.43025614661486,
          21.465777455191933,
          21.44537599027648,
          21.04163474233757,
          20.97933084311183,
          20.79056529807555,
          20.915527840127005,
          20.674742637863837,
          20.595958615022866,
          20.51965622973605,
          20.369740550577408,
          20.236348594197,
          19.531499464761595,
          19.498819002635386,
          19.940770822169632,
          19.219676471134452,
          19.1801925266426,
          19.380633602733795,
          19.108261690681733,
          18.669262589341077,
          18.38495356133004,
          18.11273084430899,
          18.144892059992102,
          17.637198643469425,
          17.80359131938565,
          17.438344967834418,
          18.137348809538075,
          17.748385487753453,
          17.890123753105925,
          17.811221933546232,
          17.622418034000734,
          17.459466464273756,
          17.28717456480487,
          17.608942996340335,
          17.251928789476864,
          17.383127591014116,
          16.983222606682688,
          17.287881162553294,
          17.034542767785975,
          17.229865745708572,
          17.256261788452147,
          16.797565767546985,
          17.151792349073904,
          16.47145376688392,
          16.57966744403775,
          16.232595768378076,
          16.207985910630466,
          16.11745677770459,
          15.96694258350244,
          16.082739462083172,
          15.711559203466201,
          16.031608777426772,
          15.510577491835852,
          15.54133322683009,
          15.197948520291805,
          15.164368862042753,
          15.388695369992938,
          14.953094165163197,
          14.975516135427009,
          14.92496378557659,
          15.067709308901115,
          15.03463980151175,
          15.061802606671717,
          14.593469685521441,
          14.323317382809293,
          14.580436547766967,
          14.013539221164855,
          14.156157204187382,
          15.300977093130058,
          14.91408901216514,
          15.023140150757966,
          14.55452280334798,
          14.707731656332129,
          14.17217943088454,
          14.377419389656154,
          13.783796521426492,
          14.318807316316672,
          14.269504137821981,
          13.991257753833414,
          14.25681614356753,
          13.782475028561214,
          13.68605724079235,
          13.946906122497138,
          13.46165774983352,
          13.592768388398483,
          13.091631348724707,
          13.08524275780497,
          13.461521943746817,
          13.160130771218583,
          12.766443209933847,
          12.416218381123358,
          12.818587736602677,
          12.10182128771503,
          12.017280424725989,
          12.255359949652256,
          11.852077390665762,
          12.098483322589138,
          11.591339431870102,
          11.803265214889207,
          11.115702286047965,
          11.14465097452672,
          11.154854240826603,
          11.292248187722045,
          11.367883793526623,
          11.11544250660858,
          10.876734362396823,
          10.891014460605652,
          10.978061574175404,
          10.62042686907608,
          10.972206774795925,
          10.396165655947556,
          10.768461986373865,
          10.425860038019884,
          10.27832671211296,
          11.165756335805515,
          10.529647238997399,
          10.397727616233553,
          10.042276065132079,
          10.020756393840472,
          10.004774822582092,
          10.618493014763207,
          10.178445086017446,
          11.121304148187685,
          10.326786402666112,
          10.100435957148829,
          10.386766841878602,
          9.968205685682092,
          10.583235595015255,
          9.803867505764112,
          9.927467225131515,
          10.271485303819023,
          9.785121517389276,
          9.55941942881254,
          9.254434044721686,
          9.84672380722662,
          8.989205259248925,
          9.443828363476252,
          8.59078531529478,
          9.106708993504327,
          8.522148478499002,
          8.55427715972574,
          9.880318812935434,
          9.029637545776856,
          9.110410721088243,
          9.628608055103395,
          9.557295245841429,
          9.615694167881658,
          9.19229733346817,
          9.024262175522658,
          8.880629595741697,
          8.997904051080814,
          8.693569807723959,
          8.825681177555051,
          8.47769609307012,
          8.497763480226563,
          8.638521623451108,
          8.774844250305994,
          8.174490815384376,
          8.696415807983035,
          7.948668118370581,
          8.244385699290905,
          7.675692218120097,
          8.133388499231659,
          7.6608256683986,
          8.10400032956255,
          7.326789464281441,
          7.821864026623551,
          7.150531786317639,
          7.786408428562399,
          6.937626154156636,
          7.589239961538656,
          6.665955405527807,
          6.790311836230349,
          7.4224575887546145,
          6.4335274077353235,
          6.695682216286856,
          6.332317903944241,
          6.676267057974913,
          6.196148522941494,
          6.139527141708066,
          5.973213684480302,
          6.374262087855112,
          5.656462517450716,
          5.525893774476152,
          5.9502815217824505,
          5.404140977501299,
          5.664247086512257,
          6.158089520709547,
          5.285661323852977,
          4.945278444268076,
          5.082520610240302,
          5.3176946861583,
          5.662945758400197,
          4.874741635905664,
          5.636152614760167,
          4.745123377419404,
          5.3672801701028,
          4.598409222040357,
          5.637326335188635,
          4.570183306272991,
          5.87952968830212,
          4.383456996675828,
          5.28277024673339,
          3.852181957373483,
          5.339896870322033,
          3.934377310535668,
          4.500440290926159,
          3.8072191091910725,
          5.4172901508956235,
          4.234949487760044,
          4.711543872065121,
          3.946659235191179,
          4.9244172740633925,
          3.5600701765029052,
          4.714748324003847,
          5.3940746390955585,
          5.7528233073413055,
          3.8516030638893453,
          5.100214733329824,
          4.7141280816539535,
          4.38470520488997,
          4.362462072672014,
          4.520475409345962,
          4.338151275325078,
          4.570253541580831,
          5.10172119579506,
          4.523015640097467,
          5.454143457797661,
          3.9484616617966033,
          4.75948974487432,
          4.743162312972039,
          4.409558022857277,
          4.390806546438167,
          4.896638100828287,
          3.8749334428232936,
          3.63734499829242,
          4.879366062252953,
          3.9711101664584683,
          3.7789385247519527,
          4.855791128010099,
          3.7230907003119147,
          3.6300932942450417,
          3.568864133656804,
          3.523943986449346,
          5.176568011613869,
          3.6420414698543055,
          4.69571448743421,
          3.639846150869394,
          3.8925716597774858,
          3.536325931173393,
          3.9638151708613494,
          3.472866775073289,
          4.46230126863394,
          3.89837293165143,
          3.833672562611986,
          3.0556248096890526,
          3.4169450418876854,
          2.6999831865993387,
          3.9454609994764027,
          3.3102316374034153,
          3.1882151936848655,
          2.7028488094231,
          3.391101314310286,
          4.242484928450757,
          2.999711299827068,
          3.690712692379692,
          3.4232439906564642,
          3.17481385921188,
          3.681800700787818,
          3.4292212866205927,
          3.1759771490945496,
          3.034151270151871,
          3.2075306793603207,
          2.9897705031236956,
          2.7616478420929136,
          2.1950733717400785,
          2.4154243927141326,
          3.2753319359199327,
          1.957256928828484,
          4.19777434636972,
          1.9913096978259988,
          4.379035332474658,
          2.7664323928959553,
          2.875717554455862,
          4.153084816685313,
          2.2927502503869155,
          2.8538590746680135,
          1.7728798113347681,
          2.4178413514971044,
          1.9860557853009553,
          4.455460351863924,
          2.32146583159901,
          1.3950892407183046,
          3.86350010731937,
          1.6300775534307863,
          4.434286889744072,
          2.3893472781012397,
          2.9796002289927856,
          2.158384076897403,
          1.3324710928248968,
          3.8382057992635055,
          1.2483263823823785,
          3.9941316257782025,
          2.0065409065414994,
          2.809280290900032,
          2.1879758299132854,
          4.8653574187674975,
          2.401031854238405,
          2.9877571598461445,
          2.902452426286936,
          2.9955511944805684,
          2.0140565573609965,
          4.721200894981937,
          2.6634660637597016,
          3.980859491352526,
          2.444633214811979,
          3.548008971015202,
          2.0330484932088124,
          2.9749496035232057,
          2.3801097923622696,
          2.5752421596805113,
          3.959336105401294,
          2.3852687124398764,
          3.261660412028664,
          1.8028122439893897,
          2.7536554563275684,
          2.0818684332622555,
          3.6161998573543546,
          2.4600969703589386,
          3.8468547321424746,
          3.038446368910558,
          4.58579726420996,
          2.1860367388301403,
          4.246725915072183,
          4.153563542589981,
          3.3671365792068864,
          2.9431393072682797,
          4.704025225636773,
          3.110562465918511,
          3.8577549656327483,
          4.190728260277373,
          3.105077774029378,
          3.0798639768044063,
          3.2933396275432023,
          2.6820884188590672,
          4.834049665248146,
          3.434240084963289,
          5.053513640941858,
          3.6571617876598927,
          4.268063214602209,
          2.870209019990047,
          3.674741865613719,
          3.3949394825204395,
          4.245805986138238,
          3.278750294817212,
          4.288576568677955,
          4.252016541722667,
          3.6748329813941725,
          3.3997708902427695,
          3.927029888913469,
          3.6577744589201546,
          3.847070363003001,
          5.270256361748778,
          4.208736792298617,
          3.4917660931482626,
          5.165716973326759,
          3.775037145485131,
          3.885665218980136,
          4.130687559261609,
          4.092263955579743,
          4.528416074927687,
          5.049530302799059,
          4.803839729739998,
          3.7480692955144073,
          5.4354004971727425,
          4.212786884648567,
          4.484393780857722,
          4.6929651343915495,
          5.579461734658098,
          4.81369519877605,
          5.852296817300951,
          4.749934433665796,
          4.37708096336899,
          5.0683224933114985,
          5.224212760745749,
          4.563754453387422,
          6.489011491376315,
          5.16329984904586,
          5.325812714994953,
          5.185541562640342,
          5.755940445804383,
          6.385060155807451,
          5.471331566024917,
          5.861652765979109,
          7.106124588682201,
          6.411548233849724,
          5.9609622245424605,
          5.465755695316209,
          5.257868111773323,
          1.882876897469373,
          5.148691730018548,
          3.760591875022651,
          2.705526742705548,
          3.0052036343687383,
          3.243386772793832,
          2.704448721078238,
          3.3203465590309227,
          2.56481870883986,
          2.9650549097408563,
          3.273364211255123,
          2.614484428922803,
          2.9362956482562774,
          5.0206156184453645,
          4.175815962476762,
          4.62150791336156,
          2.779610163101862,
          3.011766995089331,
          1.852348081079586,
          4.075346248208989,
          2.684771894140851,
          3.3536530565229454,
          2.956878913521384,
          1.8994941004468975,
          3.2232858792992727,
          3.4162538334100967,
          2.060265337862312,
          4.092511560670714,
          3.3130079427622197,
          3.3398280166460013,
          2.3445657875294437,
          3.85766014351377,
          3.8001446277937077,
          2.059262750556328,
          4.935456357100617,
          3.6732291479301624,
          2.7844772407022003,
          2.814190620545464,
          3.061179701426394,
          3.672118404744192,
          2.9721985746716015,
          2.8914726622069495,
          3.547337056190139,
          3.05548891698991,
          3.891340709671834,
          3.2822242623914595,
          3.4819883541640966,
          3.6003594839401125,
          3.2772443001870313,
          4.830719898956482,
          3.9313222805982897,
          4.003751702512639,
          3.3590950963476947,
          5.258588301373318,
          4.9254058880604195,
          5.442230840788944,
          5.0680138610879135,
          4.604313328348002,
          4.647197991920083,
          4.980908257166733,
          3.915194041279194,
          4.830402423148313,
          3.9641263220176457,
          4.78903814677877,
          4.27258356214735,
          4.518175126875421,
          5.657929864723763,
          4.436354196988633,
          5.3092387031219035,
          4.531303321081001,
          4.698684956879688,
          5.632036137743925,
          4.848493080941573,
          6.6000752244559395,
          5.550517422513693,
          4.850588159331467,
          5.20704746954577,
          5.03901838670389,
          5.251547081792048,
          5.0013495309136,
          4.909348596868404,
          5.385219159286961,
          4.881663465981922,
          4.954021414723175,
          5.857492203587804,
          4.880038623826361,
          5.613548401306365,
          5.318168092536822,
          4.9971625859707585,
          5.590426051415693,
          5.564864020738921,
          5.1817761490442225,
          5.416081457248413,
          5.434778304842039,
          6.120748052557515,
          4.748057637048713,
          4.9952532126856015,
          4.7066378115538186,
          5.109098986449491,
          4.7579461413076825,
          5.630789134251003,
          4.8908895294365,
          5.314926988623614,
          4.677709509896385,
          5.099781617969925,
          5.0481791145789945,
          5.9347693467816285,
          5.405709623993756,
          5.187258176839707,
          5.2595623794377255,
          5.345325711969659,
          4.3696479612680115,
          4.806551590493572,
          4.694851858843775,
          5.074829516131799,
          4.3990653628734755,
          6.050332283001256,
          4.801792764798532,
          5.833354527794984,
          4.912762032697542,
          6.515954332577452,
          5.764627090959541,
          6.368422187902436,
          5.479734884065641,
          5.498923538869745,
          5.56983633007793,
          5.247813839616129,
          5.724158903850135,
          4.927554342165454,
          5.21059031737619,
          4.9929982590655735,
          5.327175471244005,
          5.421723961895963,
          5.2048616116588455,
          5.600610412054845,
          5.510500364448419,
          5.3161629893063616,
          6.053760604682234,
          5.572561196538912,
          6.168656715863926,
          5.774196431321574,
          6.237608374873407,
          5.657169507072058,
          6.175854060965769,
          6.048569577768332,
          6.465392575403245,
          5.620921822419419,
          5.359031751093319,
          6.554903031547757,
          5.7612075463352745,
          5.650903236481791,
          6.570090586330926,
          5.695758061445761,
          5.684957296365149,
          6.622338861133272,
          7.31999198487407,
          6.527672869929797,
          6.614415045865443,
          6.495082536597526,
          6.4573617509516925,
          6.4965910750206355,
          6.834986785302191,
          6.477744504384005,
          7.584075088328166,
          6.59341403739026,
          7.369696585749456,
          6.8238032708784155,
          7.052538557949666,
          7.333774397994781,
          7.175652385261881,
          7.879004451428404,
          7.229737182510105,
          7.5887460742180695,
          7.346188226424641,
          7.065483172519803,
          8.112882827429631,
          7.505362671731993,
          8.96048091459357,
          8.090004232599444,
          8.105027722718035,
          7.886271644184312,
          8.595381911684798,
          8.12863339317584,
          8.63479147006046,
          8.429782504108353,
          8.490168432668334,
          8.803140807933742,
          8.399852700472136,
          9.089315767726346,
          8.717177187138342,
          9.037708820761933,
          8.737538136030505,
          9.258515144384171,
          9.206587055591644,
          9.14019658366953,
          9.425771227655698,
          8.886399420888598,
          8.715843926603474,
          8.77731969494985,
          8.985808528374262,
          8.82379686134034,
          9.434874020766463,
          9.100092521783854,
          9.082017791811952,
          9.147797730654391,
          8.92208539077066,
          9.329354060168509,
          9.111163104740173,
          9.438318592827017,
          9.278625282608662,
          9.323769187246,
          9.273871924997405,
          9.599466364177955,
          8.956382966753763,
          8.771425015981736,
          9.776718154903312,
          9.527863320801547,
          9.596672061230512,
          9.450687808939575,
          9.006732286944434,
          9.138193659148406,
          8.579306333030978,
          8.811865359264258,
          8.893699502784264,
          8.908828793814275,
          8.68681850264472,
          9.57979436911336,
          9.543031324235686,
          9.129514543606975,
          8.826441887519495,
          9.479677229377467,
          9.422421236865297,
          9.467705109072869,
          9.389212246099081,
          10.00587546340419,
          10.260800741543274,
          9.822979989121148,
          10.065248602683118,
          9.644894771473325,
          9.687270203253041,
          9.839197057345144,
          10.006161809812886,
          9.781115755133039,
          10.159452155493078,
          9.940638193419666,
          10.503333467021244,
          10.04039554648673,
          10.174568597392692,
          10.231623539286316,
          10.239553779338497,
          10.678565237168472,
          10.347833875524078,
          10.442433443142626,
          10.401603279516785,
          10.834194621068065,
          10.30009865814557,
          10.651430302679378,
          10.331644643719258,
          10.998664262527095,
          10.684911527095993,
          10.785017603993477,
          10.664059405062165,
          10.701378606438267,
          11.350513756131024,
          11.021231478229252,
          11.031735635929689,
          11.10702642194566,
          11.855232380584475,
          11.394836953529374,
          11.095993425664732,
          11.36435295883462,
          11.31484321032936,
          11.272519967379562,
          11.170094767144084,
          11.69368414162909,
          11.4877696264076,
          11.502239523133234,
          11.365312890442091,
          11.993660622280343,
          11.518281268091465,
          11.556895750115704,
          11.484979596681875,
          11.557621561832972,
          11.122068553016016,
          11.131839104029334,
          11.522440866088793,
          11.086054549350125,
          10.996805028050506,
          11.478862222193722,
          10.818865011362538,
          11.16353167988985,
          10.654702627427099,
          11.371189940643628,
          10.918167112234249,
          11.204684417948013,
          10.772252402435278,
          10.765689029382912,
          10.48639854867464,
          10.64669169288561,
          11.150332593973907,
          10.785168593650265,
          10.777368089964499,
          10.733083178189455,
          10.705056619316125,
          11.154915004672151,
          10.688719535716398,
          10.606922820504835,
          10.234387478933641,
          10.873696859180232,
          10.8580681067183,
          10.774956230394778,
          11.126216030675092,
          11.038911760104192,
          10.721281095868349,
          10.741806943450326,
          11.05875790396511,
          10.960405529129678,
          11.010931694458334,
          10.971094766134255,
          11.226930680150309,
          10.922081421771926,
          11.551111231155964,
          11.185959993269615,
          11.18677524706051,
          11.411669064744954,
          11.826082843345455,
          11.483712943622596,
          11.948202151235618,
          12.390866356266208,
          11.967248575148545,
          11.669774824583529,
          11.667183401807321,
          11.793342796450373,
          11.982832320983439,
          12.067605892666096,
          12.200175069160563,
          12.002279688178643,
          11.916193037656747,
          12.036068964912458,
          12.217606831903137,
          11.951558270955218,
          12.320588737904687,
          12.187247446257084,
          12.284594650301187,
          12.011868696302693,
          12.355997581288577,
          12.100618792754512,
          12.35426204930582,
          12.225073586810158,
          12.233210000455127,
          12.511544973071842,
          12.878126826145154,
          12.486038574872046,
          13.256804363378505,
          12.54197814457461,
          12.702308542156496,
          12.934172276512852,
          12.48291701621248,
          12.42905189593082,
          12.392133643112412,
          12.728840384940648,
          12.567049933820071,
          12.64294101250048,
          12.588780770447034,
          12.98178590359328,
          12.578103570553798,
          12.661307613912864,
          12.49712849800207,
          13.325446232303975,
          13.059136417560795,
          13.07498932811194,
          12.887901123649224,
          12.84622527713759,
          13.269300836626671,
          12.765282244437522,
          12.620622921323362,
          13.150465167219775,
          12.881783374959792,
          12.851017995135232,
          13.228437124344406,
          13.290435157620504,
          12.813992756858715,
          13.243088018411402,
          12.893174568350826,
          13.258783014820251,
          12.970291759572284,
          12.885145142437969,
          13.115207638235827,
          12.962903576703575,
          13.33423231346987,
          13.07807734870942,
          13.532095284971119,
          13.31051654110615,
          13.251423441741371,
          14.155472066352628,
          13.804048718603337,
          14.247769449032585,
          13.934257753836148,
          13.309519241426617,
          13.153854568743185,
          13.144145649414469,
          13.44925831685332,
          13.222564860537773,
          13.216850631827816,
          13.593278348036012,
          13.54386285011968,
          13.556874030119287,
          13.63678884658922,
          13.398311468135603,
          12.881035526734133,
          12.948145189093875,
          13.065347114254196,
          12.907884727934466,
          12.954067781570116,
          13.128143750268784,
          13.4016118635898,
          13.188147256646234,
          13.480000545336669,
          13.519831645642606,
          13.402860356768041,
          13.54289609586356,
          13.857944206351066,
          13.583464083249469,
          13.734010621768359,
          13.971855031807856,
          13.756351969901665,
          14.163761899497786,
          14.2309092506284,
          14.738348322850934,
          14.40980342807115,
          14.545997337541642,
          14.823031295130043,
          14.80642944564358,
          14.89118388593264,
          14.741357369121202,
          14.75210601879452,
          14.838315723432105,
          14.783016175226923,
          15.225755348105272,
          15.020616642892996,
          14.974477163491681,
          14.806010652551889,
          15.182412338250296,
          15.143969787220897,
          15.045469256873329,
          15.568351872352578,
          15.314529771251243,
          15.316676986666035,
          15.315087530487459,
          15.37298902835201,
          15.578375144903433,
          15.408364184585333,
          15.359525168442099,
          15.954591549480366,
          15.602085694084444,
          15.713438073659153,
          15.76138958831856,
          15.58762232367425,
          15.511123605961524,
          15.454934527378892,
          16.132602318771333,
          15.86324934467033,
          15.6678188544472,
          15.946669313530904,
          15.774371096263751,
          16.14339598592111,
          15.873499612468596,
          16.325729695019593,
          15.99052113035862,
          15.715197813050366,
          15.667144659598563,
          16.071663318764354,
          16.00373072562804,
          16.22628218912359,
          16.274512061862218,
          16.539092713991437,
          16.276371156984908,
          16.38195838166846,
          16.4081296176987,
          17.121707355875866,
          16.983687339292846,
          17.22756768842005,
          16.830394354927012,
          16.869914455050683,
          16.776053175709187,
          16.599603346972774,
          16.32899352966342,
          16.28282732892051,
          16.617106228672686,
          16.51721250489405,
          16.30346329560622,
          16.209822220966345,
          16.208428651305276,
          15.997215781121055,
          15.592644120014292,
          15.603448447584716,
          15.676792454707206,
          15.839800158409771,
          15.518720766518122,
          15.604274965399526,
          16.037010559585575,
          15.685186292682257,
          15.658185332350447,
          15.509558427231083,
          15.532057557604196,
          15.822553486495268,
          15.561255220556538
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        },
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "Adam",
         "line": {
          "color": "rgba(172, 142, 24, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "Adam",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.2729649,
          0.304959099,
          0.3194018,
          0.33427850000000003,
          0.34627470000000005,
          0.359363099,
          0.3767783,
          0.4091014,
          0.42943149900000005,
          0.4427265,
          0.46602730000000003,
          0.48831509900000003,
          0.5331612,
          0.5529344,
          0.5738894,
          0.5965994,
          0.6551052,
          0.6777986,
          0.7039433,
          0.7429425000000001,
          0.7565889,
          0.7857541,
          0.8111665990000001,
          0.8256203990000001,
          0.8753309,
          0.902424399,
          0.9221822000000001,
          0.9589931,
          0.973958399,
          0.9933919990000001,
          1.019137199,
          1.043984,
          1.0658192,
          1.0933928000000002,
          1.133321099,
          1.1752859,
          1.2013022990000002,
          1.221937,
          1.2444263,
          1.2641703,
          1.3202577,
          1.361808399,
          1.4263162,
          1.4574507,
          1.5140142,
          1.567762499,
          1.5850348,
          1.6212102000000002,
          1.6385900000000002,
          1.6558362000000002,
          1.6697205000000002,
          1.6836781,
          1.6999981000000002,
          1.7195202,
          1.7418885000000002,
          1.7781621,
          1.8225065,
          1.8516314,
          1.8890759990000001,
          1.9147174,
          1.948242999,
          1.980441799,
          2.0669386000000003,
          2.0876887,
          2.136725,
          2.1610529,
          2.2007700000000003,
          2.2258724,
          2.2412832000000003,
          2.2610628,
          2.277262899,
          2.2920368,
          2.3096402,
          2.344273699,
          2.3579934000000002,
          2.3702986000000004,
          2.384085499,
          2.4079559,
          2.4235719000000002,
          2.463089799,
          2.4795181,
          2.5005876000000002,
          2.5136324990000003,
          2.531735899,
          2.5480759,
          2.563667,
          2.5766337000000004,
          2.5910982000000002,
          2.630361599,
          2.6681973,
          2.6836828,
          2.7004571000000004,
          2.7147569000000003,
          2.7319832,
          2.7475564990000003,
          2.762578999,
          2.779281799,
          2.794761899,
          2.8088156,
          2.8229179
         ],
         "xaxis": "x1",
         "y": [
          43.243496620879306,
          43.22407893833289,
          43.20469991570212,
          43.185620889598454,
          43.166218781279625,
          43.14675625724949,
          43.12773200194834,
          43.108674098054415,
          43.09034929373858,
          43.072085278406206,
          43.05375320450314,
          43.03568871371147,
          43.01763768522146,
          42.99969290002764,
          42.98191687263807,
          42.96426140045335,
          42.946866383605425,
          42.92978311539035,
          42.912797095995,
          42.89577981209741,
          42.87898951632773,
          42.86241889201015,
          42.84586495278087,
          42.82929000362903,
          42.81283070478028,
          42.79655679324898,
          42.78042551350142,
          42.76456467491796,
          42.74887480733623,
          42.733205023611035,
          42.71755107637868,
          42.70230983021206,
          42.687225377713794,
          42.672302598402666,
          42.65758300557957,
          42.64310971463244,
          42.628646975361676,
          42.61441795885571,
          42.600419545210904,
          42.58649557332512,
          42.57276378787025,
          42.55927883893515,
          42.5459906729311,
          42.53272794617148,
          42.519866550252864,
          42.507189896748976,
          42.49455438825642,
          42.48213568157383,
          42.47013387526309,
          42.45830752101615,
          42.44650198686186,
          42.43475488399362,
          42.423070390024655,
          42.41148583995072,
          42.399825582784246,
          42.3881755046444,
          42.37667816063789,
          42.365292561080366,
          42.35402866626504,
          42.34273800620095,
          42.331337194478635,
          42.32004830694491,
          42.309016895818075,
          42.29817855020021,
          42.287244312079665,
          42.27664222080467,
          42.266078646970456,
          42.25548255162069,
          42.2447950029173,
          42.23451992253386,
          42.2242623090953,
          42.21431516742083,
          42.20426284858998,
          42.19422722166679,
          42.1843145624683,
          42.17448893870125,
          42.16460200524902,
          42.15480018133486,
          42.14521446007081,
          42.135770076983164,
          42.12623492969965,
          42.11674359908196,
          42.10734437685506,
          42.0982433400036,
          42.08924433098314,
          42.080356957742325,
          42.07156699971618,
          42.0626720665074,
          42.053662046107746,
          42.04442082606069,
          42.03513866722458,
          42.02601621202981,
          42.01729282275695,
          42.00857312824603,
          41.99994594139666,
          41.99125049398336,
          41.9823802740147,
          41.973658153856285,
          41.96496756926067,
          41.95638699239753,
          41.94807776277141
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        }
       ],
       "layout": {
        "annotations": [],
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 1.000)",
         "bordercolor": "rgba(0, 0, 0, 1.000)",
         "font": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tracegroupgap": 0,
         "x": 1,
         "y": 1
        },
        "margin": {
         "b": 20,
         "l": 0,
         "r": 0,
         "t": 20
        },
        "paper_bgcolor": "rgba(255, 255, 255, 1.000)",
        "plot_bgcolor": "rgba(255, 255, 255, 1.000)",
        "showlegend": true,
        "width": 600,
        "xaxis": {
         "anchor": "y1",
         "domain": [
          0.03619130941965587,
          0.9934383202099738
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          -3.61237789197,
          124.02497429097001
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "0",
          "25",
          "50",
          "75",
          "100"
         ],
         "tickvals": [
          0,
          25,
          50,
          75,
          100
         ],
         "title": "",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        },
        "yaxis": {
         "anchor": "x1",
         "domain": [
          0.03762029746281716,
          0.9901574803149606
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          -0.011528724772529308,
          44.50335172803421
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "0",
          "10",
          "20",
          "30",
          "40"
         ],
         "tickvals": [
          0,
          10,
          20,
          30,
          40
         ],
         "title": "",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        }
       }
      },
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "    <head>\n",
       "        <title>Plots.jl</title>\n",
       "        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
       "    </head>\n",
       "    <body>\n",
       "            <div id=\"24628e7e-33be-40c7-9edb-6ac60cb0cde1\" style=\"width:600px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('24628e7e-33be-40c7-9edb-6ac60cb0cde1');\n",
       "    Plotly.plot(PLOT, [\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.028951099,\n",
       "            0.031026,\n",
       "            0.046391100000000005,\n",
       "            0.1452564,\n",
       "            0.30891280000000004,\n",
       "            0.43125250000000004,\n",
       "            0.5498359,\n",
       "            0.7212557,\n",
       "            0.8437945,\n",
       "            0.9149322000000001,\n",
       "            0.9213070000000001,\n",
       "            1.1209484,\n",
       "            1.2817927,\n",
       "            1.2860497000000002,\n",
       "            1.2889731,\n",
       "            1.4560411000000002,\n",
       "            1.4595765,\n",
       "            1.5123583,\n",
       "            1.514334799,\n",
       "            1.6843022,\n",
       "            1.8008465,\n",
       "            1.878759,\n",
       "            1.9159902990000002,\n",
       "            2.0737358,\n",
       "            2.0784138000000003,\n",
       "            2.109887,\n",
       "            2.2426001,\n",
       "            2.3217861,\n",
       "            2.4607755,\n",
       "            2.4928903,\n",
       "            2.7060979,\n",
       "            2.8673978,\n",
       "            2.9188357000000003,\n",
       "            2.9598429000000004,\n",
       "            2.9946921,\n",
       "            3.1354713000000003,\n",
       "            3.3215253000000002,\n",
       "            3.4075921,\n",
       "            3.4135421000000004,\n",
       "            3.6062049000000003,\n",
       "            3.6602147,\n",
       "            3.8250037000000003,\n",
       "            3.8481139000000004,\n",
       "            4.0014859000000005,\n",
       "            4.113540100000001,\n",
       "            4.3638959,\n",
       "            4.4281856,\n",
       "            4.457624200000001,\n",
       "            4.590722100000001,\n",
       "            4.736018799,\n",
       "            4.9618928,\n",
       "            4.992293,\n",
       "            5.0691844,\n",
       "            5.075886199,\n",
       "            5.121241099000001,\n",
       "            5.2543785000000005,\n",
       "            5.296353300000001,\n",
       "            5.419961000000001,\n",
       "            5.489815800000001,\n",
       "            5.703805,\n",
       "            5.774078,\n",
       "            5.9139682,\n",
       "            6.0668791,\n",
       "            6.184329799,\n",
       "            6.3563846,\n",
       "            6.4154127,\n",
       "            6.503029199,\n",
       "            6.6810131,\n",
       "            6.863114099000001,\n",
       "            7.0019406,\n",
       "            7.174456,\n",
       "            7.2837003000000005,\n",
       "            7.4083503,\n",
       "            7.456937000000001,\n",
       "            7.682263600000001,\n",
       "            7.7911985,\n",
       "            7.969227200000001,\n",
       "            8.065038000000001,\n",
       "            8.2698902,\n",
       "            8.403718600000001,\n",
       "            8.5425479,\n",
       "            8.676073699,\n",
       "            8.760623200000001,\n",
       "            8.865948900000001,\n",
       "            9.1326626,\n",
       "            9.161282700000001,\n",
       "            9.333368,\n",
       "            9.4699924,\n",
       "            9.6516239,\n",
       "            9.7506623,\n",
       "            9.925135200000001,\n",
       "            10.3040417,\n",
       "            10.4221456,\n",
       "            10.564974300000001,\n",
       "            10.6427783,\n",
       "            10.9171581,\n",
       "            11.055684600000001,\n",
       "            11.4856052,\n",
       "            11.9150305,\n",
       "            12.229078299000001,\n",
       "            12.447800500000001,\n",
       "            12.925536899,\n",
       "            13.284064999000002,\n",
       "            13.5310103,\n",
       "            14.033294600000001,\n",
       "            14.7347838,\n",
       "            15.2088885,\n",
       "            15.6779951,\n",
       "            16.005467799,\n",
       "            16.5789186,\n",
       "            17.352063700000002,\n",
       "            18.007499000000003,\n",
       "            18.499450299,\n",
       "            18.816471200000002,\n",
       "            19.454051699,\n",
       "            20.3459788,\n",
       "            21.118444200000003,\n",
       "            21.6022921,\n",
       "            22.541036299,\n",
       "            23.149169500000003,\n",
       "            24.0127841,\n",
       "            24.589009400000002,\n",
       "            25.3130853,\n",
       "            25.898917200000003,\n",
       "            26.377033200000003,\n",
       "            26.735717500000003,\n",
       "            26.9944385,\n",
       "            27.2482526,\n",
       "            27.7108035,\n",
       "            28.3205646,\n",
       "            28.985231399000003,\n",
       "            29.432001900000003,\n",
       "            29.9909517,\n",
       "            30.712026400000003,\n",
       "            31.2507948,\n",
       "            31.677040700000003,\n",
       "            32.467490899000005,\n",
       "            33.194005799,\n",
       "            33.6881871,\n",
       "            34.514043499,\n",
       "            35.1594895,\n",
       "            36.0226532,\n",
       "            36.801492999000004,\n",
       "            38.1946061,\n",
       "            39.2485611,\n",
       "            40.0125137,\n",
       "            41.4176056,\n",
       "            42.612678499000005,\n",
       "            44.089058199,\n",
       "            45.231945199,\n",
       "            46.0790396,\n",
       "            47.5242379,\n",
       "            49.2687851,\n",
       "            50.56918700000001,\n",
       "            51.6125929,\n",
       "            52.459180399000005,\n",
       "            53.1037334,\n",
       "            53.5912458,\n",
       "            53.967686400000005,\n",
       "            54.6097849,\n",
       "            55.64872020000001,\n",
       "            56.463711700000005,\n",
       "            57.102518199,\n",
       "            58.012054000000006,\n",
       "            58.989840400000006,\n",
       "            59.6863875,\n",
       "            60.219311000000005,\n",
       "            61.215764500000006,\n",
       "            62.011559499,\n",
       "            62.6141578,\n",
       "            63.176583,\n",
       "            64.0497915,\n",
       "            64.69464620000001,\n",
       "            65.2794674,\n",
       "            66.2769765,\n",
       "            67.0448143,\n",
       "            67.683318799,\n",
       "            68.76704570000001,\n",
       "            69.907879599,\n",
       "            70.781227199,\n",
       "            71.4324757,\n",
       "            72.0224633,\n",
       "            72.72717940000001,\n",
       "            73.46209389900001,\n",
       "            74.66591910000001,\n",
       "            75.59207430000001,\n",
       "            76.33412410000001,\n",
       "            77.5087955,\n",
       "            78.388967799,\n",
       "            79.8655925,\n",
       "            81.109682799,\n",
       "            83.28142410000001,\n",
       "            85.300773,\n",
       "            87.2266438,\n",
       "            88.3650305,\n",
       "            89.810261799,\n",
       "            91.04032589900001,\n",
       "            92.1248297,\n",
       "            92.9489104,\n",
       "            94.04960549900001,\n",
       "            95.65968170000001,\n",
       "            97.0533087,\n",
       "            98.132065299,\n",
       "            99.88273059900001,\n",
       "            101.3416933,\n",
       "            102.62263490000001,\n",
       "            103.6486423,\n",
       "            105.18757570000001,\n",
       "            106.4483986,\n",
       "            107.410989599,\n",
       "            108.67118310000001,\n",
       "            110.3070107,\n",
       "            112.6945663,\n",
       "            114.61384190000001,\n",
       "            116.16653329900001,\n",
       "            117.22802220000001,\n",
       "            118.77376480000001,\n",
       "            120.41259639900001\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"BHHH sHs\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"BHHH sHs\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(0, 154, 250, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            43.243496620879306,\n",
       "            43.18590621572114,\n",
       "            43.09956835229021,\n",
       "            42.96783855629635,\n",
       "            42.768399150183896,\n",
       "            42.46945545851414,\n",
       "            42.018294224409736,\n",
       "            41.34099588842537,\n",
       "            40.32886059900783,\n",
       "            38.81925494424295,\n",
       "            38.81925494424295,\n",
       "            38.81925494424295,\n",
       "            38.418095364300505,\n",
       "            37.999855654711475,\n",
       "            37.7227176697646,\n",
       "            37.53170536098115,\n",
       "            37.171556292478265,\n",
       "            37.0495710079372,\n",
       "            36.714379527487694,\n",
       "            36.714379527487694,\n",
       "            36.572000867708745,\n",
       "            36.465250390661694,\n",
       "            36.17787185777916,\n",
       "            36.17787185777916,\n",
       "            36.04004602310698,\n",
       "            35.919519668182225,\n",
       "            35.82254048453125,\n",
       "            35.58050551543698,\n",
       "            35.48982704280461,\n",
       "            35.28895360589955,\n",
       "            35.1674079524948,\n",
       "            35.0031723303484,\n",
       "            34.758668290253055,\n",
       "            34.66424637724405,\n",
       "            34.50621276633283,\n",
       "            34.34560062580966,\n",
       "            34.229081683298816,\n",
       "            34.1506588303662,\n",
       "            34.036676079386936,\n",
       "            33.83890267192525,\n",
       "            33.419362237836644,\n",
       "            33.352357291175,\n",
       "            33.07545140900681,\n",
       "            33.00688741188622,\n",
       "            32.8745135551243,\n",
       "            32.7700697120328,\n",
       "            32.64434357009444,\n",
       "            32.55420215058093,\n",
       "            32.460564317389355,\n",
       "            32.3702504852056,\n",
       "            32.22692740206002,\n",
       "            32.0437360849622,\n",
       "            31.973604491066464,\n",
       "            31.866164855875436,\n",
       "            31.866164855875436,\n",
       "            31.790857641120585,\n",
       "            31.568152581127347,\n",
       "            31.52957751117503,\n",
       "            31.30161798770382,\n",
       "            31.210749399609394,\n",
       "            31.12327668410524,\n",
       "            30.99999147326802,\n",
       "            30.916147641936465,\n",
       "            30.83997109962959,\n",
       "            30.736810654444863,\n",
       "            30.634412118757407,\n",
       "            30.55959536446994,\n",
       "            30.44654122029495,\n",
       "            30.270397664274313,\n",
       "            30.067983969513197,\n",
       "            30.02036305619446,\n",
       "            29.929919641742543,\n",
       "            29.825165132578785,\n",
       "            29.739332582826577,\n",
       "            29.649513014160917,\n",
       "            29.443380583615806,\n",
       "            29.398862607450887,\n",
       "            29.231010836723872,\n",
       "            29.197431771790693,\n",
       "            28.97405320570511,\n",
       "            28.921920519982226,\n",
       "            28.801263418449988,\n",
       "            28.71871014777222,\n",
       "            28.63606035226542,\n",
       "            28.560200537007272,\n",
       "            28.508426315971136,\n",
       "            28.42470845984069,\n",
       "            28.305208086731696,\n",
       "            28.27734187413566,\n",
       "            28.152319294836726,\n",
       "            28.10883777751775,\n",
       "            27.911944359493525,\n",
       "            27.768201016487872,\n",
       "            27.716178348883126,\n",
       "            27.631844020061422,\n",
       "            27.502850492050694,\n",
       "            27.302386655467334,\n",
       "            27.265101069142126,\n",
       "            27.012598054621655,\n",
       "            26.90626016268151,\n",
       "            26.86045953850945,\n",
       "            26.73457131074285,\n",
       "            26.4789478122845,\n",
       "            26.432696421165076,\n",
       "            26.28887489628087,\n",
       "            26.094709712842803,\n",
       "            25.993359647002688,\n",
       "            25.951777568879965,\n",
       "            25.84882078602034,\n",
       "            25.621980551454506,\n",
       "            25.48308140554369,\n",
       "            25.3682035951309,\n",
       "            25.32977083687996,\n",
       "            25.22676824475649,\n",
       "            25.08818280766363,\n",
       "            24.92897249307845,\n",
       "            24.822336444241518,\n",
       "            24.78206301903842,\n",
       "            24.679198735369145,\n",
       "            24.449976583780057,\n",
       "            24.32961434977839,\n",
       "            24.236517010463544,\n",
       "            24.159072504837912,\n",
       "            24.081346063267798,\n",
       "            24.048773904034274,\n",
       "            23.98431121008631,\n",
       "            23.930353624852238,\n",
       "            23.87612690900907,\n",
       "            23.78589163660954,\n",
       "            23.59862561210218,\n",
       "            23.500819895516834,\n",
       "            23.416917086325107,\n",
       "            23.343988427466368,\n",
       "            23.25513891773298,\n",
       "            23.172720104115445,\n",
       "            23.13948293190087,\n",
       "            23.078608162833895,\n",
       "            22.909484403619977,\n",
       "            22.882807145593212,\n",
       "            22.810630357718555,\n",
       "            22.703316899836466,\n",
       "            22.67939947689285,\n",
       "            22.52169004693593,\n",
       "            22.44028368001841,\n",
       "            22.371666917113593,\n",
       "            22.34315040895623,\n",
       "            22.281483540702254,\n",
       "            22.123680839704015,\n",
       "            22.06377429738082,\n",
       "            21.990939334055202,\n",
       "            21.960324898863114,\n",
       "            21.89828577611098,\n",
       "            21.729145459063993,\n",
       "            21.66264217692618,\n",
       "            21.605043276114184,\n",
       "            21.5370253549851,\n",
       "            21.475324943846886,\n",
       "            21.448582103449166,\n",
       "            21.403802573507924,\n",
       "            21.330369609910225,\n",
       "            21.173398480203222,\n",
       "            21.0835147077509,\n",
       "            21.00080565243607,\n",
       "            20.911787653457157,\n",
       "            20.824845615844577,\n",
       "            20.772329540982202,\n",
       "            20.745032000063212,\n",
       "            20.692113586956495,\n",
       "            20.566973514044324,\n",
       "            20.542024469127526,\n",
       "            20.48056304752617,\n",
       "            20.345613620850838,\n",
       "            20.25179119008625,\n",
       "            20.17012174672612,\n",
       "            20.08789069890564,\n",
       "            20.0120848651983,\n",
       "            19.98695653291627,\n",
       "            19.937722039538077,\n",
       "            19.816377071051143,\n",
       "            19.751086699674847,\n",
       "            19.725200759623394,\n",
       "            19.674246388168722,\n",
       "            19.555867206863205,\n",
       "            19.465428633144395,\n",
       "            19.387637184693915,\n",
       "            19.31512559294453,\n",
       "            19.292638398679202,\n",
       "            19.248219369794786,\n",
       "            19.14012793974831,\n",
       "            19.074612469418355,\n",
       "            19.005021912341537,\n",
       "            18.942257364584357,\n",
       "            18.886009604022913,\n",
       "            18.865073755285106,\n",
       "            18.794890681158837,\n",
       "            18.647765201207328,\n",
       "            18.553230007127137,\n",
       "            18.479220464592903,\n",
       "            18.406069459938365,\n",
       "            18.335072276343237,\n",
       "            18.27259249602427,\n",
       "            18.2187578711812,\n",
       "            18.19621400017312,\n",
       "            18.151576783708034,\n",
       "            18.04524225847387,\n",
       "            17.998069354595817,\n",
       "            17.941824582772636,\n",
       "            17.881923876164525,\n",
       "            17.818354257052,\n",
       "            17.802664764042046,\n",
       "            17.72263712394546,\n",
       "            17.661254651082913,\n",
       "            17.607457256027704,\n",
       "            17.56207324042588,\n",
       "            17.522413385843,\n",
       "            17.503657524353528,\n",
       "            17.45877892266684,\n",
       "            17.38623009924475,\n",
       "            17.339652168087916\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    },\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.17369410000000002,\n",
       "            0.18485029900000002,\n",
       "            0.2063202,\n",
       "            0.3876198,\n",
       "            0.532660499,\n",
       "            0.6470128,\n",
       "            0.785217,\n",
       "            0.8842850000000001,\n",
       "            1.0164695990000001,\n",
       "            1.0527704,\n",
       "            1.1737328,\n",
       "            1.2018503,\n",
       "            1.3008493,\n",
       "            1.419470999,\n",
       "            1.434797499,\n",
       "            1.436035599,\n",
       "            1.5419207000000001,\n",
       "            1.645865399,\n",
       "            1.8780564000000002,\n",
       "            2.0374865\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"BHHH tv\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"BHHH tv\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(227, 111, 71, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            43.243496620879306,\n",
       "            43.18590621572114,\n",
       "            43.100474406358835,\n",
       "            42.97398929207457,\n",
       "            42.78113566034097,\n",
       "            42.48917007819054,\n",
       "            42.05128860568391,\n",
       "            41.390292687468154,\n",
       "            40.40337145140512,\n",
       "            38.94878703151555,\n",
       "            38.94878703151555,\n",
       "            38.55571835638938,\n",
       "            38.19337310193117,\n",
       "            37.895846910455234,\n",
       "            37.4492345064511,\n",
       "            37.17918842548385,\n",
       "            37.17918842548385,\n",
       "            36.99195733535648,\n",
       "            36.840053429990796,\n",
       "            36.68988469326428,\n",
       "            36.48819567073133\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    },\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.209733299,\n",
       "            0.249059,\n",
       "            0.29550249900000003,\n",
       "            0.408523499,\n",
       "            0.568902099,\n",
       "            0.7076244,\n",
       "            0.8469837,\n",
       "            0.9578208990000001,\n",
       "            1.121287999,\n",
       "            1.1397665000000001,\n",
       "            1.1683168000000002,\n",
       "            1.4055315000000002,\n",
       "            1.580116199,\n",
       "            1.7767686,\n",
       "            1.9659655,\n",
       "            2.137157099,\n",
       "            2.434360099,\n",
       "            2.4969266,\n",
       "            2.5378836000000002,\n",
       "            2.559651599\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"Hes tv\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"Hes tv\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(62, 164, 78, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            43.243496620879306,\n",
       "            43.18590621572114,\n",
       "            43.09973452725706,\n",
       "            42.96950438391258,\n",
       "            42.77454112524566,\n",
       "            42.482427467821815,\n",
       "            42.03991953825041,\n",
       "            40.78149849120286,\n",
       "            38.97104676546119,\n",
       "            36.540772738691,\n",
       "            36.540772738691,\n",
       "            36.540772738691,\n",
       "            36.163907410522796,\n",
       "            35.82017492584406,\n",
       "            35.49781304133694,\n",
       "            35.20798020173169,\n",
       "            34.83117665656368,\n",
       "            34.19754666625386,\n",
       "            32.866346861510564,\n",
       "            31.424583144551704,\n",
       "            27.845214615020552\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    },\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.8762630990000001,\n",
       "            1.0486858000000001,\n",
       "            1.198554799,\n",
       "            1.4055425000000001,\n",
       "            1.6074843,\n",
       "            1.7540329000000001,\n",
       "            1.9502664,\n",
       "            2.120530799,\n",
       "            2.3026288000000004,\n",
       "            2.4838987,\n",
       "            2.589203699,\n",
       "            2.8049155000000003,\n",
       "            2.9320727,\n",
       "            2.9714974,\n",
       "            3.0842569990000004,\n",
       "            3.2111636000000003,\n",
       "            3.3506341,\n",
       "            3.4907365990000003,\n",
       "            3.5961006,\n",
       "            3.7930689990000004,\n",
       "            3.9248878990000002,\n",
       "            3.9427361000000003,\n",
       "            4.0593007000000005,\n",
       "            4.2319334,\n",
       "            4.429452099000001,\n",
       "            4.5600225000000005,\n",
       "            4.725327500000001,\n",
       "            4.8614445,\n",
       "            5.028804599,\n",
       "            5.057801099000001,\n",
       "            5.1871974000000005,\n",
       "            5.316583799,\n",
       "            5.4919947,\n",
       "            5.6551524,\n",
       "            5.7748869,\n",
       "            5.939776800000001,\n",
       "            6.0916978,\n",
       "            6.305307,\n",
       "            6.4327899,\n",
       "            6.6218253,\n",
       "            6.754254400000001,\n",
       "            6.9158511,\n",
       "            7.0894127000000005,\n",
       "            7.1071375990000005,\n",
       "            7.256495200000001,\n",
       "            7.379185400000001,\n",
       "            7.4931412,\n",
       "            7.610903400000001,\n",
       "            7.804367899000001,\n",
       "            7.9097856,\n",
       "            8.0520805,\n",
       "            8.0843684,\n",
       "            8.255606099000001,\n",
       "            8.404055000000001,\n",
       "            8.534606100000001,\n",
       "            8.652867200000001,\n",
       "            8.8525389,\n",
       "            8.9779918,\n",
       "            9.0330385,\n",
       "            9.154501699,\n",
       "            9.294238,\n",
       "            9.452529699000001,\n",
       "            9.564264000000001,\n",
       "            9.6841585,\n",
       "            9.7079369,\n",
       "            9.8561408,\n",
       "            9.9549514,\n",
       "            10.0876713,\n",
       "            10.214286899000001,\n",
       "            10.3141572,\n",
       "            10.436802400000001,\n",
       "            10.581230599000001,\n",
       "            10.750874099,\n",
       "            10.9673554,\n",
       "            11.035861799000001,\n",
       "            11.153172900000001,\n",
       "            11.256066200000001,\n",
       "            11.4354321,\n",
       "            11.554885800000001,\n",
       "            11.760837800000001,\n",
       "            11.9074544,\n",
       "            11.939724100000001,\n",
       "            12.0981977,\n",
       "            12.2370932,\n",
       "            12.359006500000001,\n",
       "            12.470793599,\n",
       "            12.6100659,\n",
       "            12.614076999,\n",
       "            12.733841399000001,\n",
       "            12.893728900000001,\n",
       "            13.0106827,\n",
       "            13.129425000000001,\n",
       "            13.276799,\n",
       "            13.377885500000001,\n",
       "            13.4825286,\n",
       "            13.485190600000001,\n",
       "            13.595366100000001,\n",
       "            13.693931099,\n",
       "            13.811805199,\n",
       "            13.992859200000002,\n",
       "            14.093696900000001,\n",
       "            14.2117286,\n",
       "            14.392397500000001,\n",
       "            14.436712000000002,\n",
       "            14.554985,\n",
       "            14.7084349,\n",
       "            14.868963599,\n",
       "            15.058553700000001,\n",
       "            15.254578500000001,\n",
       "            15.272606799,\n",
       "            15.470820900000001,\n",
       "            15.6235628,\n",
       "            15.7617188,\n",
       "            15.8960138,\n",
       "            16.019628700000002,\n",
       "            16.1899158,\n",
       "            16.2949391,\n",
       "            16.2975983,\n",
       "            16.475478499,\n",
       "            16.6154526,\n",
       "            16.7727015,\n",
       "            16.929238599,\n",
       "            17.0545878,\n",
       "            17.1789908,\n",
       "            17.298726299000002,\n",
       "            17.330182699,\n",
       "            17.481676,\n",
       "            17.6211515,\n",
       "            17.7643612,\n",
       "            17.9288725,\n",
       "            18.0347847,\n",
       "            18.153686,\n",
       "            18.345438700000003,\n",
       "            18.4789888,\n",
       "            18.510538200000003,\n",
       "            18.6573628,\n",
       "            18.822969500000003,\n",
       "            18.977780299000003,\n",
       "            19.1493842,\n",
       "            19.255051,\n",
       "            19.4098201,\n",
       "            19.531427199,\n",
       "            19.577500499000003,\n",
       "            19.7120649,\n",
       "            19.826514499,\n",
       "            19.9572505,\n",
       "            20.057918100000002,\n",
       "            20.191079399,\n",
       "            20.3242845,\n",
       "            20.4443559,\n",
       "            20.6102884,\n",
       "            20.613573999,\n",
       "            20.7131846,\n",
       "            20.8543834,\n",
       "            21.008808999000003,\n",
       "            21.2353747,\n",
       "            21.338163799,\n",
       "            21.437728,\n",
       "            21.5413093,\n",
       "            21.603071099,\n",
       "            21.7401076,\n",
       "            21.937923299,\n",
       "            22.053801799000002,\n",
       "            22.1756645,\n",
       "            22.275311699000003,\n",
       "            22.378481500000003,\n",
       "            22.480401299,\n",
       "            22.5810371,\n",
       "            22.5835721,\n",
       "            22.701059200000003,\n",
       "            22.863661800000003,\n",
       "            22.962971699,\n",
       "            23.0656633,\n",
       "            23.182425799,\n",
       "            23.379449100000002,\n",
       "            23.565456400000002,\n",
       "            23.589639899,\n",
       "            23.719011799,\n",
       "            23.8405302,\n",
       "            23.963405100000003,\n",
       "            24.099289300000002,\n",
       "            24.200761,\n",
       "            24.388312300000003,\n",
       "            24.5367651,\n",
       "            24.674922900000002,\n",
       "            24.745222300000002,\n",
       "            24.9344566,\n",
       "            25.034576099000002,\n",
       "            25.1377513,\n",
       "            25.2876085,\n",
       "            25.471190499000002,\n",
       "            25.626517200000002,\n",
       "            25.795855500000002,\n",
       "            25.814067,\n",
       "            25.915367800000002,\n",
       "            26.065248500000003,\n",
       "            26.279377200000003,\n",
       "            26.3962274,\n",
       "            26.5304046,\n",
       "            26.6959309,\n",
       "            26.8378544,\n",
       "            26.9760533,\n",
       "            26.996555800000003,\n",
       "            27.108435799000002,\n",
       "            27.247860899000003,\n",
       "            27.3870554,\n",
       "            27.5193762,\n",
       "            27.640779299000002,\n",
       "            27.792832099,\n",
       "            27.917137299,\n",
       "            27.9420463,\n",
       "            28.1419587,\n",
       "            28.260902799,\n",
       "            28.3788112,\n",
       "            28.492030300000003,\n",
       "            28.617063,\n",
       "            28.718584099,\n",
       "            28.8421325,\n",
       "            28.980437100000003,\n",
       "            29.0163271,\n",
       "            29.144952999,\n",
       "            29.267283600000003,\n",
       "            29.369866000000002,\n",
       "            29.5468797,\n",
       "            29.6499625,\n",
       "            29.7523687,\n",
       "            29.9039444,\n",
       "            29.925316199,\n",
       "            30.110689200000003,\n",
       "            30.267326,\n",
       "            30.434168699,\n",
       "            30.569648,\n",
       "            30.696987399,\n",
       "            30.8558932,\n",
       "            31.009389399000003,\n",
       "            31.134481299,\n",
       "            31.188471899000003,\n",
       "            31.3425797,\n",
       "            31.4772734,\n",
       "            31.6249143,\n",
       "            31.7254994,\n",
       "            31.826300699,\n",
       "            31.9845705,\n",
       "            32.0852755,\n",
       "            32.1131268,\n",
       "            32.2546004,\n",
       "            32.375701500000005,\n",
       "            32.475638299,\n",
       "            32.6022491,\n",
       "            32.7283665,\n",
       "            32.864000999000005,\n",
       "            33.008385600000004,\n",
       "            33.1872866,\n",
       "            33.203317199000004,\n",
       "            33.340807799000004,\n",
       "            33.4416802,\n",
       "            33.571251700000005,\n",
       "            33.672282499000005,\n",
       "            33.771924699,\n",
       "            33.9209472,\n",
       "            34.026757299,\n",
       "            34.0296678,\n",
       "            34.149349999,\n",
       "            34.248158899,\n",
       "            34.348682399000005,\n",
       "            34.463278399000004,\n",
       "            34.665905599000006,\n",
       "            34.789110499,\n",
       "            34.9457979,\n",
       "            35.1072654,\n",
       "            35.140640000000005,\n",
       "            35.2497983,\n",
       "            35.437699799,\n",
       "            35.580553,\n",
       "            35.725785199,\n",
       "            35.959918900000005,\n",
       "            36.0814557,\n",
       "            36.252656,\n",
       "            36.2826855,\n",
       "            36.4323558,\n",
       "            36.5773643,\n",
       "            36.740892800000005,\n",
       "            36.914163399,\n",
       "            37.069955499,\n",
       "            37.1920469,\n",
       "            37.3377385,\n",
       "            37.502714100000006,\n",
       "            37.5367577,\n",
       "            37.637187899000004,\n",
       "            37.788008299000005,\n",
       "            37.976814100000006,\n",
       "            38.0944591,\n",
       "            38.206459999,\n",
       "            38.3857561,\n",
       "            38.5013062,\n",
       "            38.5599514,\n",
       "            38.714640199,\n",
       "            38.836751500000005,\n",
       "            38.978321400000006,\n",
       "            39.144853299000005,\n",
       "            39.2461502,\n",
       "            39.3492894,\n",
       "            39.450985599,\n",
       "            39.5559012,\n",
       "            39.5782206,\n",
       "            39.678205399,\n",
       "            39.8038838,\n",
       "            39.9064982,\n",
       "            40.0084285,\n",
       "            40.158839900000004,\n",
       "            40.266447400000004,\n",
       "            40.370611600000004,\n",
       "            40.3733451,\n",
       "            40.475327,\n",
       "            40.606900299,\n",
       "            40.818207900000004,\n",
       "            40.9768503,\n",
       "            41.0970486,\n",
       "            41.21528,\n",
       "            41.344913999,\n",
       "            41.526230399,\n",
       "            41.632324699,\n",
       "            41.757385999,\n",
       "            41.8557949,\n",
       "            41.972371800000005,\n",
       "            42.100321,\n",
       "            42.227045199,\n",
       "            42.396405899,\n",
       "            42.517423999,\n",
       "            42.565954100000006,\n",
       "            42.670822499,\n",
       "            42.822599299000004,\n",
       "            42.9530248,\n",
       "            43.093682799,\n",
       "            43.2956556,\n",
       "            43.4592296,\n",
       "            43.5617467,\n",
       "            43.742953899,\n",
       "            43.795401499,\n",
       "            43.936556700000004,\n",
       "            44.0578659,\n",
       "            44.211426100000004,\n",
       "            44.349674500000006,\n",
       "            44.452213500000006,\n",
       "            44.570105500000004,\n",
       "            44.6929243,\n",
       "            44.709913400000005,\n",
       "            44.8507881,\n",
       "            44.9925957,\n",
       "            45.1285886,\n",
       "            45.2844211,\n",
       "            45.45366,\n",
       "            45.610999400000004,\n",
       "            45.8169641,\n",
       "            45.9854563,\n",
       "            46.056301999000006,\n",
       "            46.1749597,\n",
       "            46.381682899000005,\n",
       "            46.5040672,\n",
       "            46.646099699000004,\n",
       "            46.805627900000005,\n",
       "            46.945877,\n",
       "            47.047068699,\n",
       "            47.109970800000006,\n",
       "            47.273971,\n",
       "            47.39641,\n",
       "            47.526514600000006,\n",
       "            47.625299399000006,\n",
       "            47.726553900000006,\n",
       "            47.827934699000004,\n",
       "            47.94847600000001,\n",
       "            48.0550744,\n",
       "            48.058249200000006,\n",
       "            48.157116599000005,\n",
       "            48.357981300000006,\n",
       "            48.513547399000004,\n",
       "            48.653254999000005,\n",
       "            48.78309,\n",
       "            48.8854333,\n",
       "            49.0286495,\n",
       "            49.0316605,\n",
       "            49.128433399,\n",
       "            49.244871399000004,\n",
       "            49.3449704,\n",
       "            49.495848900000006,\n",
       "            49.617505200000004,\n",
       "            49.7182959,\n",
       "            49.820784100000004,\n",
       "            49.926950700000006,\n",
       "            49.9747111,\n",
       "            50.121713,\n",
       "            50.271141300000004,\n",
       "            50.439939399000004,\n",
       "            50.626067600000006,\n",
       "            50.782987499,\n",
       "            50.9644727,\n",
       "            51.082284,\n",
       "            51.0845299,\n",
       "            51.2215471,\n",
       "            51.3356423,\n",
       "            51.4343275,\n",
       "            51.5418414,\n",
       "            51.699710199,\n",
       "            51.837729700000004,\n",
       "            51.939813400000006,\n",
       "            52.0683458,\n",
       "            52.117494499,\n",
       "            52.2897158,\n",
       "            52.426822799,\n",
       "            52.5644222,\n",
       "            52.726962599000004,\n",
       "            52.943947800000004,\n",
       "            53.0984095,\n",
       "            53.2152625,\n",
       "            53.2636514,\n",
       "            53.4140701,\n",
       "            53.530469200000006,\n",
       "            53.658740200000004,\n",
       "            53.813616799,\n",
       "            53.9140522,\n",
       "            54.030796200000005,\n",
       "            54.143422400000006,\n",
       "            54.28597490000001,\n",
       "            54.288557100000006,\n",
       "            54.407219100000006,\n",
       "            54.527783500000005,\n",
       "            54.6653522,\n",
       "            54.79078560000001,\n",
       "            54.942377799000006,\n",
       "            55.048758400000004,\n",
       "            55.152296400000004,\n",
       "            55.154830299000004,\n",
       "            55.255788499000005,\n",
       "            55.375555000000006,\n",
       "            55.5407554,\n",
       "            55.658826000000005,\n",
       "            55.7817385,\n",
       "            55.8844982,\n",
       "            55.9880581,\n",
       "            56.1443097,\n",
       "            56.2490552,\n",
       "            56.394463999,\n",
       "            56.514740299,\n",
       "            56.70048159900001,\n",
       "            56.8488976,\n",
       "            56.9996233,\n",
       "            57.1436895,\n",
       "            57.266783200000006,\n",
       "            57.271756999000004,\n",
       "            57.417186300000004,\n",
       "            57.539357300000006,\n",
       "            57.658060500000005,\n",
       "            57.815261399,\n",
       "            57.9726458,\n",
       "            58.128579199,\n",
       "            58.244838,\n",
       "            58.3836687,\n",
       "            58.4545073,\n",
       "            58.611424899000006,\n",
       "            58.726597500000004,\n",
       "            58.863513099,\n",
       "            58.985052800000005,\n",
       "            59.1320756,\n",
       "            59.2473381,\n",
       "            59.4309705,\n",
       "            59.4606384,\n",
       "            59.5947638,\n",
       "            59.710581100000006,\n",
       "            59.8127403,\n",
       "            59.9370398,\n",
       "            60.0394969,\n",
       "            60.1410131,\n",
       "            60.24152050000001,\n",
       "            60.424257100000005,\n",
       "            60.439157800000004,\n",
       "            60.619068000000006,\n",
       "            60.79908270000001,\n",
       "            60.932639599000005,\n",
       "            61.053765299000005,\n",
       "            61.2264313,\n",
       "            61.3513413,\n",
       "            61.5464087,\n",
       "            61.561027399000004,\n",
       "            61.702958399,\n",
       "            61.816301799,\n",
       "            61.970145300000006,\n",
       "            62.110882899,\n",
       "            62.224248499000005,\n",
       "            62.3828776,\n",
       "            62.511225100000004,\n",
       "            62.616609099,\n",
       "            62.701220500000005,\n",
       "            62.8416435,\n",
       "            63.037250900000004,\n",
       "            63.164780400000005,\n",
       "            63.281649599000005,\n",
       "            63.400617699,\n",
       "            63.55545389900001,\n",
       "            63.6782952,\n",
       "            63.74183089900001,\n",
       "            63.873128099000006,\n",
       "            64.0204621,\n",
       "            64.20040130000001,\n",
       "            64.33640479900001,\n",
       "            64.4683129,\n",
       "            64.6178531,\n",
       "            64.8303186,\n",
       "            64.9711158,\n",
       "            64.97362929900001,\n",
       "            65.1354688,\n",
       "            65.24864039900001,\n",
       "            65.383938099,\n",
       "            65.5335022,\n",
       "            65.7201563,\n",
       "            65.918757399,\n",
       "            66.1228178,\n",
       "            66.249435999,\n",
       "            66.405831199,\n",
       "            66.57299729900001,\n",
       "            66.6745393,\n",
       "            66.819403799,\n",
       "            66.9223699,\n",
       "            67.04304450000001,\n",
       "            67.2009848,\n",
       "            67.376760699,\n",
       "            67.397575999,\n",
       "            67.5540613,\n",
       "            67.653668599,\n",
       "            67.7531613,\n",
       "            67.854878,\n",
       "            68.0068612,\n",
       "            68.128979,\n",
       "            68.2431846,\n",
       "            68.2911313,\n",
       "            68.4074324,\n",
       "            68.5545305,\n",
       "            68.65464010000001,\n",
       "            68.7913453,\n",
       "            68.892582,\n",
       "            69.02815410000001,\n",
       "            69.16499300000001,\n",
       "            69.26688440000001,\n",
       "            69.2694352,\n",
       "            69.36885310000001,\n",
       "            69.5495466,\n",
       "            69.6616934,\n",
       "            69.7639439,\n",
       "            69.9053985,\n",
       "            70.05361470000001,\n",
       "            70.2677098,\n",
       "            70.3175801,\n",
       "            70.466268099,\n",
       "            70.6206952,\n",
       "            70.75054970000001,\n",
       "            70.85997199900001,\n",
       "            71.02545140000001,\n",
       "            71.1857906,\n",
       "            71.40823610000001,\n",
       "            71.5912656,\n",
       "            71.62136860000001,\n",
       "            71.72382610000001,\n",
       "            71.83587049900001,\n",
       "            71.938457799,\n",
       "            72.037382099,\n",
       "            72.155878199,\n",
       "            72.261161,\n",
       "            72.3643576,\n",
       "            72.3672909,\n",
       "            72.4682184,\n",
       "            72.567692799,\n",
       "            72.669709,\n",
       "            72.8051128,\n",
       "            72.90335110000001,\n",
       "            73.044337,\n",
       "            73.1493756,\n",
       "            73.318201,\n",
       "            73.35915870000001,\n",
       "            73.46000360000001,\n",
       "            73.558442799,\n",
       "            73.69868619900001,\n",
       "            73.820330599,\n",
       "            73.9555375,\n",
       "            74.09374000000001,\n",
       "            74.230623099,\n",
       "            74.2703607,\n",
       "            74.4015018,\n",
       "            74.5001963,\n",
       "            74.64895909900001,\n",
       "            74.752080499,\n",
       "            74.89417319900001,\n",
       "            74.9927727,\n",
       "            75.1167944,\n",
       "            75.220640699,\n",
       "            75.223292799,\n",
       "            75.40719560000001,\n",
       "            75.5198654,\n",
       "            75.6270564,\n",
       "            75.7909736,\n",
       "            75.985805299,\n",
       "            76.1305918,\n",
       "            76.3369277,\n",
       "            76.3773541,\n",
       "            76.54678990000001,\n",
       "            76.7161123,\n",
       "            76.8845407,\n",
       "            77.1381762,\n",
       "            77.261719,\n",
       "            77.43194960000001,\n",
       "            77.5692379,\n",
       "            77.6715188,\n",
       "            77.6740898,\n",
       "            77.7730083,\n",
       "            77.89229920000001,\n",
       "            77.9933618,\n",
       "            78.15038119900001,\n",
       "            78.31347120000001,\n",
       "            78.4697245,\n",
       "            78.6144472,\n",
       "            78.6663218,\n",
       "            78.7967715,\n",
       "            78.91025880000001,\n",
       "            79.1427117,\n",
       "            79.277887699,\n",
       "            79.3901943,\n",
       "            79.5260444,\n",
       "            79.664208599,\n",
       "            79.81207640000001,\n",
       "            79.8157367,\n",
       "            79.9147355,\n",
       "            80.0534142,\n",
       "            80.16924180000001,\n",
       "            80.30394270000001,\n",
       "            80.4488395,\n",
       "            80.55837449900001,\n",
       "            80.7418703,\n",
       "            80.7750944,\n",
       "            80.89469309900001,\n",
       "            80.996731099,\n",
       "            81.190382799,\n",
       "            81.3992149,\n",
       "            81.5578126,\n",
       "            81.737806,\n",
       "            81.8557244,\n",
       "            82.00589430000001,\n",
       "            82.0283187,\n",
       "            82.19674570000001,\n",
       "            82.3081308,\n",
       "            82.43020809900001,\n",
       "            82.55090940000001,\n",
       "            82.6723405,\n",
       "            82.8184049,\n",
       "            82.9604894,\n",
       "            82.9629781,\n",
       "            83.0608916,\n",
       "            83.19657020000001,\n",
       "            83.3323936,\n",
       "            83.43185720000001,\n",
       "            83.545423799,\n",
       "            83.65731539900001,\n",
       "            83.775333,\n",
       "            83.918765499,\n",
       "            83.9815573,\n",
       "            84.127890699,\n",
       "            84.25634480000001,\n",
       "            84.42990249900001,\n",
       "            84.55242050000001,\n",
       "            84.6721334,\n",
       "            84.7758154,\n",
       "            84.9187086,\n",
       "            84.9221174,\n",
       "            85.1075989,\n",
       "            85.20689850000001,\n",
       "            85.307249,\n",
       "            85.426127099,\n",
       "            85.5258294,\n",
       "            85.6926031,\n",
       "            85.91295689900001,\n",
       "            86.139066899,\n",
       "            86.1426163,\n",
       "            86.278217399,\n",
       "            86.4126705,\n",
       "            86.53774580000001,\n",
       "            86.6532387,\n",
       "            86.804618,\n",
       "            86.9251515,\n",
       "            87.0276951,\n",
       "            87.0812873,\n",
       "            87.206230499,\n",
       "            87.31296660000001,\n",
       "            87.4334944,\n",
       "            87.57776940000001,\n",
       "            87.70507400000001,\n",
       "            87.806915,\n",
       "            87.91069540000001,\n",
       "            88.03222690000001,\n",
       "            88.104285699,\n",
       "            88.2566587,\n",
       "            88.378642,\n",
       "            88.4794217,\n",
       "            88.58113789900001,\n",
       "            88.7116154,\n",
       "            88.81205650000001,\n",
       "            88.96010549900001,\n",
       "            88.97843049900001,\n",
       "            89.0923717,\n",
       "            89.206613499,\n",
       "            89.4017678,\n",
       "            89.50540430000001,\n",
       "            89.62523610000001,\n",
       "            89.78142890000001,\n",
       "            89.9552646,\n",
       "            90.11152170000001,\n",
       "            90.114857799,\n",
       "            90.235409199,\n",
       "            90.38011479900001,\n",
       "            90.5140356,\n",
       "            90.6654388,\n",
       "            90.79426620000001,\n",
       "            90.9436264,\n",
       "            91.079196999,\n",
       "            91.14065860000001,\n",
       "            91.2689917,\n",
       "            91.3813123,\n",
       "            91.54052730000001,\n",
       "            91.6580423,\n",
       "            91.7980189,\n",
       "            91.9163436,\n",
       "            92.0250432,\n",
       "            92.1277433,\n",
       "            92.15815710000001,\n",
       "            92.26337229900001,\n",
       "            92.367671199,\n",
       "            92.472464,\n",
       "            92.57658400000001,\n",
       "            92.7368165,\n",
       "            92.8887124,\n",
       "            93.0063786,\n",
       "            93.03119310000001,\n",
       "            93.1538783,\n",
       "            93.296017,\n",
       "            93.4261587,\n",
       "            93.526336799,\n",
       "            93.6571876,\n",
       "            93.7863564,\n",
       "            93.931031,\n",
       "            94.03577049900001,\n",
       "            94.038270099,\n",
       "            94.1784186,\n",
       "            94.28610609900001,\n",
       "            94.40210450000001,\n",
       "            94.58581729900001,\n",
       "            94.77111190000001,\n",
       "            94.8880232,\n",
       "            95.00914300000001,\n",
       "            95.01220299900001,\n",
       "            95.14761010000001,\n",
       "            95.3638579,\n",
       "            95.5163665,\n",
       "            95.72570079900001,\n",
       "            95.8324489,\n",
       "            95.9620237,\n",
       "            96.06491910000001,\n",
       "            96.1690231,\n",
       "            96.17155050000001,\n",
       "            96.32702880000001,\n",
       "            96.5544735,\n",
       "            96.6553617,\n",
       "            96.8046984,\n",
       "            96.9066557,\n",
       "            97.0063214,\n",
       "            97.1089745,\n",
       "            97.11144580000001,\n",
       "            97.21205459900001,\n",
       "            97.331306599,\n",
       "            97.460770999,\n",
       "            97.5763785,\n",
       "            97.67760100000001,\n",
       "            97.8022306,\n",
       "            97.90595180000001,\n",
       "            98.04851299900001,\n",
       "            98.10592030000001,\n",
       "            98.230675899,\n",
       "            98.3408964,\n",
       "            98.4943879,\n",
       "            98.592598299,\n",
       "            98.69692230000001,\n",
       "            98.8167806,\n",
       "            98.98849619900001,\n",
       "            99.03005119900001,\n",
       "            99.21935970000001,\n",
       "            99.34005919900001,\n",
       "            99.4627025,\n",
       "            99.56323250000001,\n",
       "            99.696291899,\n",
       "            99.856624799,\n",
       "            100.0102164,\n",
       "            100.12721470000001,\n",
       "            100.1298392,\n",
       "            100.22985530000001,\n",
       "            100.41425650000001,\n",
       "            100.6033855,\n",
       "            100.8082174,\n",
       "            100.94961660000001,\n",
       "            101.048834099,\n",
       "            101.2198961,\n",
       "            101.2235007,\n",
       "            101.34451130000001,\n",
       "            101.4681736,\n",
       "            101.597803299,\n",
       "            101.69744150000001,\n",
       "            101.7995709,\n",
       "            101.9051446,\n",
       "            102.00825560000001,\n",
       "            102.136412,\n",
       "            102.15386160000001,\n",
       "            102.312584899,\n",
       "            102.4892712,\n",
       "            102.64214580000001,\n",
       "            102.81098119900001,\n",
       "            102.931173199,\n",
       "            103.04666319900001,\n",
       "            103.149179899,\n",
       "            103.15154550000001,\n",
       "            103.274288399,\n",
       "            103.4168946,\n",
       "            103.5325916,\n",
       "            103.71371369900001,\n",
       "            103.815482899,\n",
       "            103.95266570000001,\n",
       "            104.1081209,\n",
       "            104.23583550000001,\n",
       "            104.26184140000001,\n",
       "            104.45330100000001,\n",
       "            104.60396840000001,\n",
       "            104.717575099,\n",
       "            104.91538820000001,\n",
       "            105.0951036,\n",
       "            105.3076439,\n",
       "            105.46894160000001,\n",
       "            105.52494680000001,\n",
       "            105.70275430000001,\n",
       "            105.87369020000001,\n",
       "            105.99524779900001,\n",
       "            106.157139599,\n",
       "            106.304118,\n",
       "            106.44933160000001,\n",
       "            106.59254290000001,\n",
       "            106.76454740000001,\n",
       "            106.7669908,\n",
       "            106.870322899,\n",
       "            107.03564560000001,\n",
       "            107.1717952,\n",
       "            107.27748960000001,\n",
       "            107.381208599,\n",
       "            107.50906799900001,\n",
       "            107.6404784,\n",
       "            107.7010195,\n",
       "            107.80699859900001,\n",
       "            107.92796879900001,\n",
       "            108.0607166,\n",
       "            108.183244399,\n",
       "            108.37857650000001,\n",
       "            108.510558699,\n",
       "            108.64851200000001,\n",
       "            108.7770263,\n",
       "            108.83577220000001,\n",
       "            108.98201820000001,\n",
       "            109.120123899,\n",
       "            109.27961230000001,\n",
       "            109.47314580000001,\n",
       "            109.61442570000001,\n",
       "            109.77785739900001,\n",
       "            109.9151078,\n",
       "            109.9175611,\n",
       "            110.0412211,\n",
       "            110.20201300000001,\n",
       "            110.34034899900001,\n",
       "            110.49549199900001,\n",
       "            110.672542699,\n",
       "            110.8598219,\n",
       "            110.99110850000001,\n",
       "            111.1333984,\n",
       "            111.15187730000001,\n",
       "            111.29687719900001,\n",
       "            111.5317998,\n",
       "            111.6729061,\n",
       "            111.81300870000001,\n",
       "            111.9655453,\n",
       "            112.1097912,\n",
       "            112.230401399,\n",
       "            112.29628859900001,\n",
       "            112.40273250000001,\n",
       "            112.5082251,\n",
       "            112.6416494,\n",
       "            112.761759299,\n",
       "            112.8646264,\n",
       "            113.01206509900001,\n",
       "            113.14327530000001,\n",
       "            113.28914440000001,\n",
       "            113.29200920000001,\n",
       "            113.4249714,\n",
       "            113.54358249900001,\n",
       "            113.6850533,\n",
       "            113.8037764,\n",
       "            113.980180199,\n",
       "            114.1675599,\n",
       "            114.301893,\n",
       "            114.333316299,\n",
       "            114.47017840000001,\n",
       "            114.6139756,\n",
       "            114.73677180000001,\n",
       "            114.90056240000001,\n",
       "            115.09393370000001,\n",
       "            115.208248999,\n",
       "            115.351487699,\n",
       "            115.521176599,\n",
       "            115.556027399,\n",
       "            115.713798799,\n",
       "            115.8150224,\n",
       "            115.94136390000001,\n",
       "            116.04242749900001,\n",
       "            116.162405199,\n",
       "            116.2875322,\n",
       "            116.412614,\n",
       "            116.45074690000001,\n",
       "            116.5770846,\n",
       "            116.7162844,\n",
       "            116.8503,\n",
       "            117.05291930000001,\n",
       "            117.19432610000001,\n",
       "            117.36101279900001,\n",
       "            117.53026720000001,\n",
       "            117.6766484,\n",
       "            117.67981440000001,\n",
       "            117.79624500000001,\n",
       "            117.93106730000001,\n",
       "            118.1077279,\n",
       "            118.30936890000001,\n",
       "            118.4115022,\n",
       "            118.51383510000001,\n",
       "            118.61527729900001,\n",
       "            118.61774019900001,\n",
       "            118.71550880000001,\n",
       "            118.8321518,\n",
       "            118.991676999,\n",
       "            119.12454349900001,\n",
       "            119.263096699,\n",
       "            119.363421099,\n",
       "            119.54803430000001,\n",
       "            119.6968291,\n",
       "            119.6998734,\n",
       "            119.8360983,\n",
       "            120.03361020000001\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"IR\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"IR\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(195, 113, 210, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            43.243496620879306,\n",
       "            41.610493827977194,\n",
       "            40.677730352516186,\n",
       "            39.243765725753576,\n",
       "            37.09109425274473,\n",
       "            34.21923370745323,\n",
       "            31.430819053534492,\n",
       "            26.49771934240901,\n",
       "            19.55673472738391,\n",
       "            11.768468184689084,\n",
       "            11.460979713835098,\n",
       "            11.309269708863143,\n",
       "            11.230073281542921,\n",
       "            11.092432053388924,\n",
       "            12.730678429981197,\n",
       "            11.364919073416527,\n",
       "            11.224402596248432,\n",
       "            12.128022415696666,\n",
       "            11.01984795340814,\n",
       "            15.379011188811765,\n",
       "            15.990876424188938,\n",
       "            15.93208883036006,\n",
       "            15.984100091566164,\n",
       "            15.546782382963228,\n",
       "            16.911607531495093,\n",
       "            18.61669924458407,\n",
       "            17.681524172871082,\n",
       "            17.838646818118296,\n",
       "            21.344839511288995,\n",
       "            24.749402858510066,\n",
       "            23.354623542285328,\n",
       "            22.707441772622904,\n",
       "            23.54859348834788,\n",
       "            22.172948286388475,\n",
       "            22.46812536337601,\n",
       "            22.666772752813582,\n",
       "            22.560005969375336,\n",
       "            22.892730815866535,\n",
       "            22.44619368902172,\n",
       "            22.477885926907483,\n",
       "            21.93834259248908,\n",
       "            21.952475105164392,\n",
       "            22.200712209343976,\n",
       "            22.12948762547738,\n",
       "            21.83889133795859,\n",
       "            21.556814757860156,\n",
       "            22.002922991903244,\n",
       "            21.611475228090004,\n",
       "            21.43025614661486,\n",
       "            21.465777455191933,\n",
       "            21.44537599027648,\n",
       "            21.04163474233757,\n",
       "            20.97933084311183,\n",
       "            20.79056529807555,\n",
       "            20.915527840127005,\n",
       "            20.674742637863837,\n",
       "            20.595958615022866,\n",
       "            20.51965622973605,\n",
       "            20.369740550577408,\n",
       "            20.236348594197,\n",
       "            19.531499464761595,\n",
       "            19.498819002635386,\n",
       "            19.940770822169632,\n",
       "            19.219676471134452,\n",
       "            19.1801925266426,\n",
       "            19.380633602733795,\n",
       "            19.108261690681733,\n",
       "            18.669262589341077,\n",
       "            18.38495356133004,\n",
       "            18.11273084430899,\n",
       "            18.144892059992102,\n",
       "            17.637198643469425,\n",
       "            17.80359131938565,\n",
       "            17.438344967834418,\n",
       "            18.137348809538075,\n",
       "            17.748385487753453,\n",
       "            17.890123753105925,\n",
       "            17.811221933546232,\n",
       "            17.622418034000734,\n",
       "            17.459466464273756,\n",
       "            17.28717456480487,\n",
       "            17.608942996340335,\n",
       "            17.251928789476864,\n",
       "            17.383127591014116,\n",
       "            16.983222606682688,\n",
       "            17.287881162553294,\n",
       "            17.034542767785975,\n",
       "            17.229865745708572,\n",
       "            17.256261788452147,\n",
       "            16.797565767546985,\n",
       "            17.151792349073904,\n",
       "            16.47145376688392,\n",
       "            16.57966744403775,\n",
       "            16.232595768378076,\n",
       "            16.207985910630466,\n",
       "            16.11745677770459,\n",
       "            15.96694258350244,\n",
       "            16.082739462083172,\n",
       "            15.711559203466201,\n",
       "            16.031608777426772,\n",
       "            15.510577491835852,\n",
       "            15.54133322683009,\n",
       "            15.197948520291805,\n",
       "            15.164368862042753,\n",
       "            15.388695369992938,\n",
       "            14.953094165163197,\n",
       "            14.975516135427009,\n",
       "            14.92496378557659,\n",
       "            15.067709308901115,\n",
       "            15.03463980151175,\n",
       "            15.061802606671717,\n",
       "            14.593469685521441,\n",
       "            14.323317382809293,\n",
       "            14.580436547766967,\n",
       "            14.013539221164855,\n",
       "            14.156157204187382,\n",
       "            15.300977093130058,\n",
       "            14.91408901216514,\n",
       "            15.023140150757966,\n",
       "            14.55452280334798,\n",
       "            14.707731656332129,\n",
       "            14.17217943088454,\n",
       "            14.377419389656154,\n",
       "            13.783796521426492,\n",
       "            14.318807316316672,\n",
       "            14.269504137821981,\n",
       "            13.991257753833414,\n",
       "            14.25681614356753,\n",
       "            13.782475028561214,\n",
       "            13.68605724079235,\n",
       "            13.946906122497138,\n",
       "            13.46165774983352,\n",
       "            13.592768388398483,\n",
       "            13.091631348724707,\n",
       "            13.08524275780497,\n",
       "            13.461521943746817,\n",
       "            13.160130771218583,\n",
       "            12.766443209933847,\n",
       "            12.416218381123358,\n",
       "            12.818587736602677,\n",
       "            12.10182128771503,\n",
       "            12.017280424725989,\n",
       "            12.255359949652256,\n",
       "            11.852077390665762,\n",
       "            12.098483322589138,\n",
       "            11.591339431870102,\n",
       "            11.803265214889207,\n",
       "            11.115702286047965,\n",
       "            11.14465097452672,\n",
       "            11.154854240826603,\n",
       "            11.292248187722045,\n",
       "            11.367883793526623,\n",
       "            11.11544250660858,\n",
       "            10.876734362396823,\n",
       "            10.891014460605652,\n",
       "            10.978061574175404,\n",
       "            10.62042686907608,\n",
       "            10.972206774795925,\n",
       "            10.396165655947556,\n",
       "            10.768461986373865,\n",
       "            10.425860038019884,\n",
       "            10.27832671211296,\n",
       "            11.165756335805515,\n",
       "            10.529647238997399,\n",
       "            10.397727616233553,\n",
       "            10.042276065132079,\n",
       "            10.020756393840472,\n",
       "            10.004774822582092,\n",
       "            10.618493014763207,\n",
       "            10.178445086017446,\n",
       "            11.121304148187685,\n",
       "            10.326786402666112,\n",
       "            10.100435957148829,\n",
       "            10.386766841878602,\n",
       "            9.968205685682092,\n",
       "            10.583235595015255,\n",
       "            9.803867505764112,\n",
       "            9.927467225131515,\n",
       "            10.271485303819023,\n",
       "            9.785121517389276,\n",
       "            9.55941942881254,\n",
       "            9.254434044721686,\n",
       "            9.84672380722662,\n",
       "            8.989205259248925,\n",
       "            9.443828363476252,\n",
       "            8.59078531529478,\n",
       "            9.106708993504327,\n",
       "            8.522148478499002,\n",
       "            8.55427715972574,\n",
       "            9.880318812935434,\n",
       "            9.029637545776856,\n",
       "            9.110410721088243,\n",
       "            9.628608055103395,\n",
       "            9.557295245841429,\n",
       "            9.615694167881658,\n",
       "            9.19229733346817,\n",
       "            9.024262175522658,\n",
       "            8.880629595741697,\n",
       "            8.997904051080814,\n",
       "            8.693569807723959,\n",
       "            8.825681177555051,\n",
       "            8.47769609307012,\n",
       "            8.497763480226563,\n",
       "            8.638521623451108,\n",
       "            8.774844250305994,\n",
       "            8.174490815384376,\n",
       "            8.696415807983035,\n",
       "            7.948668118370581,\n",
       "            8.244385699290905,\n",
       "            7.675692218120097,\n",
       "            8.133388499231659,\n",
       "            7.6608256683986,\n",
       "            8.10400032956255,\n",
       "            7.326789464281441,\n",
       "            7.821864026623551,\n",
       "            7.150531786317639,\n",
       "            7.786408428562399,\n",
       "            6.937626154156636,\n",
       "            7.589239961538656,\n",
       "            6.665955405527807,\n",
       "            6.790311836230349,\n",
       "            7.4224575887546145,\n",
       "            6.4335274077353235,\n",
       "            6.695682216286856,\n",
       "            6.332317903944241,\n",
       "            6.676267057974913,\n",
       "            6.196148522941494,\n",
       "            6.139527141708066,\n",
       "            5.973213684480302,\n",
       "            6.374262087855112,\n",
       "            5.656462517450716,\n",
       "            5.525893774476152,\n",
       "            5.9502815217824505,\n",
       "            5.404140977501299,\n",
       "            5.664247086512257,\n",
       "            6.158089520709547,\n",
       "            5.285661323852977,\n",
       "            4.945278444268076,\n",
       "            5.082520610240302,\n",
       "            5.3176946861583,\n",
       "            5.662945758400197,\n",
       "            4.874741635905664,\n",
       "            5.636152614760167,\n",
       "            4.745123377419404,\n",
       "            5.3672801701028,\n",
       "            4.598409222040357,\n",
       "            5.637326335188635,\n",
       "            4.570183306272991,\n",
       "            5.87952968830212,\n",
       "            4.383456996675828,\n",
       "            5.28277024673339,\n",
       "            3.852181957373483,\n",
       "            5.339896870322033,\n",
       "            3.934377310535668,\n",
       "            4.500440290926159,\n",
       "            3.8072191091910725,\n",
       "            5.4172901508956235,\n",
       "            4.234949487760044,\n",
       "            4.711543872065121,\n",
       "            3.946659235191179,\n",
       "            4.9244172740633925,\n",
       "            3.5600701765029052,\n",
       "            4.714748324003847,\n",
       "            5.3940746390955585,\n",
       "            5.7528233073413055,\n",
       "            3.8516030638893453,\n",
       "            5.100214733329824,\n",
       "            4.7141280816539535,\n",
       "            4.38470520488997,\n",
       "            4.362462072672014,\n",
       "            4.520475409345962,\n",
       "            4.338151275325078,\n",
       "            4.570253541580831,\n",
       "            5.10172119579506,\n",
       "            4.523015640097467,\n",
       "            5.454143457797661,\n",
       "            3.9484616617966033,\n",
       "            4.75948974487432,\n",
       "            4.743162312972039,\n",
       "            4.409558022857277,\n",
       "            4.390806546438167,\n",
       "            4.896638100828287,\n",
       "            3.8749334428232936,\n",
       "            3.63734499829242,\n",
       "            4.879366062252953,\n",
       "            3.9711101664584683,\n",
       "            3.7789385247519527,\n",
       "            4.855791128010099,\n",
       "            3.7230907003119147,\n",
       "            3.6300932942450417,\n",
       "            3.568864133656804,\n",
       "            3.523943986449346,\n",
       "            5.176568011613869,\n",
       "            3.6420414698543055,\n",
       "            4.69571448743421,\n",
       "            3.639846150869394,\n",
       "            3.8925716597774858,\n",
       "            3.536325931173393,\n",
       "            3.9638151708613494,\n",
       "            3.472866775073289,\n",
       "            4.46230126863394,\n",
       "            3.89837293165143,\n",
       "            3.833672562611986,\n",
       "            3.0556248096890526,\n",
       "            3.4169450418876854,\n",
       "            2.6999831865993387,\n",
       "            3.9454609994764027,\n",
       "            3.3102316374034153,\n",
       "            3.1882151936848655,\n",
       "            2.7028488094231,\n",
       "            3.391101314310286,\n",
       "            4.242484928450757,\n",
       "            2.999711299827068,\n",
       "            3.690712692379692,\n",
       "            3.4232439906564642,\n",
       "            3.17481385921188,\n",
       "            3.681800700787818,\n",
       "            3.4292212866205927,\n",
       "            3.1759771490945496,\n",
       "            3.034151270151871,\n",
       "            3.2075306793603207,\n",
       "            2.9897705031236956,\n",
       "            2.7616478420929136,\n",
       "            2.1950733717400785,\n",
       "            2.4154243927141326,\n",
       "            3.2753319359199327,\n",
       "            1.957256928828484,\n",
       "            4.19777434636972,\n",
       "            1.9913096978259988,\n",
       "            4.379035332474658,\n",
       "            2.7664323928959553,\n",
       "            2.875717554455862,\n",
       "            4.153084816685313,\n",
       "            2.2927502503869155,\n",
       "            2.8538590746680135,\n",
       "            1.7728798113347681,\n",
       "            2.4178413514971044,\n",
       "            1.9860557853009553,\n",
       "            4.455460351863924,\n",
       "            2.32146583159901,\n",
       "            1.3950892407183046,\n",
       "            3.86350010731937,\n",
       "            1.6300775534307863,\n",
       "            4.434286889744072,\n",
       "            2.3893472781012397,\n",
       "            2.9796002289927856,\n",
       "            2.158384076897403,\n",
       "            1.3324710928248968,\n",
       "            3.8382057992635055,\n",
       "            1.2483263823823785,\n",
       "            3.9941316257782025,\n",
       "            2.0065409065414994,\n",
       "            2.809280290900032,\n",
       "            2.1879758299132854,\n",
       "            4.8653574187674975,\n",
       "            2.401031854238405,\n",
       "            2.9877571598461445,\n",
       "            2.902452426286936,\n",
       "            2.9955511944805684,\n",
       "            2.0140565573609965,\n",
       "            4.721200894981937,\n",
       "            2.6634660637597016,\n",
       "            3.980859491352526,\n",
       "            2.444633214811979,\n",
       "            3.548008971015202,\n",
       "            2.0330484932088124,\n",
       "            2.9749496035232057,\n",
       "            2.3801097923622696,\n",
       "            2.5752421596805113,\n",
       "            3.959336105401294,\n",
       "            2.3852687124398764,\n",
       "            3.261660412028664,\n",
       "            1.8028122439893897,\n",
       "            2.7536554563275684,\n",
       "            2.0818684332622555,\n",
       "            3.6161998573543546,\n",
       "            2.4600969703589386,\n",
       "            3.8468547321424746,\n",
       "            3.038446368910558,\n",
       "            4.58579726420996,\n",
       "            2.1860367388301403,\n",
       "            4.246725915072183,\n",
       "            4.153563542589981,\n",
       "            3.3671365792068864,\n",
       "            2.9431393072682797,\n",
       "            4.704025225636773,\n",
       "            3.110562465918511,\n",
       "            3.8577549656327483,\n",
       "            4.190728260277373,\n",
       "            3.105077774029378,\n",
       "            3.0798639768044063,\n",
       "            3.2933396275432023,\n",
       "            2.6820884188590672,\n",
       "            4.834049665248146,\n",
       "            3.434240084963289,\n",
       "            5.053513640941858,\n",
       "            3.6571617876598927,\n",
       "            4.268063214602209,\n",
       "            2.870209019990047,\n",
       "            3.674741865613719,\n",
       "            3.3949394825204395,\n",
       "            4.245805986138238,\n",
       "            3.278750294817212,\n",
       "            4.288576568677955,\n",
       "            4.252016541722667,\n",
       "            3.6748329813941725,\n",
       "            3.3997708902427695,\n",
       "            3.927029888913469,\n",
       "            3.6577744589201546,\n",
       "            3.847070363003001,\n",
       "            5.270256361748778,\n",
       "            4.208736792298617,\n",
       "            3.4917660931482626,\n",
       "            5.165716973326759,\n",
       "            3.775037145485131,\n",
       "            3.885665218980136,\n",
       "            4.130687559261609,\n",
       "            4.092263955579743,\n",
       "            4.528416074927687,\n",
       "            5.049530302799059,\n",
       "            4.803839729739998,\n",
       "            3.7480692955144073,\n",
       "            5.4354004971727425,\n",
       "            4.212786884648567,\n",
       "            4.484393780857722,\n",
       "            4.6929651343915495,\n",
       "            5.579461734658098,\n",
       "            4.81369519877605,\n",
       "            5.852296817300951,\n",
       "            4.749934433665796,\n",
       "            4.37708096336899,\n",
       "            5.0683224933114985,\n",
       "            5.224212760745749,\n",
       "            4.563754453387422,\n",
       "            6.489011491376315,\n",
       "            5.16329984904586,\n",
       "            5.325812714994953,\n",
       "            5.185541562640342,\n",
       "            5.755940445804383,\n",
       "            6.385060155807451,\n",
       "            5.471331566024917,\n",
       "            5.861652765979109,\n",
       "            7.106124588682201,\n",
       "            6.411548233849724,\n",
       "            5.9609622245424605,\n",
       "            5.465755695316209,\n",
       "            5.257868111773323,\n",
       "            1.882876897469373,\n",
       "            5.148691730018548,\n",
       "            3.760591875022651,\n",
       "            2.705526742705548,\n",
       "            3.0052036343687383,\n",
       "            3.243386772793832,\n",
       "            2.704448721078238,\n",
       "            3.3203465590309227,\n",
       "            2.56481870883986,\n",
       "            2.9650549097408563,\n",
       "            3.273364211255123,\n",
       "            2.614484428922803,\n",
       "            2.9362956482562774,\n",
       "            5.0206156184453645,\n",
       "            4.175815962476762,\n",
       "            4.62150791336156,\n",
       "            2.779610163101862,\n",
       "            3.011766995089331,\n",
       "            1.852348081079586,\n",
       "            4.075346248208989,\n",
       "            2.684771894140851,\n",
       "            3.3536530565229454,\n",
       "            2.956878913521384,\n",
       "            1.8994941004468975,\n",
       "            3.2232858792992727,\n",
       "            3.4162538334100967,\n",
       "            2.060265337862312,\n",
       "            4.092511560670714,\n",
       "            3.3130079427622197,\n",
       "            3.3398280166460013,\n",
       "            2.3445657875294437,\n",
       "            3.85766014351377,\n",
       "            3.8001446277937077,\n",
       "            2.059262750556328,\n",
       "            4.935456357100617,\n",
       "            3.6732291479301624,\n",
       "            2.7844772407022003,\n",
       "            2.814190620545464,\n",
       "            3.061179701426394,\n",
       "            3.672118404744192,\n",
       "            2.9721985746716015,\n",
       "            2.8914726622069495,\n",
       "            3.547337056190139,\n",
       "            3.05548891698991,\n",
       "            3.891340709671834,\n",
       "            3.2822242623914595,\n",
       "            3.4819883541640966,\n",
       "            3.6003594839401125,\n",
       "            3.2772443001870313,\n",
       "            4.830719898956482,\n",
       "            3.9313222805982897,\n",
       "            4.003751702512639,\n",
       "            3.3590950963476947,\n",
       "            5.258588301373318,\n",
       "            4.9254058880604195,\n",
       "            5.442230840788944,\n",
       "            5.0680138610879135,\n",
       "            4.604313328348002,\n",
       "            4.647197991920083,\n",
       "            4.980908257166733,\n",
       "            3.915194041279194,\n",
       "            4.830402423148313,\n",
       "            3.9641263220176457,\n",
       "            4.78903814677877,\n",
       "            4.27258356214735,\n",
       "            4.518175126875421,\n",
       "            5.657929864723763,\n",
       "            4.436354196988633,\n",
       "            5.3092387031219035,\n",
       "            4.531303321081001,\n",
       "            4.698684956879688,\n",
       "            5.632036137743925,\n",
       "            4.848493080941573,\n",
       "            6.6000752244559395,\n",
       "            5.550517422513693,\n",
       "            4.850588159331467,\n",
       "            5.20704746954577,\n",
       "            5.03901838670389,\n",
       "            5.251547081792048,\n",
       "            5.0013495309136,\n",
       "            4.909348596868404,\n",
       "            5.385219159286961,\n",
       "            4.881663465981922,\n",
       "            4.954021414723175,\n",
       "            5.857492203587804,\n",
       "            4.880038623826361,\n",
       "            5.613548401306365,\n",
       "            5.318168092536822,\n",
       "            4.9971625859707585,\n",
       "            5.590426051415693,\n",
       "            5.564864020738921,\n",
       "            5.1817761490442225,\n",
       "            5.416081457248413,\n",
       "            5.434778304842039,\n",
       "            6.120748052557515,\n",
       "            4.748057637048713,\n",
       "            4.9952532126856015,\n",
       "            4.7066378115538186,\n",
       "            5.109098986449491,\n",
       "            4.7579461413076825,\n",
       "            5.630789134251003,\n",
       "            4.8908895294365,\n",
       "            5.314926988623614,\n",
       "            4.677709509896385,\n",
       "            5.099781617969925,\n",
       "            5.0481791145789945,\n",
       "            5.9347693467816285,\n",
       "            5.405709623993756,\n",
       "            5.187258176839707,\n",
       "            5.2595623794377255,\n",
       "            5.345325711969659,\n",
       "            4.3696479612680115,\n",
       "            4.806551590493572,\n",
       "            4.694851858843775,\n",
       "            5.074829516131799,\n",
       "            4.3990653628734755,\n",
       "            6.050332283001256,\n",
       "            4.801792764798532,\n",
       "            5.833354527794984,\n",
       "            4.912762032697542,\n",
       "            6.515954332577452,\n",
       "            5.764627090959541,\n",
       "            6.368422187902436,\n",
       "            5.479734884065641,\n",
       "            5.498923538869745,\n",
       "            5.56983633007793,\n",
       "            5.247813839616129,\n",
       "            5.724158903850135,\n",
       "            4.927554342165454,\n",
       "            5.21059031737619,\n",
       "            4.9929982590655735,\n",
       "            5.327175471244005,\n",
       "            5.421723961895963,\n",
       "            5.2048616116588455,\n",
       "            5.600610412054845,\n",
       "            5.510500364448419,\n",
       "            5.3161629893063616,\n",
       "            6.053760604682234,\n",
       "            5.572561196538912,\n",
       "            6.168656715863926,\n",
       "            5.774196431321574,\n",
       "            6.237608374873407,\n",
       "            5.657169507072058,\n",
       "            6.175854060965769,\n",
       "            6.048569577768332,\n",
       "            6.465392575403245,\n",
       "            5.620921822419419,\n",
       "            5.359031751093319,\n",
       "            6.554903031547757,\n",
       "            5.7612075463352745,\n",
       "            5.650903236481791,\n",
       "            6.570090586330926,\n",
       "            5.695758061445761,\n",
       "            5.684957296365149,\n",
       "            6.622338861133272,\n",
       "            7.31999198487407,\n",
       "            6.527672869929797,\n",
       "            6.614415045865443,\n",
       "            6.495082536597526,\n",
       "            6.4573617509516925,\n",
       "            6.4965910750206355,\n",
       "            6.834986785302191,\n",
       "            6.477744504384005,\n",
       "            7.584075088328166,\n",
       "            6.59341403739026,\n",
       "            7.369696585749456,\n",
       "            6.8238032708784155,\n",
       "            7.052538557949666,\n",
       "            7.333774397994781,\n",
       "            7.175652385261881,\n",
       "            7.879004451428404,\n",
       "            7.229737182510105,\n",
       "            7.5887460742180695,\n",
       "            7.346188226424641,\n",
       "            7.065483172519803,\n",
       "            8.112882827429631,\n",
       "            7.505362671731993,\n",
       "            8.96048091459357,\n",
       "            8.090004232599444,\n",
       "            8.105027722718035,\n",
       "            7.886271644184312,\n",
       "            8.595381911684798,\n",
       "            8.12863339317584,\n",
       "            8.63479147006046,\n",
       "            8.429782504108353,\n",
       "            8.490168432668334,\n",
       "            8.803140807933742,\n",
       "            8.399852700472136,\n",
       "            9.089315767726346,\n",
       "            8.717177187138342,\n",
       "            9.037708820761933,\n",
       "            8.737538136030505,\n",
       "            9.258515144384171,\n",
       "            9.206587055591644,\n",
       "            9.14019658366953,\n",
       "            9.425771227655698,\n",
       "            8.886399420888598,\n",
       "            8.715843926603474,\n",
       "            8.77731969494985,\n",
       "            8.985808528374262,\n",
       "            8.82379686134034,\n",
       "            9.434874020766463,\n",
       "            9.100092521783854,\n",
       "            9.082017791811952,\n",
       "            9.147797730654391,\n",
       "            8.92208539077066,\n",
       "            9.329354060168509,\n",
       "            9.111163104740173,\n",
       "            9.438318592827017,\n",
       "            9.278625282608662,\n",
       "            9.323769187246,\n",
       "            9.273871924997405,\n",
       "            9.599466364177955,\n",
       "            8.956382966753763,\n",
       "            8.771425015981736,\n",
       "            9.776718154903312,\n",
       "            9.527863320801547,\n",
       "            9.596672061230512,\n",
       "            9.450687808939575,\n",
       "            9.006732286944434,\n",
       "            9.138193659148406,\n",
       "            8.579306333030978,\n",
       "            8.811865359264258,\n",
       "            8.893699502784264,\n",
       "            8.908828793814275,\n",
       "            8.68681850264472,\n",
       "            9.57979436911336,\n",
       "            9.543031324235686,\n",
       "            9.129514543606975,\n",
       "            8.826441887519495,\n",
       "            9.479677229377467,\n",
       "            9.422421236865297,\n",
       "            9.467705109072869,\n",
       "            9.389212246099081,\n",
       "            10.00587546340419,\n",
       "            10.260800741543274,\n",
       "            9.822979989121148,\n",
       "            10.065248602683118,\n",
       "            9.644894771473325,\n",
       "            9.687270203253041,\n",
       "            9.839197057345144,\n",
       "            10.006161809812886,\n",
       "            9.781115755133039,\n",
       "            10.159452155493078,\n",
       "            9.940638193419666,\n",
       "            10.503333467021244,\n",
       "            10.04039554648673,\n",
       "            10.174568597392692,\n",
       "            10.231623539286316,\n",
       "            10.239553779338497,\n",
       "            10.678565237168472,\n",
       "            10.347833875524078,\n",
       "            10.442433443142626,\n",
       "            10.401603279516785,\n",
       "            10.834194621068065,\n",
       "            10.30009865814557,\n",
       "            10.651430302679378,\n",
       "            10.331644643719258,\n",
       "            10.998664262527095,\n",
       "            10.684911527095993,\n",
       "            10.785017603993477,\n",
       "            10.664059405062165,\n",
       "            10.701378606438267,\n",
       "            11.350513756131024,\n",
       "            11.021231478229252,\n",
       "            11.031735635929689,\n",
       "            11.10702642194566,\n",
       "            11.855232380584475,\n",
       "            11.394836953529374,\n",
       "            11.095993425664732,\n",
       "            11.36435295883462,\n",
       "            11.31484321032936,\n",
       "            11.272519967379562,\n",
       "            11.170094767144084,\n",
       "            11.69368414162909,\n",
       "            11.4877696264076,\n",
       "            11.502239523133234,\n",
       "            11.365312890442091,\n",
       "            11.993660622280343,\n",
       "            11.518281268091465,\n",
       "            11.556895750115704,\n",
       "            11.484979596681875,\n",
       "            11.557621561832972,\n",
       "            11.122068553016016,\n",
       "            11.131839104029334,\n",
       "            11.522440866088793,\n",
       "            11.086054549350125,\n",
       "            10.996805028050506,\n",
       "            11.478862222193722,\n",
       "            10.818865011362538,\n",
       "            11.16353167988985,\n",
       "            10.654702627427099,\n",
       "            11.371189940643628,\n",
       "            10.918167112234249,\n",
       "            11.204684417948013,\n",
       "            10.772252402435278,\n",
       "            10.765689029382912,\n",
       "            10.48639854867464,\n",
       "            10.64669169288561,\n",
       "            11.150332593973907,\n",
       "            10.785168593650265,\n",
       "            10.777368089964499,\n",
       "            10.733083178189455,\n",
       "            10.705056619316125,\n",
       "            11.154915004672151,\n",
       "            10.688719535716398,\n",
       "            10.606922820504835,\n",
       "            10.234387478933641,\n",
       "            10.873696859180232,\n",
       "            10.8580681067183,\n",
       "            10.774956230394778,\n",
       "            11.126216030675092,\n",
       "            11.038911760104192,\n",
       "            10.721281095868349,\n",
       "            10.741806943450326,\n",
       "            11.05875790396511,\n",
       "            10.960405529129678,\n",
       "            11.010931694458334,\n",
       "            10.971094766134255,\n",
       "            11.226930680150309,\n",
       "            10.922081421771926,\n",
       "            11.551111231155964,\n",
       "            11.185959993269615,\n",
       "            11.18677524706051,\n",
       "            11.411669064744954,\n",
       "            11.826082843345455,\n",
       "            11.483712943622596,\n",
       "            11.948202151235618,\n",
       "            12.390866356266208,\n",
       "            11.967248575148545,\n",
       "            11.669774824583529,\n",
       "            11.667183401807321,\n",
       "            11.793342796450373,\n",
       "            11.982832320983439,\n",
       "            12.067605892666096,\n",
       "            12.200175069160563,\n",
       "            12.002279688178643,\n",
       "            11.916193037656747,\n",
       "            12.036068964912458,\n",
       "            12.217606831903137,\n",
       "            11.951558270955218,\n",
       "            12.320588737904687,\n",
       "            12.187247446257084,\n",
       "            12.284594650301187,\n",
       "            12.011868696302693,\n",
       "            12.355997581288577,\n",
       "            12.100618792754512,\n",
       "            12.35426204930582,\n",
       "            12.225073586810158,\n",
       "            12.233210000455127,\n",
       "            12.511544973071842,\n",
       "            12.878126826145154,\n",
       "            12.486038574872046,\n",
       "            13.256804363378505,\n",
       "            12.54197814457461,\n",
       "            12.702308542156496,\n",
       "            12.934172276512852,\n",
       "            12.48291701621248,\n",
       "            12.42905189593082,\n",
       "            12.392133643112412,\n",
       "            12.728840384940648,\n",
       "            12.567049933820071,\n",
       "            12.64294101250048,\n",
       "            12.588780770447034,\n",
       "            12.98178590359328,\n",
       "            12.578103570553798,\n",
       "            12.661307613912864,\n",
       "            12.49712849800207,\n",
       "            13.325446232303975,\n",
       "            13.059136417560795,\n",
       "            13.07498932811194,\n",
       "            12.887901123649224,\n",
       "            12.84622527713759,\n",
       "            13.269300836626671,\n",
       "            12.765282244437522,\n",
       "            12.620622921323362,\n",
       "            13.150465167219775,\n",
       "            12.881783374959792,\n",
       "            12.851017995135232,\n",
       "            13.228437124344406,\n",
       "            13.290435157620504,\n",
       "            12.813992756858715,\n",
       "            13.243088018411402,\n",
       "            12.893174568350826,\n",
       "            13.258783014820251,\n",
       "            12.970291759572284,\n",
       "            12.885145142437969,\n",
       "            13.115207638235827,\n",
       "            12.962903576703575,\n",
       "            13.33423231346987,\n",
       "            13.07807734870942,\n",
       "            13.532095284971119,\n",
       "            13.31051654110615,\n",
       "            13.251423441741371,\n",
       "            14.155472066352628,\n",
       "            13.804048718603337,\n",
       "            14.247769449032585,\n",
       "            13.934257753836148,\n",
       "            13.309519241426617,\n",
       "            13.153854568743185,\n",
       "            13.144145649414469,\n",
       "            13.44925831685332,\n",
       "            13.222564860537773,\n",
       "            13.216850631827816,\n",
       "            13.593278348036012,\n",
       "            13.54386285011968,\n",
       "            13.556874030119287,\n",
       "            13.63678884658922,\n",
       "            13.398311468135603,\n",
       "            12.881035526734133,\n",
       "            12.948145189093875,\n",
       "            13.065347114254196,\n",
       "            12.907884727934466,\n",
       "            12.954067781570116,\n",
       "            13.128143750268784,\n",
       "            13.4016118635898,\n",
       "            13.188147256646234,\n",
       "            13.480000545336669,\n",
       "            13.519831645642606,\n",
       "            13.402860356768041,\n",
       "            13.54289609586356,\n",
       "            13.857944206351066,\n",
       "            13.583464083249469,\n",
       "            13.734010621768359,\n",
       "            13.971855031807856,\n",
       "            13.756351969901665,\n",
       "            14.163761899497786,\n",
       "            14.2309092506284,\n",
       "            14.738348322850934,\n",
       "            14.40980342807115,\n",
       "            14.545997337541642,\n",
       "            14.823031295130043,\n",
       "            14.80642944564358,\n",
       "            14.89118388593264,\n",
       "            14.741357369121202,\n",
       "            14.75210601879452,\n",
       "            14.838315723432105,\n",
       "            14.783016175226923,\n",
       "            15.225755348105272,\n",
       "            15.020616642892996,\n",
       "            14.974477163491681,\n",
       "            14.806010652551889,\n",
       "            15.182412338250296,\n",
       "            15.143969787220897,\n",
       "            15.045469256873329,\n",
       "            15.568351872352578,\n",
       "            15.314529771251243,\n",
       "            15.316676986666035,\n",
       "            15.315087530487459,\n",
       "            15.37298902835201,\n",
       "            15.578375144903433,\n",
       "            15.408364184585333,\n",
       "            15.359525168442099,\n",
       "            15.954591549480366,\n",
       "            15.602085694084444,\n",
       "            15.713438073659153,\n",
       "            15.76138958831856,\n",
       "            15.58762232367425,\n",
       "            15.511123605961524,\n",
       "            15.454934527378892,\n",
       "            16.132602318771333,\n",
       "            15.86324934467033,\n",
       "            15.6678188544472,\n",
       "            15.946669313530904,\n",
       "            15.774371096263751,\n",
       "            16.14339598592111,\n",
       "            15.873499612468596,\n",
       "            16.325729695019593,\n",
       "            15.99052113035862,\n",
       "            15.715197813050366,\n",
       "            15.667144659598563,\n",
       "            16.071663318764354,\n",
       "            16.00373072562804,\n",
       "            16.22628218912359,\n",
       "            16.274512061862218,\n",
       "            16.539092713991437,\n",
       "            16.276371156984908,\n",
       "            16.38195838166846,\n",
       "            16.4081296176987,\n",
       "            17.121707355875866,\n",
       "            16.983687339292846,\n",
       "            17.22756768842005,\n",
       "            16.830394354927012,\n",
       "            16.869914455050683,\n",
       "            16.776053175709187,\n",
       "            16.599603346972774,\n",
       "            16.32899352966342,\n",
       "            16.28282732892051,\n",
       "            16.617106228672686,\n",
       "            16.51721250489405,\n",
       "            16.30346329560622,\n",
       "            16.209822220966345,\n",
       "            16.208428651305276,\n",
       "            15.997215781121055,\n",
       "            15.592644120014292,\n",
       "            15.603448447584716,\n",
       "            15.676792454707206,\n",
       "            15.839800158409771,\n",
       "            15.518720766518122,\n",
       "            15.604274965399526,\n",
       "            16.037010559585575,\n",
       "            15.685186292682257,\n",
       "            15.658185332350447,\n",
       "            15.509558427231083,\n",
       "            15.532057557604196,\n",
       "            15.822553486495268,\n",
       "            15.561255220556538\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    },\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.2729649,\n",
       "            0.304959099,\n",
       "            0.3194018,\n",
       "            0.33427850000000003,\n",
       "            0.34627470000000005,\n",
       "            0.359363099,\n",
       "            0.3767783,\n",
       "            0.4091014,\n",
       "            0.42943149900000005,\n",
       "            0.4427265,\n",
       "            0.46602730000000003,\n",
       "            0.48831509900000003,\n",
       "            0.5331612,\n",
       "            0.5529344,\n",
       "            0.5738894,\n",
       "            0.5965994,\n",
       "            0.6551052,\n",
       "            0.6777986,\n",
       "            0.7039433,\n",
       "            0.7429425000000001,\n",
       "            0.7565889,\n",
       "            0.7857541,\n",
       "            0.8111665990000001,\n",
       "            0.8256203990000001,\n",
       "            0.8753309,\n",
       "            0.902424399,\n",
       "            0.9221822000000001,\n",
       "            0.9589931,\n",
       "            0.973958399,\n",
       "            0.9933919990000001,\n",
       "            1.019137199,\n",
       "            1.043984,\n",
       "            1.0658192,\n",
       "            1.0933928000000002,\n",
       "            1.133321099,\n",
       "            1.1752859,\n",
       "            1.2013022990000002,\n",
       "            1.221937,\n",
       "            1.2444263,\n",
       "            1.2641703,\n",
       "            1.3202577,\n",
       "            1.361808399,\n",
       "            1.4263162,\n",
       "            1.4574507,\n",
       "            1.5140142,\n",
       "            1.567762499,\n",
       "            1.5850348,\n",
       "            1.6212102000000002,\n",
       "            1.6385900000000002,\n",
       "            1.6558362000000002,\n",
       "            1.6697205000000002,\n",
       "            1.6836781,\n",
       "            1.6999981000000002,\n",
       "            1.7195202,\n",
       "            1.7418885000000002,\n",
       "            1.7781621,\n",
       "            1.8225065,\n",
       "            1.8516314,\n",
       "            1.8890759990000001,\n",
       "            1.9147174,\n",
       "            1.948242999,\n",
       "            1.980441799,\n",
       "            2.0669386000000003,\n",
       "            2.0876887,\n",
       "            2.136725,\n",
       "            2.1610529,\n",
       "            2.2007700000000003,\n",
       "            2.2258724,\n",
       "            2.2412832000000003,\n",
       "            2.2610628,\n",
       "            2.277262899,\n",
       "            2.2920368,\n",
       "            2.3096402,\n",
       "            2.344273699,\n",
       "            2.3579934000000002,\n",
       "            2.3702986000000004,\n",
       "            2.384085499,\n",
       "            2.4079559,\n",
       "            2.4235719000000002,\n",
       "            2.463089799,\n",
       "            2.4795181,\n",
       "            2.5005876000000002,\n",
       "            2.5136324990000003,\n",
       "            2.531735899,\n",
       "            2.5480759,\n",
       "            2.563667,\n",
       "            2.5766337000000004,\n",
       "            2.5910982000000002,\n",
       "            2.630361599,\n",
       "            2.6681973,\n",
       "            2.6836828,\n",
       "            2.7004571000000004,\n",
       "            2.7147569000000003,\n",
       "            2.7319832,\n",
       "            2.7475564990000003,\n",
       "            2.762578999,\n",
       "            2.779281799,\n",
       "            2.794761899,\n",
       "            2.8088156,\n",
       "            2.8229179\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"Adam\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"Adam\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(172, 142, 24, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            43.243496620879306,\n",
       "            43.22407893833289,\n",
       "            43.20469991570212,\n",
       "            43.185620889598454,\n",
       "            43.166218781279625,\n",
       "            43.14675625724949,\n",
       "            43.12773200194834,\n",
       "            43.108674098054415,\n",
       "            43.09034929373858,\n",
       "            43.072085278406206,\n",
       "            43.05375320450314,\n",
       "            43.03568871371147,\n",
       "            43.01763768522146,\n",
       "            42.99969290002764,\n",
       "            42.98191687263807,\n",
       "            42.96426140045335,\n",
       "            42.946866383605425,\n",
       "            42.92978311539035,\n",
       "            42.912797095995,\n",
       "            42.89577981209741,\n",
       "            42.87898951632773,\n",
       "            42.86241889201015,\n",
       "            42.84586495278087,\n",
       "            42.82929000362903,\n",
       "            42.81283070478028,\n",
       "            42.79655679324898,\n",
       "            42.78042551350142,\n",
       "            42.76456467491796,\n",
       "            42.74887480733623,\n",
       "            42.733205023611035,\n",
       "            42.71755107637868,\n",
       "            42.70230983021206,\n",
       "            42.687225377713794,\n",
       "            42.672302598402666,\n",
       "            42.65758300557957,\n",
       "            42.64310971463244,\n",
       "            42.628646975361676,\n",
       "            42.61441795885571,\n",
       "            42.600419545210904,\n",
       "            42.58649557332512,\n",
       "            42.57276378787025,\n",
       "            42.55927883893515,\n",
       "            42.5459906729311,\n",
       "            42.53272794617148,\n",
       "            42.519866550252864,\n",
       "            42.507189896748976,\n",
       "            42.49455438825642,\n",
       "            42.48213568157383,\n",
       "            42.47013387526309,\n",
       "            42.45830752101615,\n",
       "            42.44650198686186,\n",
       "            42.43475488399362,\n",
       "            42.423070390024655,\n",
       "            42.41148583995072,\n",
       "            42.399825582784246,\n",
       "            42.3881755046444,\n",
       "            42.37667816063789,\n",
       "            42.365292561080366,\n",
       "            42.35402866626504,\n",
       "            42.34273800620095,\n",
       "            42.331337194478635,\n",
       "            42.32004830694491,\n",
       "            42.309016895818075,\n",
       "            42.29817855020021,\n",
       "            42.287244312079665,\n",
       "            42.27664222080467,\n",
       "            42.266078646970456,\n",
       "            42.25548255162069,\n",
       "            42.2447950029173,\n",
       "            42.23451992253386,\n",
       "            42.2242623090953,\n",
       "            42.21431516742083,\n",
       "            42.20426284858998,\n",
       "            42.19422722166679,\n",
       "            42.1843145624683,\n",
       "            42.17448893870125,\n",
       "            42.16460200524902,\n",
       "            42.15480018133486,\n",
       "            42.14521446007081,\n",
       "            42.135770076983164,\n",
       "            42.12623492969965,\n",
       "            42.11674359908196,\n",
       "            42.10734437685506,\n",
       "            42.0982433400036,\n",
       "            42.08924433098314,\n",
       "            42.080356957742325,\n",
       "            42.07156699971618,\n",
       "            42.0626720665074,\n",
       "            42.053662046107746,\n",
       "            42.04442082606069,\n",
       "            42.03513866722458,\n",
       "            42.02601621202981,\n",
       "            42.01729282275695,\n",
       "            42.00857312824603,\n",
       "            41.99994594139666,\n",
       "            41.99125049398336,\n",
       "            41.9823802740147,\n",
       "            41.973658153856285,\n",
       "            41.96496756926067,\n",
       "            41.95638699239753,\n",
       "            41.94807776277141\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    }\n",
       "]\n",
       ", {\n",
       "    \"showlegend\": true,\n",
       "    \"xaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            0.0,\n",
       "            25.0,\n",
       "            50.0,\n",
       "            75.0,\n",
       "            100.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            -3.61237789197,\n",
       "            124.02497429097001\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.03619130941965587,\n",
       "            0.9934383202099738\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"0\",\n",
       "            \"25\",\n",
       "            \"50\",\n",
       "            \"75\",\n",
       "            \"100\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"y1\"\n",
       "    },\n",
       "    \"paper_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"annotations\": [],\n",
       "    \"height\": 400,\n",
       "    \"margin\": {\n",
       "        \"l\": 0,\n",
       "        \"b\": 20,\n",
       "        \"r\": 0,\n",
       "        \"t\": 20\n",
       "    },\n",
       "    \"plot_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"yaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            0.0,\n",
       "            10.0,\n",
       "            20.0,\n",
       "            30.0,\n",
       "            40.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            -0.011528724772529308,\n",
       "            44.50335172803421\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.03762029746281716,\n",
       "            0.9901574803149606\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"0\",\n",
       "            \"10\",\n",
       "            \"20\",\n",
       "            \"30\",\n",
       "            \"40\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"x1\"\n",
       "    },\n",
       "    \"legend\": {\n",
       "        \"tracegroupgap\": 0,\n",
       "        \"bordercolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "        \"font\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"y\": 1.0,\n",
       "        \"x\": 1.0\n",
       "    },\n",
       "    \"width\": 600\n",
       "}\n",
       ");\n",
       "    </script>\n",
       "\n",
       "    </body>\n",
       "</html>\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = plot(resultBHHHshs[:Times], resultBHHHshs[:DistTo], label=\"BHHH sHs\")\n",
    "plot!(resultBHHHtv[:Times], resultBHHHtv[:DistTo], label=\"BHHH tv\")\n",
    "plot!(resultHEStv[:Times], resultHEStv[:DistTo], label=\"Hes tv\")\n",
    "plot!(resultIR[:Times], resultIR[:DistTo], label=\"IR\")\n",
    "plot!(resultAdam[:Times], resultAdam[:DistTo], label=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "innocent-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "BHHH sHs",
         "line": {
          "color": "rgba(0, 154, 250, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "BHHH sHs",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.028951099,
          0.031026,
          0.046391100000000005,
          0.1452564,
          0.30891280000000004,
          0.43125250000000004,
          0.5498359,
          0.7212557,
          0.8437945,
          0.9149322000000001,
          0.9213070000000001,
          1.1209484,
          1.2817927,
          1.2860497000000002,
          1.2889731,
          1.4560411000000002,
          1.4595765,
          1.5123583,
          1.514334799,
          1.6843022,
          1.8008465,
          1.878759,
          1.9159902990000002,
          2.0737358,
          2.0784138000000003,
          2.109887,
          2.2426001,
          2.3217861,
          2.4607755,
          2.4928903,
          2.7060979,
          2.8673978,
          2.9188357000000003,
          2.9598429000000004,
          2.9946921,
          3.1354713000000003,
          3.3215253000000002,
          3.4075921,
          3.4135421000000004,
          3.6062049000000003,
          3.6602147,
          3.8250037000000003,
          3.8481139000000004,
          4.0014859000000005,
          4.113540100000001,
          4.3638959,
          4.4281856,
          4.457624200000001,
          4.590722100000001,
          4.736018799,
          4.9618928,
          4.992293,
          5.0691844,
          5.075886199,
          5.121241099000001,
          5.2543785000000005,
          5.296353300000001,
          5.419961000000001,
          5.489815800000001,
          5.703805,
          5.774078,
          5.9139682,
          6.0668791,
          6.184329799,
          6.3563846,
          6.4154127,
          6.503029199,
          6.6810131,
          6.863114099000001,
          7.0019406,
          7.174456,
          7.2837003000000005,
          7.4083503,
          7.456937000000001,
          7.682263600000001,
          7.7911985,
          7.969227200000001,
          8.065038000000001,
          8.2698902,
          8.403718600000001,
          8.5425479,
          8.676073699,
          8.760623200000001,
          8.865948900000001,
          9.1326626,
          9.161282700000001,
          9.333368,
          9.4699924,
          9.6516239,
          9.7506623,
          9.925135200000001,
          10.3040417,
          10.4221456,
          10.564974300000001,
          10.6427783,
          10.9171581,
          11.055684600000001,
          11.4856052,
          11.9150305,
          12.229078299000001,
          12.447800500000001,
          12.925536899,
          13.284064999000002,
          13.5310103,
          14.033294600000001,
          14.7347838,
          15.2088885,
          15.6779951,
          16.005467799,
          16.5789186,
          17.352063700000002,
          18.007499000000003,
          18.499450299,
          18.816471200000002,
          19.454051699,
          20.3459788,
          21.118444200000003,
          21.6022921,
          22.541036299,
          23.149169500000003,
          24.0127841,
          24.589009400000002,
          25.3130853,
          25.898917200000003,
          26.377033200000003,
          26.735717500000003,
          26.9944385,
          27.2482526,
          27.7108035,
          28.3205646,
          28.985231399000003,
          29.432001900000003,
          29.9909517,
          30.712026400000003,
          31.2507948,
          31.677040700000003,
          32.467490899000005,
          33.194005799,
          33.6881871,
          34.514043499,
          35.1594895,
          36.0226532,
          36.801492999000004,
          38.1946061,
          39.2485611,
          40.0125137,
          41.4176056,
          42.612678499000005,
          44.089058199,
          45.231945199,
          46.0790396,
          47.5242379,
          49.2687851,
          50.56918700000001,
          51.6125929,
          52.459180399000005,
          53.1037334,
          53.5912458,
          53.967686400000005,
          54.6097849,
          55.64872020000001,
          56.463711700000005,
          57.102518199,
          58.012054000000006,
          58.989840400000006,
          59.6863875,
          60.219311000000005,
          61.215764500000006,
          62.011559499,
          62.6141578,
          63.176583,
          64.0497915,
          64.69464620000001,
          65.2794674,
          66.2769765,
          67.0448143,
          67.683318799,
          68.76704570000001,
          69.907879599,
          70.781227199,
          71.4324757,
          72.0224633,
          72.72717940000001,
          73.46209389900001,
          74.66591910000001,
          75.59207430000001,
          76.33412410000001,
          77.5087955,
          78.388967799,
          79.8655925,
          81.109682799,
          83.28142410000001,
          85.300773,
          87.2266438,
          88.3650305,
          89.810261799,
          91.04032589900001,
          92.1248297,
          92.9489104,
          94.04960549900001,
          95.65968170000001,
          97.0533087,
          98.132065299,
          99.88273059900001,
          101.3416933,
          102.62263490000001,
          103.6486423,
          105.18757570000001,
          106.4483986,
          107.410989599,
          108.67118310000001,
          110.3070107,
          112.6945663,
          114.61384190000001,
          116.16653329900001,
          117.22802220000001,
          118.77376480000001,
          120.41259639900001
         ],
         "xaxis": "x1",
         "y": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        },
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "BHHH tv",
         "line": {
          "color": "rgba(227, 111, 71, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "BHHH tv",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.17369410000000002,
          0.18485029900000002,
          0.2063202,
          0.3876198,
          0.532660499,
          0.6470128,
          0.785217,
          0.8842850000000001,
          1.0164695990000001,
          1.0527704,
          1.1737328,
          1.2018503,
          1.3008493,
          1.419470999,
          1.434797499,
          1.436035599,
          1.5419207000000001,
          1.645865399,
          1.8780564000000002,
          2.0374865
         ],
         "xaxis": "x1",
         "y": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        },
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "Hes tv",
         "line": {
          "color": "rgba(62, 164, 78, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "Hes tv",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.209733299,
          0.249059,
          0.29550249900000003,
          0.408523499,
          0.568902099,
          0.7076244,
          0.8469837,
          0.9578208990000001,
          1.121287999,
          1.1397665000000001,
          1.1683168000000002,
          1.4055315000000002,
          1.580116199,
          1.7767686,
          1.9659655,
          2.137157099,
          2.434360099,
          2.4969266,
          2.5378836000000002,
          2.559651599
         ],
         "xaxis": "x1",
         "y": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        },
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "IR",
         "line": {
          "color": "rgba(195, 113, 210, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "IR",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.8762630990000001,
          1.0486858000000001,
          1.198554799,
          1.4055425000000001,
          1.6074843,
          1.7540329000000001,
          1.9502664,
          2.120530799,
          2.3026288000000004,
          2.4838987,
          2.589203699,
          2.8049155000000003,
          2.9320727,
          2.9714974,
          3.0842569990000004,
          3.2111636000000003,
          3.3506341,
          3.4907365990000003,
          3.5961006,
          3.7930689990000004,
          3.9248878990000002,
          3.9427361000000003,
          4.0593007000000005,
          4.2319334,
          4.429452099000001,
          4.5600225000000005,
          4.725327500000001,
          4.8614445,
          5.028804599,
          5.057801099000001,
          5.1871974000000005,
          5.316583799,
          5.4919947,
          5.6551524,
          5.7748869,
          5.939776800000001,
          6.0916978,
          6.305307,
          6.4327899,
          6.6218253,
          6.754254400000001,
          6.9158511,
          7.0894127000000005,
          7.1071375990000005,
          7.256495200000001,
          7.379185400000001,
          7.4931412,
          7.610903400000001,
          7.804367899000001,
          7.9097856,
          8.0520805,
          8.0843684,
          8.255606099000001,
          8.404055000000001,
          8.534606100000001,
          8.652867200000001,
          8.8525389,
          8.9779918,
          9.0330385,
          9.154501699,
          9.294238,
          9.452529699000001,
          9.564264000000001,
          9.6841585,
          9.7079369,
          9.8561408,
          9.9549514,
          10.0876713,
          10.214286899000001,
          10.3141572,
          10.436802400000001,
          10.581230599000001,
          10.750874099,
          10.9673554,
          11.035861799000001,
          11.153172900000001,
          11.256066200000001,
          11.4354321,
          11.554885800000001,
          11.760837800000001,
          11.9074544,
          11.939724100000001,
          12.0981977,
          12.2370932,
          12.359006500000001,
          12.470793599,
          12.6100659,
          12.614076999,
          12.733841399000001,
          12.893728900000001,
          13.0106827,
          13.129425000000001,
          13.276799,
          13.377885500000001,
          13.4825286,
          13.485190600000001,
          13.595366100000001,
          13.693931099,
          13.811805199,
          13.992859200000002,
          14.093696900000001,
          14.2117286,
          14.392397500000001,
          14.436712000000002,
          14.554985,
          14.7084349,
          14.868963599,
          15.058553700000001,
          15.254578500000001,
          15.272606799,
          15.470820900000001,
          15.6235628,
          15.7617188,
          15.8960138,
          16.019628700000002,
          16.1899158,
          16.2949391,
          16.2975983,
          16.475478499,
          16.6154526,
          16.7727015,
          16.929238599,
          17.0545878,
          17.1789908,
          17.298726299000002,
          17.330182699,
          17.481676,
          17.6211515,
          17.7643612,
          17.9288725,
          18.0347847,
          18.153686,
          18.345438700000003,
          18.4789888,
          18.510538200000003,
          18.6573628,
          18.822969500000003,
          18.977780299000003,
          19.1493842,
          19.255051,
          19.4098201,
          19.531427199,
          19.577500499000003,
          19.7120649,
          19.826514499,
          19.9572505,
          20.057918100000002,
          20.191079399,
          20.3242845,
          20.4443559,
          20.6102884,
          20.613573999,
          20.7131846,
          20.8543834,
          21.008808999000003,
          21.2353747,
          21.338163799,
          21.437728,
          21.5413093,
          21.603071099,
          21.7401076,
          21.937923299,
          22.053801799000002,
          22.1756645,
          22.275311699000003,
          22.378481500000003,
          22.480401299,
          22.5810371,
          22.5835721,
          22.701059200000003,
          22.863661800000003,
          22.962971699,
          23.0656633,
          23.182425799,
          23.379449100000002,
          23.565456400000002,
          23.589639899,
          23.719011799,
          23.8405302,
          23.963405100000003,
          24.099289300000002,
          24.200761,
          24.388312300000003,
          24.5367651,
          24.674922900000002,
          24.745222300000002,
          24.9344566,
          25.034576099000002,
          25.1377513,
          25.2876085,
          25.471190499000002,
          25.626517200000002,
          25.795855500000002,
          25.814067,
          25.915367800000002,
          26.065248500000003,
          26.279377200000003,
          26.3962274,
          26.5304046,
          26.6959309,
          26.8378544,
          26.9760533,
          26.996555800000003,
          27.108435799000002,
          27.247860899000003,
          27.3870554,
          27.5193762,
          27.640779299000002,
          27.792832099,
          27.917137299,
          27.9420463,
          28.1419587,
          28.260902799,
          28.3788112,
          28.492030300000003,
          28.617063,
          28.718584099,
          28.8421325,
          28.980437100000003,
          29.0163271,
          29.144952999,
          29.267283600000003,
          29.369866000000002,
          29.5468797,
          29.6499625,
          29.7523687,
          29.9039444,
          29.925316199,
          30.110689200000003,
          30.267326,
          30.434168699,
          30.569648,
          30.696987399,
          30.8558932,
          31.009389399000003,
          31.134481299,
          31.188471899000003,
          31.3425797,
          31.4772734,
          31.6249143,
          31.7254994,
          31.826300699,
          31.9845705,
          32.0852755,
          32.1131268,
          32.2546004,
          32.375701500000005,
          32.475638299,
          32.6022491,
          32.7283665,
          32.864000999000005,
          33.008385600000004,
          33.1872866,
          33.203317199000004,
          33.340807799000004,
          33.4416802,
          33.571251700000005,
          33.672282499000005,
          33.771924699,
          33.9209472,
          34.026757299,
          34.0296678,
          34.149349999,
          34.248158899,
          34.348682399000005,
          34.463278399000004,
          34.665905599000006,
          34.789110499,
          34.9457979,
          35.1072654,
          35.140640000000005,
          35.2497983,
          35.437699799,
          35.580553,
          35.725785199,
          35.959918900000005,
          36.0814557,
          36.252656,
          36.2826855,
          36.4323558,
          36.5773643,
          36.740892800000005,
          36.914163399,
          37.069955499,
          37.1920469,
          37.3377385,
          37.502714100000006,
          37.5367577,
          37.637187899000004,
          37.788008299000005,
          37.976814100000006,
          38.0944591,
          38.206459999,
          38.3857561,
          38.5013062,
          38.5599514,
          38.714640199,
          38.836751500000005,
          38.978321400000006,
          39.144853299000005,
          39.2461502,
          39.3492894,
          39.450985599,
          39.5559012,
          39.5782206,
          39.678205399,
          39.8038838,
          39.9064982,
          40.0084285,
          40.158839900000004,
          40.266447400000004,
          40.370611600000004,
          40.3733451,
          40.475327,
          40.606900299,
          40.818207900000004,
          40.9768503,
          41.0970486,
          41.21528,
          41.344913999,
          41.526230399,
          41.632324699,
          41.757385999,
          41.8557949,
          41.972371800000005,
          42.100321,
          42.227045199,
          42.396405899,
          42.517423999,
          42.565954100000006,
          42.670822499,
          42.822599299000004,
          42.9530248,
          43.093682799,
          43.2956556,
          43.4592296,
          43.5617467,
          43.742953899,
          43.795401499,
          43.936556700000004,
          44.0578659,
          44.211426100000004,
          44.349674500000006,
          44.452213500000006,
          44.570105500000004,
          44.6929243,
          44.709913400000005,
          44.8507881,
          44.9925957,
          45.1285886,
          45.2844211,
          45.45366,
          45.610999400000004,
          45.8169641,
          45.9854563,
          46.056301999000006,
          46.1749597,
          46.381682899000005,
          46.5040672,
          46.646099699000004,
          46.805627900000005,
          46.945877,
          47.047068699,
          47.109970800000006,
          47.273971,
          47.39641,
          47.526514600000006,
          47.625299399000006,
          47.726553900000006,
          47.827934699000004,
          47.94847600000001,
          48.0550744,
          48.058249200000006,
          48.157116599000005,
          48.357981300000006,
          48.513547399000004,
          48.653254999000005,
          48.78309,
          48.8854333,
          49.0286495,
          49.0316605,
          49.128433399,
          49.244871399000004,
          49.3449704,
          49.495848900000006,
          49.617505200000004,
          49.7182959,
          49.820784100000004,
          49.926950700000006,
          49.9747111,
          50.121713,
          50.271141300000004,
          50.439939399000004,
          50.626067600000006,
          50.782987499,
          50.9644727,
          51.082284,
          51.0845299,
          51.2215471,
          51.3356423,
          51.4343275,
          51.5418414,
          51.699710199,
          51.837729700000004,
          51.939813400000006,
          52.0683458,
          52.117494499,
          52.2897158,
          52.426822799,
          52.5644222,
          52.726962599000004,
          52.943947800000004,
          53.0984095,
          53.2152625,
          53.2636514,
          53.4140701,
          53.530469200000006,
          53.658740200000004,
          53.813616799,
          53.9140522,
          54.030796200000005,
          54.143422400000006,
          54.28597490000001,
          54.288557100000006,
          54.407219100000006,
          54.527783500000005,
          54.6653522,
          54.79078560000001,
          54.942377799000006,
          55.048758400000004,
          55.152296400000004,
          55.154830299000004,
          55.255788499000005,
          55.375555000000006,
          55.5407554,
          55.658826000000005,
          55.7817385,
          55.8844982,
          55.9880581,
          56.1443097,
          56.2490552,
          56.394463999,
          56.514740299,
          56.70048159900001,
          56.8488976,
          56.9996233,
          57.1436895,
          57.266783200000006,
          57.271756999000004,
          57.417186300000004,
          57.539357300000006,
          57.658060500000005,
          57.815261399,
          57.9726458,
          58.128579199,
          58.244838,
          58.3836687,
          58.4545073,
          58.611424899000006,
          58.726597500000004,
          58.863513099,
          58.985052800000005,
          59.1320756,
          59.2473381,
          59.4309705,
          59.4606384,
          59.5947638,
          59.710581100000006,
          59.8127403,
          59.9370398,
          60.0394969,
          60.1410131,
          60.24152050000001,
          60.424257100000005,
          60.439157800000004,
          60.619068000000006,
          60.79908270000001,
          60.932639599000005,
          61.053765299000005,
          61.2264313,
          61.3513413,
          61.5464087,
          61.561027399000004,
          61.702958399,
          61.816301799,
          61.970145300000006,
          62.110882899,
          62.224248499000005,
          62.3828776,
          62.511225100000004,
          62.616609099,
          62.701220500000005,
          62.8416435,
          63.037250900000004,
          63.164780400000005,
          63.281649599000005,
          63.400617699,
          63.55545389900001,
          63.6782952,
          63.74183089900001,
          63.873128099000006,
          64.0204621,
          64.20040130000001,
          64.33640479900001,
          64.4683129,
          64.6178531,
          64.8303186,
          64.9711158,
          64.97362929900001,
          65.1354688,
          65.24864039900001,
          65.383938099,
          65.5335022,
          65.7201563,
          65.918757399,
          66.1228178,
          66.249435999,
          66.405831199,
          66.57299729900001,
          66.6745393,
          66.819403799,
          66.9223699,
          67.04304450000001,
          67.2009848,
          67.376760699,
          67.397575999,
          67.5540613,
          67.653668599,
          67.7531613,
          67.854878,
          68.0068612,
          68.128979,
          68.2431846,
          68.2911313,
          68.4074324,
          68.5545305,
          68.65464010000001,
          68.7913453,
          68.892582,
          69.02815410000001,
          69.16499300000001,
          69.26688440000001,
          69.2694352,
          69.36885310000001,
          69.5495466,
          69.6616934,
          69.7639439,
          69.9053985,
          70.05361470000001,
          70.2677098,
          70.3175801,
          70.466268099,
          70.6206952,
          70.75054970000001,
          70.85997199900001,
          71.02545140000001,
          71.1857906,
          71.40823610000001,
          71.5912656,
          71.62136860000001,
          71.72382610000001,
          71.83587049900001,
          71.938457799,
          72.037382099,
          72.155878199,
          72.261161,
          72.3643576,
          72.3672909,
          72.4682184,
          72.567692799,
          72.669709,
          72.8051128,
          72.90335110000001,
          73.044337,
          73.1493756,
          73.318201,
          73.35915870000001,
          73.46000360000001,
          73.558442799,
          73.69868619900001,
          73.820330599,
          73.9555375,
          74.09374000000001,
          74.230623099,
          74.2703607,
          74.4015018,
          74.5001963,
          74.64895909900001,
          74.752080499,
          74.89417319900001,
          74.9927727,
          75.1167944,
          75.220640699,
          75.223292799,
          75.40719560000001,
          75.5198654,
          75.6270564,
          75.7909736,
          75.985805299,
          76.1305918,
          76.3369277,
          76.3773541,
          76.54678990000001,
          76.7161123,
          76.8845407,
          77.1381762,
          77.261719,
          77.43194960000001,
          77.5692379,
          77.6715188,
          77.6740898,
          77.7730083,
          77.89229920000001,
          77.9933618,
          78.15038119900001,
          78.31347120000001,
          78.4697245,
          78.6144472,
          78.6663218,
          78.7967715,
          78.91025880000001,
          79.1427117,
          79.277887699,
          79.3901943,
          79.5260444,
          79.664208599,
          79.81207640000001,
          79.8157367,
          79.9147355,
          80.0534142,
          80.16924180000001,
          80.30394270000001,
          80.4488395,
          80.55837449900001,
          80.7418703,
          80.7750944,
          80.89469309900001,
          80.996731099,
          81.190382799,
          81.3992149,
          81.5578126,
          81.737806,
          81.8557244,
          82.00589430000001,
          82.0283187,
          82.19674570000001,
          82.3081308,
          82.43020809900001,
          82.55090940000001,
          82.6723405,
          82.8184049,
          82.9604894,
          82.9629781,
          83.0608916,
          83.19657020000001,
          83.3323936,
          83.43185720000001,
          83.545423799,
          83.65731539900001,
          83.775333,
          83.918765499,
          83.9815573,
          84.127890699,
          84.25634480000001,
          84.42990249900001,
          84.55242050000001,
          84.6721334,
          84.7758154,
          84.9187086,
          84.9221174,
          85.1075989,
          85.20689850000001,
          85.307249,
          85.426127099,
          85.5258294,
          85.6926031,
          85.91295689900001,
          86.139066899,
          86.1426163,
          86.278217399,
          86.4126705,
          86.53774580000001,
          86.6532387,
          86.804618,
          86.9251515,
          87.0276951,
          87.0812873,
          87.206230499,
          87.31296660000001,
          87.4334944,
          87.57776940000001,
          87.70507400000001,
          87.806915,
          87.91069540000001,
          88.03222690000001,
          88.104285699,
          88.2566587,
          88.378642,
          88.4794217,
          88.58113789900001,
          88.7116154,
          88.81205650000001,
          88.96010549900001,
          88.97843049900001,
          89.0923717,
          89.206613499,
          89.4017678,
          89.50540430000001,
          89.62523610000001,
          89.78142890000001,
          89.9552646,
          90.11152170000001,
          90.114857799,
          90.235409199,
          90.38011479900001,
          90.5140356,
          90.6654388,
          90.79426620000001,
          90.9436264,
          91.079196999,
          91.14065860000001,
          91.2689917,
          91.3813123,
          91.54052730000001,
          91.6580423,
          91.7980189,
          91.9163436,
          92.0250432,
          92.1277433,
          92.15815710000001,
          92.26337229900001,
          92.367671199,
          92.472464,
          92.57658400000001,
          92.7368165,
          92.8887124,
          93.0063786,
          93.03119310000001,
          93.1538783,
          93.296017,
          93.4261587,
          93.526336799,
          93.6571876,
          93.7863564,
          93.931031,
          94.03577049900001,
          94.038270099,
          94.1784186,
          94.28610609900001,
          94.40210450000001,
          94.58581729900001,
          94.77111190000001,
          94.8880232,
          95.00914300000001,
          95.01220299900001,
          95.14761010000001,
          95.3638579,
          95.5163665,
          95.72570079900001,
          95.8324489,
          95.9620237,
          96.06491910000001,
          96.1690231,
          96.17155050000001,
          96.32702880000001,
          96.5544735,
          96.6553617,
          96.8046984,
          96.9066557,
          97.0063214,
          97.1089745,
          97.11144580000001,
          97.21205459900001,
          97.331306599,
          97.460770999,
          97.5763785,
          97.67760100000001,
          97.8022306,
          97.90595180000001,
          98.04851299900001,
          98.10592030000001,
          98.230675899,
          98.3408964,
          98.4943879,
          98.592598299,
          98.69692230000001,
          98.8167806,
          98.98849619900001,
          99.03005119900001,
          99.21935970000001,
          99.34005919900001,
          99.4627025,
          99.56323250000001,
          99.696291899,
          99.856624799,
          100.0102164,
          100.12721470000001,
          100.1298392,
          100.22985530000001,
          100.41425650000001,
          100.6033855,
          100.8082174,
          100.94961660000001,
          101.048834099,
          101.2198961,
          101.2235007,
          101.34451130000001,
          101.4681736,
          101.597803299,
          101.69744150000001,
          101.7995709,
          101.9051446,
          102.00825560000001,
          102.136412,
          102.15386160000001,
          102.312584899,
          102.4892712,
          102.64214580000001,
          102.81098119900001,
          102.931173199,
          103.04666319900001,
          103.149179899,
          103.15154550000001,
          103.274288399,
          103.4168946,
          103.5325916,
          103.71371369900001,
          103.815482899,
          103.95266570000001,
          104.1081209,
          104.23583550000001,
          104.26184140000001,
          104.45330100000001,
          104.60396840000001,
          104.717575099,
          104.91538820000001,
          105.0951036,
          105.3076439,
          105.46894160000001,
          105.52494680000001,
          105.70275430000001,
          105.87369020000001,
          105.99524779900001,
          106.157139599,
          106.304118,
          106.44933160000001,
          106.59254290000001,
          106.76454740000001,
          106.7669908,
          106.870322899,
          107.03564560000001,
          107.1717952,
          107.27748960000001,
          107.381208599,
          107.50906799900001,
          107.6404784,
          107.7010195,
          107.80699859900001,
          107.92796879900001,
          108.0607166,
          108.183244399,
          108.37857650000001,
          108.510558699,
          108.64851200000001,
          108.7770263,
          108.83577220000001,
          108.98201820000001,
          109.120123899,
          109.27961230000001,
          109.47314580000001,
          109.61442570000001,
          109.77785739900001,
          109.9151078,
          109.9175611,
          110.0412211,
          110.20201300000001,
          110.34034899900001,
          110.49549199900001,
          110.672542699,
          110.8598219,
          110.99110850000001,
          111.1333984,
          111.15187730000001,
          111.29687719900001,
          111.5317998,
          111.6729061,
          111.81300870000001,
          111.9655453,
          112.1097912,
          112.230401399,
          112.29628859900001,
          112.40273250000001,
          112.5082251,
          112.6416494,
          112.761759299,
          112.8646264,
          113.01206509900001,
          113.14327530000001,
          113.28914440000001,
          113.29200920000001,
          113.4249714,
          113.54358249900001,
          113.6850533,
          113.8037764,
          113.980180199,
          114.1675599,
          114.301893,
          114.333316299,
          114.47017840000001,
          114.6139756,
          114.73677180000001,
          114.90056240000001,
          115.09393370000001,
          115.208248999,
          115.351487699,
          115.521176599,
          115.556027399,
          115.713798799,
          115.8150224,
          115.94136390000001,
          116.04242749900001,
          116.162405199,
          116.2875322,
          116.412614,
          116.45074690000001,
          116.5770846,
          116.7162844,
          116.8503,
          117.05291930000001,
          117.19432610000001,
          117.36101279900001,
          117.53026720000001,
          117.6766484,
          117.67981440000001,
          117.79624500000001,
          117.93106730000001,
          118.1077279,
          118.30936890000001,
          118.4115022,
          118.51383510000001,
          118.61527729900001,
          118.61774019900001,
          118.71550880000001,
          118.8321518,
          118.991676999,
          119.12454349900001,
          119.263096699,
          119.363421099,
          119.54803430000001,
          119.6968291,
          119.6998734,
          119.8360983,
          120.03361020000001
         ],
         "xaxis": "x1",
         "y": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        },
        {
         "colorbar": {
          "title": ""
         },
         "legendgroup": "Adam",
         "line": {
          "color": "rgba(172, 142, 24, 1.000)",
          "dash": "solid",
          "shape": "linear",
          "width": 1
         },
         "mode": "lines",
         "name": "Adam",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          0.2729649,
          0.304959099,
          0.3194018,
          0.33427850000000003,
          0.34627470000000005,
          0.359363099,
          0.3767783,
          0.4091014,
          0.42943149900000005,
          0.4427265,
          0.46602730000000003,
          0.48831509900000003,
          0.5331612,
          0.5529344,
          0.5738894,
          0.5965994,
          0.6551052,
          0.6777986,
          0.7039433,
          0.7429425000000001,
          0.7565889,
          0.7857541,
          0.8111665990000001,
          0.8256203990000001,
          0.8753309,
          0.902424399,
          0.9221822000000001,
          0.9589931,
          0.973958399,
          0.9933919990000001,
          1.019137199,
          1.043984,
          1.0658192,
          1.0933928000000002,
          1.133321099,
          1.1752859,
          1.2013022990000002,
          1.221937,
          1.2444263,
          1.2641703,
          1.3202577,
          1.361808399,
          1.4263162,
          1.4574507,
          1.5140142,
          1.567762499,
          1.5850348,
          1.6212102000000002,
          1.6385900000000002,
          1.6558362000000002,
          1.6697205000000002,
          1.6836781,
          1.6999981000000002,
          1.7195202,
          1.7418885000000002,
          1.7781621,
          1.8225065,
          1.8516314,
          1.8890759990000001,
          1.9147174,
          1.948242999,
          1.980441799,
          2.0669386000000003,
          2.0876887,
          2.136725,
          2.1610529,
          2.2007700000000003,
          2.2258724,
          2.2412832000000003,
          2.2610628,
          2.277262899,
          2.2920368,
          2.3096402,
          2.344273699,
          2.3579934000000002,
          2.3702986000000004,
          2.384085499,
          2.4079559,
          2.4235719000000002,
          2.463089799,
          2.4795181,
          2.5005876000000002,
          2.5136324990000003,
          2.531735899,
          2.5480759,
          2.563667,
          2.5766337000000004,
          2.5910982000000002,
          2.630361599,
          2.6681973,
          2.6836828,
          2.7004571000000004,
          2.7147569000000003,
          2.7319832,
          2.7475564990000003,
          2.762578999,
          2.779281799,
          2.794761899,
          2.8088156,
          2.8229179
         ],
         "xaxis": "x1",
         "y": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "yaxis": "y1",
         "zmax": null,
         "zmin": null
        }
       ],
       "layout": {
        "annotations": [],
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 1.000)",
         "bordercolor": "rgba(0, 0, 0, 1.000)",
         "font": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tracegroupgap": 0,
         "x": 1,
         "y": 1
        },
        "margin": {
         "b": 20,
         "l": 0,
         "r": 0,
         "t": 20
        },
        "paper_bgcolor": "rgba(255, 255, 255, 1.000)",
        "plot_bgcolor": "rgba(255, 255, 255, 1.000)",
        "showlegend": true,
        "width": 600,
        "xaxis": {
         "anchor": "y1",
         "domain": [
          0.07646908719743364,
          0.9934383202099737
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          -3.61237789197,
          124.02497429097001
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "0",
          "25",
          "50",
          "75",
          "100"
         ],
         "tickvals": [
          0,
          25,
          50,
          75,
          100
         ],
         "title": "time",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        },
        "yaxis": {
         "anchor": "x1",
         "domain": [
          0.07581474190726165,
          0.9901574803149606
         ],
         "gridcolor": "rgba(0, 0, 0, 0.100)",
         "gridwidth": 0.5,
         "linecolor": "rgba(0, 0, 0, 1.000)",
         "mirror": false,
         "range": [
          -28.59,
          981.59
         ],
         "showgrid": true,
         "showline": true,
         "showticklabels": true,
         "tickangle": 0,
         "tickcolor": "rgb(0, 0, 0)",
         "tickfont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 11
         },
         "tickmode": "array",
         "ticks": "inside",
         "ticktext": [
          "0",
          "200",
          "400",
          "600",
          "800"
         ],
         "tickvals": [
          0,
          200,
          400,
          600,
          800
         ],
         "title": "Iter",
         "titlefont": {
          "color": "rgba(0, 0, 0, 1.000)",
          "family": "sans-serif",
          "size": 15
         },
         "type": "-",
         "visible": true,
         "zeroline": false,
         "zerolinecolor": "rgba(0, 0, 0, 1.000)"
        }
       }
      },
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "    <head>\n",
       "        <title>Plots.jl</title>\n",
       "        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
       "    </head>\n",
       "    <body>\n",
       "            <div id=\"e8ef84c3-4626-4251-aaed-f46d943ccac0\" style=\"width:600px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('e8ef84c3-4626-4251-aaed-f46d943ccac0');\n",
       "    Plotly.plot(PLOT, [\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.028951099,\n",
       "            0.031026,\n",
       "            0.046391100000000005,\n",
       "            0.1452564,\n",
       "            0.30891280000000004,\n",
       "            0.43125250000000004,\n",
       "            0.5498359,\n",
       "            0.7212557,\n",
       "            0.8437945,\n",
       "            0.9149322000000001,\n",
       "            0.9213070000000001,\n",
       "            1.1209484,\n",
       "            1.2817927,\n",
       "            1.2860497000000002,\n",
       "            1.2889731,\n",
       "            1.4560411000000002,\n",
       "            1.4595765,\n",
       "            1.5123583,\n",
       "            1.514334799,\n",
       "            1.6843022,\n",
       "            1.8008465,\n",
       "            1.878759,\n",
       "            1.9159902990000002,\n",
       "            2.0737358,\n",
       "            2.0784138000000003,\n",
       "            2.109887,\n",
       "            2.2426001,\n",
       "            2.3217861,\n",
       "            2.4607755,\n",
       "            2.4928903,\n",
       "            2.7060979,\n",
       "            2.8673978,\n",
       "            2.9188357000000003,\n",
       "            2.9598429000000004,\n",
       "            2.9946921,\n",
       "            3.1354713000000003,\n",
       "            3.3215253000000002,\n",
       "            3.4075921,\n",
       "            3.4135421000000004,\n",
       "            3.6062049000000003,\n",
       "            3.6602147,\n",
       "            3.8250037000000003,\n",
       "            3.8481139000000004,\n",
       "            4.0014859000000005,\n",
       "            4.113540100000001,\n",
       "            4.3638959,\n",
       "            4.4281856,\n",
       "            4.457624200000001,\n",
       "            4.590722100000001,\n",
       "            4.736018799,\n",
       "            4.9618928,\n",
       "            4.992293,\n",
       "            5.0691844,\n",
       "            5.075886199,\n",
       "            5.121241099000001,\n",
       "            5.2543785000000005,\n",
       "            5.296353300000001,\n",
       "            5.419961000000001,\n",
       "            5.489815800000001,\n",
       "            5.703805,\n",
       "            5.774078,\n",
       "            5.9139682,\n",
       "            6.0668791,\n",
       "            6.184329799,\n",
       "            6.3563846,\n",
       "            6.4154127,\n",
       "            6.503029199,\n",
       "            6.6810131,\n",
       "            6.863114099000001,\n",
       "            7.0019406,\n",
       "            7.174456,\n",
       "            7.2837003000000005,\n",
       "            7.4083503,\n",
       "            7.456937000000001,\n",
       "            7.682263600000001,\n",
       "            7.7911985,\n",
       "            7.969227200000001,\n",
       "            8.065038000000001,\n",
       "            8.2698902,\n",
       "            8.403718600000001,\n",
       "            8.5425479,\n",
       "            8.676073699,\n",
       "            8.760623200000001,\n",
       "            8.865948900000001,\n",
       "            9.1326626,\n",
       "            9.161282700000001,\n",
       "            9.333368,\n",
       "            9.4699924,\n",
       "            9.6516239,\n",
       "            9.7506623,\n",
       "            9.925135200000001,\n",
       "            10.3040417,\n",
       "            10.4221456,\n",
       "            10.564974300000001,\n",
       "            10.6427783,\n",
       "            10.9171581,\n",
       "            11.055684600000001,\n",
       "            11.4856052,\n",
       "            11.9150305,\n",
       "            12.229078299000001,\n",
       "            12.447800500000001,\n",
       "            12.925536899,\n",
       "            13.284064999000002,\n",
       "            13.5310103,\n",
       "            14.033294600000001,\n",
       "            14.7347838,\n",
       "            15.2088885,\n",
       "            15.6779951,\n",
       "            16.005467799,\n",
       "            16.5789186,\n",
       "            17.352063700000002,\n",
       "            18.007499000000003,\n",
       "            18.499450299,\n",
       "            18.816471200000002,\n",
       "            19.454051699,\n",
       "            20.3459788,\n",
       "            21.118444200000003,\n",
       "            21.6022921,\n",
       "            22.541036299,\n",
       "            23.149169500000003,\n",
       "            24.0127841,\n",
       "            24.589009400000002,\n",
       "            25.3130853,\n",
       "            25.898917200000003,\n",
       "            26.377033200000003,\n",
       "            26.735717500000003,\n",
       "            26.9944385,\n",
       "            27.2482526,\n",
       "            27.7108035,\n",
       "            28.3205646,\n",
       "            28.985231399000003,\n",
       "            29.432001900000003,\n",
       "            29.9909517,\n",
       "            30.712026400000003,\n",
       "            31.2507948,\n",
       "            31.677040700000003,\n",
       "            32.467490899000005,\n",
       "            33.194005799,\n",
       "            33.6881871,\n",
       "            34.514043499,\n",
       "            35.1594895,\n",
       "            36.0226532,\n",
       "            36.801492999000004,\n",
       "            38.1946061,\n",
       "            39.2485611,\n",
       "            40.0125137,\n",
       "            41.4176056,\n",
       "            42.612678499000005,\n",
       "            44.089058199,\n",
       "            45.231945199,\n",
       "            46.0790396,\n",
       "            47.5242379,\n",
       "            49.2687851,\n",
       "            50.56918700000001,\n",
       "            51.6125929,\n",
       "            52.459180399000005,\n",
       "            53.1037334,\n",
       "            53.5912458,\n",
       "            53.967686400000005,\n",
       "            54.6097849,\n",
       "            55.64872020000001,\n",
       "            56.463711700000005,\n",
       "            57.102518199,\n",
       "            58.012054000000006,\n",
       "            58.989840400000006,\n",
       "            59.6863875,\n",
       "            60.219311000000005,\n",
       "            61.215764500000006,\n",
       "            62.011559499,\n",
       "            62.6141578,\n",
       "            63.176583,\n",
       "            64.0497915,\n",
       "            64.69464620000001,\n",
       "            65.2794674,\n",
       "            66.2769765,\n",
       "            67.0448143,\n",
       "            67.683318799,\n",
       "            68.76704570000001,\n",
       "            69.907879599,\n",
       "            70.781227199,\n",
       "            71.4324757,\n",
       "            72.0224633,\n",
       "            72.72717940000001,\n",
       "            73.46209389900001,\n",
       "            74.66591910000001,\n",
       "            75.59207430000001,\n",
       "            76.33412410000001,\n",
       "            77.5087955,\n",
       "            78.388967799,\n",
       "            79.8655925,\n",
       "            81.109682799,\n",
       "            83.28142410000001,\n",
       "            85.300773,\n",
       "            87.2266438,\n",
       "            88.3650305,\n",
       "            89.810261799,\n",
       "            91.04032589900001,\n",
       "            92.1248297,\n",
       "            92.9489104,\n",
       "            94.04960549900001,\n",
       "            95.65968170000001,\n",
       "            97.0533087,\n",
       "            98.132065299,\n",
       "            99.88273059900001,\n",
       "            101.3416933,\n",
       "            102.62263490000001,\n",
       "            103.6486423,\n",
       "            105.18757570000001,\n",
       "            106.4483986,\n",
       "            107.410989599,\n",
       "            108.67118310000001,\n",
       "            110.3070107,\n",
       "            112.6945663,\n",
       "            114.61384190000001,\n",
       "            116.16653329900001,\n",
       "            117.22802220000001,\n",
       "            118.77376480000001,\n",
       "            120.41259639900001\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"BHHH sHs\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"BHHH sHs\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(0, 154, 250, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            0.0,\n",
       "            1.0,\n",
       "            2.0,\n",
       "            3.0,\n",
       "            4.0,\n",
       "            5.0,\n",
       "            6.0,\n",
       "            7.0,\n",
       "            8.0,\n",
       "            9.0,\n",
       "            10.0,\n",
       "            11.0,\n",
       "            12.0,\n",
       "            13.0,\n",
       "            14.0,\n",
       "            15.0,\n",
       "            16.0,\n",
       "            17.0,\n",
       "            18.0,\n",
       "            19.0,\n",
       "            20.0,\n",
       "            21.0,\n",
       "            22.0,\n",
       "            23.0,\n",
       "            24.0,\n",
       "            25.0,\n",
       "            26.0,\n",
       "            27.0,\n",
       "            28.0,\n",
       "            29.0,\n",
       "            30.0,\n",
       "            31.0,\n",
       "            32.0,\n",
       "            33.0,\n",
       "            34.0,\n",
       "            35.0,\n",
       "            36.0,\n",
       "            37.0,\n",
       "            38.0,\n",
       "            39.0,\n",
       "            40.0,\n",
       "            41.0,\n",
       "            42.0,\n",
       "            43.0,\n",
       "            44.0,\n",
       "            45.0,\n",
       "            46.0,\n",
       "            47.0,\n",
       "            48.0,\n",
       "            49.0,\n",
       "            50.0,\n",
       "            51.0,\n",
       "            52.0,\n",
       "            53.0,\n",
       "            54.0,\n",
       "            55.0,\n",
       "            56.0,\n",
       "            57.0,\n",
       "            58.0,\n",
       "            59.0,\n",
       "            60.0,\n",
       "            61.0,\n",
       "            62.0,\n",
       "            63.0,\n",
       "            64.0,\n",
       "            65.0,\n",
       "            66.0,\n",
       "            67.0,\n",
       "            68.0,\n",
       "            69.0,\n",
       "            70.0,\n",
       "            71.0,\n",
       "            72.0,\n",
       "            73.0,\n",
       "            74.0,\n",
       "            75.0,\n",
       "            76.0,\n",
       "            77.0,\n",
       "            78.0,\n",
       "            79.0,\n",
       "            80.0,\n",
       "            81.0,\n",
       "            82.0,\n",
       "            83.0,\n",
       "            84.0,\n",
       "            85.0,\n",
       "            86.0,\n",
       "            87.0,\n",
       "            88.0,\n",
       "            89.0,\n",
       "            90.0,\n",
       "            91.0,\n",
       "            92.0,\n",
       "            93.0,\n",
       "            94.0,\n",
       "            95.0,\n",
       "            96.0,\n",
       "            97.0,\n",
       "            98.0,\n",
       "            99.0,\n",
       "            100.0,\n",
       "            101.0,\n",
       "            102.0,\n",
       "            103.0,\n",
       "            104.0,\n",
       "            105.0,\n",
       "            106.0,\n",
       "            107.0,\n",
       "            108.0,\n",
       "            109.0,\n",
       "            110.0,\n",
       "            111.0,\n",
       "            112.0,\n",
       "            113.0,\n",
       "            114.0,\n",
       "            115.0,\n",
       "            116.0,\n",
       "            117.0,\n",
       "            118.0,\n",
       "            119.0,\n",
       "            120.0,\n",
       "            121.0,\n",
       "            122.0,\n",
       "            123.0,\n",
       "            124.0,\n",
       "            125.0,\n",
       "            126.0,\n",
       "            127.0,\n",
       "            128.0,\n",
       "            129.0,\n",
       "            130.0,\n",
       "            131.0,\n",
       "            132.0,\n",
       "            133.0,\n",
       "            134.0,\n",
       "            135.0,\n",
       "            136.0,\n",
       "            137.0,\n",
       "            138.0,\n",
       "            139.0,\n",
       "            140.0,\n",
       "            141.0,\n",
       "            142.0,\n",
       "            143.0,\n",
       "            144.0,\n",
       "            145.0,\n",
       "            146.0,\n",
       "            147.0,\n",
       "            148.0,\n",
       "            149.0,\n",
       "            150.0,\n",
       "            151.0,\n",
       "            152.0,\n",
       "            153.0,\n",
       "            154.0,\n",
       "            155.0,\n",
       "            156.0,\n",
       "            157.0,\n",
       "            158.0,\n",
       "            159.0,\n",
       "            160.0,\n",
       "            161.0,\n",
       "            162.0,\n",
       "            163.0,\n",
       "            164.0,\n",
       "            165.0,\n",
       "            166.0,\n",
       "            167.0,\n",
       "            168.0,\n",
       "            169.0,\n",
       "            170.0,\n",
       "            171.0,\n",
       "            172.0,\n",
       "            173.0,\n",
       "            174.0,\n",
       "            175.0,\n",
       "            176.0,\n",
       "            177.0,\n",
       "            178.0,\n",
       "            179.0,\n",
       "            180.0,\n",
       "            181.0,\n",
       "            182.0,\n",
       "            183.0,\n",
       "            184.0,\n",
       "            185.0,\n",
       "            186.0,\n",
       "            187.0,\n",
       "            188.0,\n",
       "            189.0,\n",
       "            190.0,\n",
       "            191.0,\n",
       "            192.0,\n",
       "            193.0,\n",
       "            194.0,\n",
       "            195.0,\n",
       "            196.0,\n",
       "            197.0,\n",
       "            198.0,\n",
       "            199.0,\n",
       "            200.0,\n",
       "            201.0,\n",
       "            202.0,\n",
       "            203.0,\n",
       "            204.0,\n",
       "            205.0,\n",
       "            206.0,\n",
       "            207.0,\n",
       "            208.0,\n",
       "            209.0,\n",
       "            210.0,\n",
       "            211.0,\n",
       "            212.0,\n",
       "            213.0,\n",
       "            214.0,\n",
       "            215.0,\n",
       "            216.0,\n",
       "            217.0,\n",
       "            218.0\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    },\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.17369410000000002,\n",
       "            0.18485029900000002,\n",
       "            0.2063202,\n",
       "            0.3876198,\n",
       "            0.532660499,\n",
       "            0.6470128,\n",
       "            0.785217,\n",
       "            0.8842850000000001,\n",
       "            1.0164695990000001,\n",
       "            1.0527704,\n",
       "            1.1737328,\n",
       "            1.2018503,\n",
       "            1.3008493,\n",
       "            1.419470999,\n",
       "            1.434797499,\n",
       "            1.436035599,\n",
       "            1.5419207000000001,\n",
       "            1.645865399,\n",
       "            1.8780564000000002,\n",
       "            2.0374865\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"BHHH tv\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"BHHH tv\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(227, 111, 71, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            0.0,\n",
       "            1.0,\n",
       "            2.0,\n",
       "            3.0,\n",
       "            4.0,\n",
       "            5.0,\n",
       "            6.0,\n",
       "            7.0,\n",
       "            8.0,\n",
       "            9.0,\n",
       "            10.0,\n",
       "            11.0,\n",
       "            12.0,\n",
       "            13.0,\n",
       "            14.0,\n",
       "            15.0,\n",
       "            16.0,\n",
       "            17.0,\n",
       "            18.0,\n",
       "            19.0,\n",
       "            20.0\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    },\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.209733299,\n",
       "            0.249059,\n",
       "            0.29550249900000003,\n",
       "            0.408523499,\n",
       "            0.568902099,\n",
       "            0.7076244,\n",
       "            0.8469837,\n",
       "            0.9578208990000001,\n",
       "            1.121287999,\n",
       "            1.1397665000000001,\n",
       "            1.1683168000000002,\n",
       "            1.4055315000000002,\n",
       "            1.580116199,\n",
       "            1.7767686,\n",
       "            1.9659655,\n",
       "            2.137157099,\n",
       "            2.434360099,\n",
       "            2.4969266,\n",
       "            2.5378836000000002,\n",
       "            2.559651599\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"Hes tv\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"Hes tv\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(62, 164, 78, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            0.0,\n",
       "            1.0,\n",
       "            2.0,\n",
       "            3.0,\n",
       "            4.0,\n",
       "            5.0,\n",
       "            6.0,\n",
       "            7.0,\n",
       "            8.0,\n",
       "            9.0,\n",
       "            10.0,\n",
       "            11.0,\n",
       "            12.0,\n",
       "            13.0,\n",
       "            14.0,\n",
       "            15.0,\n",
       "            16.0,\n",
       "            17.0,\n",
       "            18.0,\n",
       "            19.0,\n",
       "            20.0\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    },\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.8762630990000001,\n",
       "            1.0486858000000001,\n",
       "            1.198554799,\n",
       "            1.4055425000000001,\n",
       "            1.6074843,\n",
       "            1.7540329000000001,\n",
       "            1.9502664,\n",
       "            2.120530799,\n",
       "            2.3026288000000004,\n",
       "            2.4838987,\n",
       "            2.589203699,\n",
       "            2.8049155000000003,\n",
       "            2.9320727,\n",
       "            2.9714974,\n",
       "            3.0842569990000004,\n",
       "            3.2111636000000003,\n",
       "            3.3506341,\n",
       "            3.4907365990000003,\n",
       "            3.5961006,\n",
       "            3.7930689990000004,\n",
       "            3.9248878990000002,\n",
       "            3.9427361000000003,\n",
       "            4.0593007000000005,\n",
       "            4.2319334,\n",
       "            4.429452099000001,\n",
       "            4.5600225000000005,\n",
       "            4.725327500000001,\n",
       "            4.8614445,\n",
       "            5.028804599,\n",
       "            5.057801099000001,\n",
       "            5.1871974000000005,\n",
       "            5.316583799,\n",
       "            5.4919947,\n",
       "            5.6551524,\n",
       "            5.7748869,\n",
       "            5.939776800000001,\n",
       "            6.0916978,\n",
       "            6.305307,\n",
       "            6.4327899,\n",
       "            6.6218253,\n",
       "            6.754254400000001,\n",
       "            6.9158511,\n",
       "            7.0894127000000005,\n",
       "            7.1071375990000005,\n",
       "            7.256495200000001,\n",
       "            7.379185400000001,\n",
       "            7.4931412,\n",
       "            7.610903400000001,\n",
       "            7.804367899000001,\n",
       "            7.9097856,\n",
       "            8.0520805,\n",
       "            8.0843684,\n",
       "            8.255606099000001,\n",
       "            8.404055000000001,\n",
       "            8.534606100000001,\n",
       "            8.652867200000001,\n",
       "            8.8525389,\n",
       "            8.9779918,\n",
       "            9.0330385,\n",
       "            9.154501699,\n",
       "            9.294238,\n",
       "            9.452529699000001,\n",
       "            9.564264000000001,\n",
       "            9.6841585,\n",
       "            9.7079369,\n",
       "            9.8561408,\n",
       "            9.9549514,\n",
       "            10.0876713,\n",
       "            10.214286899000001,\n",
       "            10.3141572,\n",
       "            10.436802400000001,\n",
       "            10.581230599000001,\n",
       "            10.750874099,\n",
       "            10.9673554,\n",
       "            11.035861799000001,\n",
       "            11.153172900000001,\n",
       "            11.256066200000001,\n",
       "            11.4354321,\n",
       "            11.554885800000001,\n",
       "            11.760837800000001,\n",
       "            11.9074544,\n",
       "            11.939724100000001,\n",
       "            12.0981977,\n",
       "            12.2370932,\n",
       "            12.359006500000001,\n",
       "            12.470793599,\n",
       "            12.6100659,\n",
       "            12.614076999,\n",
       "            12.733841399000001,\n",
       "            12.893728900000001,\n",
       "            13.0106827,\n",
       "            13.129425000000001,\n",
       "            13.276799,\n",
       "            13.377885500000001,\n",
       "            13.4825286,\n",
       "            13.485190600000001,\n",
       "            13.595366100000001,\n",
       "            13.693931099,\n",
       "            13.811805199,\n",
       "            13.992859200000002,\n",
       "            14.093696900000001,\n",
       "            14.2117286,\n",
       "            14.392397500000001,\n",
       "            14.436712000000002,\n",
       "            14.554985,\n",
       "            14.7084349,\n",
       "            14.868963599,\n",
       "            15.058553700000001,\n",
       "            15.254578500000001,\n",
       "            15.272606799,\n",
       "            15.470820900000001,\n",
       "            15.6235628,\n",
       "            15.7617188,\n",
       "            15.8960138,\n",
       "            16.019628700000002,\n",
       "            16.1899158,\n",
       "            16.2949391,\n",
       "            16.2975983,\n",
       "            16.475478499,\n",
       "            16.6154526,\n",
       "            16.7727015,\n",
       "            16.929238599,\n",
       "            17.0545878,\n",
       "            17.1789908,\n",
       "            17.298726299000002,\n",
       "            17.330182699,\n",
       "            17.481676,\n",
       "            17.6211515,\n",
       "            17.7643612,\n",
       "            17.9288725,\n",
       "            18.0347847,\n",
       "            18.153686,\n",
       "            18.345438700000003,\n",
       "            18.4789888,\n",
       "            18.510538200000003,\n",
       "            18.6573628,\n",
       "            18.822969500000003,\n",
       "            18.977780299000003,\n",
       "            19.1493842,\n",
       "            19.255051,\n",
       "            19.4098201,\n",
       "            19.531427199,\n",
       "            19.577500499000003,\n",
       "            19.7120649,\n",
       "            19.826514499,\n",
       "            19.9572505,\n",
       "            20.057918100000002,\n",
       "            20.191079399,\n",
       "            20.3242845,\n",
       "            20.4443559,\n",
       "            20.6102884,\n",
       "            20.613573999,\n",
       "            20.7131846,\n",
       "            20.8543834,\n",
       "            21.008808999000003,\n",
       "            21.2353747,\n",
       "            21.338163799,\n",
       "            21.437728,\n",
       "            21.5413093,\n",
       "            21.603071099,\n",
       "            21.7401076,\n",
       "            21.937923299,\n",
       "            22.053801799000002,\n",
       "            22.1756645,\n",
       "            22.275311699000003,\n",
       "            22.378481500000003,\n",
       "            22.480401299,\n",
       "            22.5810371,\n",
       "            22.5835721,\n",
       "            22.701059200000003,\n",
       "            22.863661800000003,\n",
       "            22.962971699,\n",
       "            23.0656633,\n",
       "            23.182425799,\n",
       "            23.379449100000002,\n",
       "            23.565456400000002,\n",
       "            23.589639899,\n",
       "            23.719011799,\n",
       "            23.8405302,\n",
       "            23.963405100000003,\n",
       "            24.099289300000002,\n",
       "            24.200761,\n",
       "            24.388312300000003,\n",
       "            24.5367651,\n",
       "            24.674922900000002,\n",
       "            24.745222300000002,\n",
       "            24.9344566,\n",
       "            25.034576099000002,\n",
       "            25.1377513,\n",
       "            25.2876085,\n",
       "            25.471190499000002,\n",
       "            25.626517200000002,\n",
       "            25.795855500000002,\n",
       "            25.814067,\n",
       "            25.915367800000002,\n",
       "            26.065248500000003,\n",
       "            26.279377200000003,\n",
       "            26.3962274,\n",
       "            26.5304046,\n",
       "            26.6959309,\n",
       "            26.8378544,\n",
       "            26.9760533,\n",
       "            26.996555800000003,\n",
       "            27.108435799000002,\n",
       "            27.247860899000003,\n",
       "            27.3870554,\n",
       "            27.5193762,\n",
       "            27.640779299000002,\n",
       "            27.792832099,\n",
       "            27.917137299,\n",
       "            27.9420463,\n",
       "            28.1419587,\n",
       "            28.260902799,\n",
       "            28.3788112,\n",
       "            28.492030300000003,\n",
       "            28.617063,\n",
       "            28.718584099,\n",
       "            28.8421325,\n",
       "            28.980437100000003,\n",
       "            29.0163271,\n",
       "            29.144952999,\n",
       "            29.267283600000003,\n",
       "            29.369866000000002,\n",
       "            29.5468797,\n",
       "            29.6499625,\n",
       "            29.7523687,\n",
       "            29.9039444,\n",
       "            29.925316199,\n",
       "            30.110689200000003,\n",
       "            30.267326,\n",
       "            30.434168699,\n",
       "            30.569648,\n",
       "            30.696987399,\n",
       "            30.8558932,\n",
       "            31.009389399000003,\n",
       "            31.134481299,\n",
       "            31.188471899000003,\n",
       "            31.3425797,\n",
       "            31.4772734,\n",
       "            31.6249143,\n",
       "            31.7254994,\n",
       "            31.826300699,\n",
       "            31.9845705,\n",
       "            32.0852755,\n",
       "            32.1131268,\n",
       "            32.2546004,\n",
       "            32.375701500000005,\n",
       "            32.475638299,\n",
       "            32.6022491,\n",
       "            32.7283665,\n",
       "            32.864000999000005,\n",
       "            33.008385600000004,\n",
       "            33.1872866,\n",
       "            33.203317199000004,\n",
       "            33.340807799000004,\n",
       "            33.4416802,\n",
       "            33.571251700000005,\n",
       "            33.672282499000005,\n",
       "            33.771924699,\n",
       "            33.9209472,\n",
       "            34.026757299,\n",
       "            34.0296678,\n",
       "            34.149349999,\n",
       "            34.248158899,\n",
       "            34.348682399000005,\n",
       "            34.463278399000004,\n",
       "            34.665905599000006,\n",
       "            34.789110499,\n",
       "            34.9457979,\n",
       "            35.1072654,\n",
       "            35.140640000000005,\n",
       "            35.2497983,\n",
       "            35.437699799,\n",
       "            35.580553,\n",
       "            35.725785199,\n",
       "            35.959918900000005,\n",
       "            36.0814557,\n",
       "            36.252656,\n",
       "            36.2826855,\n",
       "            36.4323558,\n",
       "            36.5773643,\n",
       "            36.740892800000005,\n",
       "            36.914163399,\n",
       "            37.069955499,\n",
       "            37.1920469,\n",
       "            37.3377385,\n",
       "            37.502714100000006,\n",
       "            37.5367577,\n",
       "            37.637187899000004,\n",
       "            37.788008299000005,\n",
       "            37.976814100000006,\n",
       "            38.0944591,\n",
       "            38.206459999,\n",
       "            38.3857561,\n",
       "            38.5013062,\n",
       "            38.5599514,\n",
       "            38.714640199,\n",
       "            38.836751500000005,\n",
       "            38.978321400000006,\n",
       "            39.144853299000005,\n",
       "            39.2461502,\n",
       "            39.3492894,\n",
       "            39.450985599,\n",
       "            39.5559012,\n",
       "            39.5782206,\n",
       "            39.678205399,\n",
       "            39.8038838,\n",
       "            39.9064982,\n",
       "            40.0084285,\n",
       "            40.158839900000004,\n",
       "            40.266447400000004,\n",
       "            40.370611600000004,\n",
       "            40.3733451,\n",
       "            40.475327,\n",
       "            40.606900299,\n",
       "            40.818207900000004,\n",
       "            40.9768503,\n",
       "            41.0970486,\n",
       "            41.21528,\n",
       "            41.344913999,\n",
       "            41.526230399,\n",
       "            41.632324699,\n",
       "            41.757385999,\n",
       "            41.8557949,\n",
       "            41.972371800000005,\n",
       "            42.100321,\n",
       "            42.227045199,\n",
       "            42.396405899,\n",
       "            42.517423999,\n",
       "            42.565954100000006,\n",
       "            42.670822499,\n",
       "            42.822599299000004,\n",
       "            42.9530248,\n",
       "            43.093682799,\n",
       "            43.2956556,\n",
       "            43.4592296,\n",
       "            43.5617467,\n",
       "            43.742953899,\n",
       "            43.795401499,\n",
       "            43.936556700000004,\n",
       "            44.0578659,\n",
       "            44.211426100000004,\n",
       "            44.349674500000006,\n",
       "            44.452213500000006,\n",
       "            44.570105500000004,\n",
       "            44.6929243,\n",
       "            44.709913400000005,\n",
       "            44.8507881,\n",
       "            44.9925957,\n",
       "            45.1285886,\n",
       "            45.2844211,\n",
       "            45.45366,\n",
       "            45.610999400000004,\n",
       "            45.8169641,\n",
       "            45.9854563,\n",
       "            46.056301999000006,\n",
       "            46.1749597,\n",
       "            46.381682899000005,\n",
       "            46.5040672,\n",
       "            46.646099699000004,\n",
       "            46.805627900000005,\n",
       "            46.945877,\n",
       "            47.047068699,\n",
       "            47.109970800000006,\n",
       "            47.273971,\n",
       "            47.39641,\n",
       "            47.526514600000006,\n",
       "            47.625299399000006,\n",
       "            47.726553900000006,\n",
       "            47.827934699000004,\n",
       "            47.94847600000001,\n",
       "            48.0550744,\n",
       "            48.058249200000006,\n",
       "            48.157116599000005,\n",
       "            48.357981300000006,\n",
       "            48.513547399000004,\n",
       "            48.653254999000005,\n",
       "            48.78309,\n",
       "            48.8854333,\n",
       "            49.0286495,\n",
       "            49.0316605,\n",
       "            49.128433399,\n",
       "            49.244871399000004,\n",
       "            49.3449704,\n",
       "            49.495848900000006,\n",
       "            49.617505200000004,\n",
       "            49.7182959,\n",
       "            49.820784100000004,\n",
       "            49.926950700000006,\n",
       "            49.9747111,\n",
       "            50.121713,\n",
       "            50.271141300000004,\n",
       "            50.439939399000004,\n",
       "            50.626067600000006,\n",
       "            50.782987499,\n",
       "            50.9644727,\n",
       "            51.082284,\n",
       "            51.0845299,\n",
       "            51.2215471,\n",
       "            51.3356423,\n",
       "            51.4343275,\n",
       "            51.5418414,\n",
       "            51.699710199,\n",
       "            51.837729700000004,\n",
       "            51.939813400000006,\n",
       "            52.0683458,\n",
       "            52.117494499,\n",
       "            52.2897158,\n",
       "            52.426822799,\n",
       "            52.5644222,\n",
       "            52.726962599000004,\n",
       "            52.943947800000004,\n",
       "            53.0984095,\n",
       "            53.2152625,\n",
       "            53.2636514,\n",
       "            53.4140701,\n",
       "            53.530469200000006,\n",
       "            53.658740200000004,\n",
       "            53.813616799,\n",
       "            53.9140522,\n",
       "            54.030796200000005,\n",
       "            54.143422400000006,\n",
       "            54.28597490000001,\n",
       "            54.288557100000006,\n",
       "            54.407219100000006,\n",
       "            54.527783500000005,\n",
       "            54.6653522,\n",
       "            54.79078560000001,\n",
       "            54.942377799000006,\n",
       "            55.048758400000004,\n",
       "            55.152296400000004,\n",
       "            55.154830299000004,\n",
       "            55.255788499000005,\n",
       "            55.375555000000006,\n",
       "            55.5407554,\n",
       "            55.658826000000005,\n",
       "            55.7817385,\n",
       "            55.8844982,\n",
       "            55.9880581,\n",
       "            56.1443097,\n",
       "            56.2490552,\n",
       "            56.394463999,\n",
       "            56.514740299,\n",
       "            56.70048159900001,\n",
       "            56.8488976,\n",
       "            56.9996233,\n",
       "            57.1436895,\n",
       "            57.266783200000006,\n",
       "            57.271756999000004,\n",
       "            57.417186300000004,\n",
       "            57.539357300000006,\n",
       "            57.658060500000005,\n",
       "            57.815261399,\n",
       "            57.9726458,\n",
       "            58.128579199,\n",
       "            58.244838,\n",
       "            58.3836687,\n",
       "            58.4545073,\n",
       "            58.611424899000006,\n",
       "            58.726597500000004,\n",
       "            58.863513099,\n",
       "            58.985052800000005,\n",
       "            59.1320756,\n",
       "            59.2473381,\n",
       "            59.4309705,\n",
       "            59.4606384,\n",
       "            59.5947638,\n",
       "            59.710581100000006,\n",
       "            59.8127403,\n",
       "            59.9370398,\n",
       "            60.0394969,\n",
       "            60.1410131,\n",
       "            60.24152050000001,\n",
       "            60.424257100000005,\n",
       "            60.439157800000004,\n",
       "            60.619068000000006,\n",
       "            60.79908270000001,\n",
       "            60.932639599000005,\n",
       "            61.053765299000005,\n",
       "            61.2264313,\n",
       "            61.3513413,\n",
       "            61.5464087,\n",
       "            61.561027399000004,\n",
       "            61.702958399,\n",
       "            61.816301799,\n",
       "            61.970145300000006,\n",
       "            62.110882899,\n",
       "            62.224248499000005,\n",
       "            62.3828776,\n",
       "            62.511225100000004,\n",
       "            62.616609099,\n",
       "            62.701220500000005,\n",
       "            62.8416435,\n",
       "            63.037250900000004,\n",
       "            63.164780400000005,\n",
       "            63.281649599000005,\n",
       "            63.400617699,\n",
       "            63.55545389900001,\n",
       "            63.6782952,\n",
       "            63.74183089900001,\n",
       "            63.873128099000006,\n",
       "            64.0204621,\n",
       "            64.20040130000001,\n",
       "            64.33640479900001,\n",
       "            64.4683129,\n",
       "            64.6178531,\n",
       "            64.8303186,\n",
       "            64.9711158,\n",
       "            64.97362929900001,\n",
       "            65.1354688,\n",
       "            65.24864039900001,\n",
       "            65.383938099,\n",
       "            65.5335022,\n",
       "            65.7201563,\n",
       "            65.918757399,\n",
       "            66.1228178,\n",
       "            66.249435999,\n",
       "            66.405831199,\n",
       "            66.57299729900001,\n",
       "            66.6745393,\n",
       "            66.819403799,\n",
       "            66.9223699,\n",
       "            67.04304450000001,\n",
       "            67.2009848,\n",
       "            67.376760699,\n",
       "            67.397575999,\n",
       "            67.5540613,\n",
       "            67.653668599,\n",
       "            67.7531613,\n",
       "            67.854878,\n",
       "            68.0068612,\n",
       "            68.128979,\n",
       "            68.2431846,\n",
       "            68.2911313,\n",
       "            68.4074324,\n",
       "            68.5545305,\n",
       "            68.65464010000001,\n",
       "            68.7913453,\n",
       "            68.892582,\n",
       "            69.02815410000001,\n",
       "            69.16499300000001,\n",
       "            69.26688440000001,\n",
       "            69.2694352,\n",
       "            69.36885310000001,\n",
       "            69.5495466,\n",
       "            69.6616934,\n",
       "            69.7639439,\n",
       "            69.9053985,\n",
       "            70.05361470000001,\n",
       "            70.2677098,\n",
       "            70.3175801,\n",
       "            70.466268099,\n",
       "            70.6206952,\n",
       "            70.75054970000001,\n",
       "            70.85997199900001,\n",
       "            71.02545140000001,\n",
       "            71.1857906,\n",
       "            71.40823610000001,\n",
       "            71.5912656,\n",
       "            71.62136860000001,\n",
       "            71.72382610000001,\n",
       "            71.83587049900001,\n",
       "            71.938457799,\n",
       "            72.037382099,\n",
       "            72.155878199,\n",
       "            72.261161,\n",
       "            72.3643576,\n",
       "            72.3672909,\n",
       "            72.4682184,\n",
       "            72.567692799,\n",
       "            72.669709,\n",
       "            72.8051128,\n",
       "            72.90335110000001,\n",
       "            73.044337,\n",
       "            73.1493756,\n",
       "            73.318201,\n",
       "            73.35915870000001,\n",
       "            73.46000360000001,\n",
       "            73.558442799,\n",
       "            73.69868619900001,\n",
       "            73.820330599,\n",
       "            73.9555375,\n",
       "            74.09374000000001,\n",
       "            74.230623099,\n",
       "            74.2703607,\n",
       "            74.4015018,\n",
       "            74.5001963,\n",
       "            74.64895909900001,\n",
       "            74.752080499,\n",
       "            74.89417319900001,\n",
       "            74.9927727,\n",
       "            75.1167944,\n",
       "            75.220640699,\n",
       "            75.223292799,\n",
       "            75.40719560000001,\n",
       "            75.5198654,\n",
       "            75.6270564,\n",
       "            75.7909736,\n",
       "            75.985805299,\n",
       "            76.1305918,\n",
       "            76.3369277,\n",
       "            76.3773541,\n",
       "            76.54678990000001,\n",
       "            76.7161123,\n",
       "            76.8845407,\n",
       "            77.1381762,\n",
       "            77.261719,\n",
       "            77.43194960000001,\n",
       "            77.5692379,\n",
       "            77.6715188,\n",
       "            77.6740898,\n",
       "            77.7730083,\n",
       "            77.89229920000001,\n",
       "            77.9933618,\n",
       "            78.15038119900001,\n",
       "            78.31347120000001,\n",
       "            78.4697245,\n",
       "            78.6144472,\n",
       "            78.6663218,\n",
       "            78.7967715,\n",
       "            78.91025880000001,\n",
       "            79.1427117,\n",
       "            79.277887699,\n",
       "            79.3901943,\n",
       "            79.5260444,\n",
       "            79.664208599,\n",
       "            79.81207640000001,\n",
       "            79.8157367,\n",
       "            79.9147355,\n",
       "            80.0534142,\n",
       "            80.16924180000001,\n",
       "            80.30394270000001,\n",
       "            80.4488395,\n",
       "            80.55837449900001,\n",
       "            80.7418703,\n",
       "            80.7750944,\n",
       "            80.89469309900001,\n",
       "            80.996731099,\n",
       "            81.190382799,\n",
       "            81.3992149,\n",
       "            81.5578126,\n",
       "            81.737806,\n",
       "            81.8557244,\n",
       "            82.00589430000001,\n",
       "            82.0283187,\n",
       "            82.19674570000001,\n",
       "            82.3081308,\n",
       "            82.43020809900001,\n",
       "            82.55090940000001,\n",
       "            82.6723405,\n",
       "            82.8184049,\n",
       "            82.9604894,\n",
       "            82.9629781,\n",
       "            83.0608916,\n",
       "            83.19657020000001,\n",
       "            83.3323936,\n",
       "            83.43185720000001,\n",
       "            83.545423799,\n",
       "            83.65731539900001,\n",
       "            83.775333,\n",
       "            83.918765499,\n",
       "            83.9815573,\n",
       "            84.127890699,\n",
       "            84.25634480000001,\n",
       "            84.42990249900001,\n",
       "            84.55242050000001,\n",
       "            84.6721334,\n",
       "            84.7758154,\n",
       "            84.9187086,\n",
       "            84.9221174,\n",
       "            85.1075989,\n",
       "            85.20689850000001,\n",
       "            85.307249,\n",
       "            85.426127099,\n",
       "            85.5258294,\n",
       "            85.6926031,\n",
       "            85.91295689900001,\n",
       "            86.139066899,\n",
       "            86.1426163,\n",
       "            86.278217399,\n",
       "            86.4126705,\n",
       "            86.53774580000001,\n",
       "            86.6532387,\n",
       "            86.804618,\n",
       "            86.9251515,\n",
       "            87.0276951,\n",
       "            87.0812873,\n",
       "            87.206230499,\n",
       "            87.31296660000001,\n",
       "            87.4334944,\n",
       "            87.57776940000001,\n",
       "            87.70507400000001,\n",
       "            87.806915,\n",
       "            87.91069540000001,\n",
       "            88.03222690000001,\n",
       "            88.104285699,\n",
       "            88.2566587,\n",
       "            88.378642,\n",
       "            88.4794217,\n",
       "            88.58113789900001,\n",
       "            88.7116154,\n",
       "            88.81205650000001,\n",
       "            88.96010549900001,\n",
       "            88.97843049900001,\n",
       "            89.0923717,\n",
       "            89.206613499,\n",
       "            89.4017678,\n",
       "            89.50540430000001,\n",
       "            89.62523610000001,\n",
       "            89.78142890000001,\n",
       "            89.9552646,\n",
       "            90.11152170000001,\n",
       "            90.114857799,\n",
       "            90.235409199,\n",
       "            90.38011479900001,\n",
       "            90.5140356,\n",
       "            90.6654388,\n",
       "            90.79426620000001,\n",
       "            90.9436264,\n",
       "            91.079196999,\n",
       "            91.14065860000001,\n",
       "            91.2689917,\n",
       "            91.3813123,\n",
       "            91.54052730000001,\n",
       "            91.6580423,\n",
       "            91.7980189,\n",
       "            91.9163436,\n",
       "            92.0250432,\n",
       "            92.1277433,\n",
       "            92.15815710000001,\n",
       "            92.26337229900001,\n",
       "            92.367671199,\n",
       "            92.472464,\n",
       "            92.57658400000001,\n",
       "            92.7368165,\n",
       "            92.8887124,\n",
       "            93.0063786,\n",
       "            93.03119310000001,\n",
       "            93.1538783,\n",
       "            93.296017,\n",
       "            93.4261587,\n",
       "            93.526336799,\n",
       "            93.6571876,\n",
       "            93.7863564,\n",
       "            93.931031,\n",
       "            94.03577049900001,\n",
       "            94.038270099,\n",
       "            94.1784186,\n",
       "            94.28610609900001,\n",
       "            94.40210450000001,\n",
       "            94.58581729900001,\n",
       "            94.77111190000001,\n",
       "            94.8880232,\n",
       "            95.00914300000001,\n",
       "            95.01220299900001,\n",
       "            95.14761010000001,\n",
       "            95.3638579,\n",
       "            95.5163665,\n",
       "            95.72570079900001,\n",
       "            95.8324489,\n",
       "            95.9620237,\n",
       "            96.06491910000001,\n",
       "            96.1690231,\n",
       "            96.17155050000001,\n",
       "            96.32702880000001,\n",
       "            96.5544735,\n",
       "            96.6553617,\n",
       "            96.8046984,\n",
       "            96.9066557,\n",
       "            97.0063214,\n",
       "            97.1089745,\n",
       "            97.11144580000001,\n",
       "            97.21205459900001,\n",
       "            97.331306599,\n",
       "            97.460770999,\n",
       "            97.5763785,\n",
       "            97.67760100000001,\n",
       "            97.8022306,\n",
       "            97.90595180000001,\n",
       "            98.04851299900001,\n",
       "            98.10592030000001,\n",
       "            98.230675899,\n",
       "            98.3408964,\n",
       "            98.4943879,\n",
       "            98.592598299,\n",
       "            98.69692230000001,\n",
       "            98.8167806,\n",
       "            98.98849619900001,\n",
       "            99.03005119900001,\n",
       "            99.21935970000001,\n",
       "            99.34005919900001,\n",
       "            99.4627025,\n",
       "            99.56323250000001,\n",
       "            99.696291899,\n",
       "            99.856624799,\n",
       "            100.0102164,\n",
       "            100.12721470000001,\n",
       "            100.1298392,\n",
       "            100.22985530000001,\n",
       "            100.41425650000001,\n",
       "            100.6033855,\n",
       "            100.8082174,\n",
       "            100.94961660000001,\n",
       "            101.048834099,\n",
       "            101.2198961,\n",
       "            101.2235007,\n",
       "            101.34451130000001,\n",
       "            101.4681736,\n",
       "            101.597803299,\n",
       "            101.69744150000001,\n",
       "            101.7995709,\n",
       "            101.9051446,\n",
       "            102.00825560000001,\n",
       "            102.136412,\n",
       "            102.15386160000001,\n",
       "            102.312584899,\n",
       "            102.4892712,\n",
       "            102.64214580000001,\n",
       "            102.81098119900001,\n",
       "            102.931173199,\n",
       "            103.04666319900001,\n",
       "            103.149179899,\n",
       "            103.15154550000001,\n",
       "            103.274288399,\n",
       "            103.4168946,\n",
       "            103.5325916,\n",
       "            103.71371369900001,\n",
       "            103.815482899,\n",
       "            103.95266570000001,\n",
       "            104.1081209,\n",
       "            104.23583550000001,\n",
       "            104.26184140000001,\n",
       "            104.45330100000001,\n",
       "            104.60396840000001,\n",
       "            104.717575099,\n",
       "            104.91538820000001,\n",
       "            105.0951036,\n",
       "            105.3076439,\n",
       "            105.46894160000001,\n",
       "            105.52494680000001,\n",
       "            105.70275430000001,\n",
       "            105.87369020000001,\n",
       "            105.99524779900001,\n",
       "            106.157139599,\n",
       "            106.304118,\n",
       "            106.44933160000001,\n",
       "            106.59254290000001,\n",
       "            106.76454740000001,\n",
       "            106.7669908,\n",
       "            106.870322899,\n",
       "            107.03564560000001,\n",
       "            107.1717952,\n",
       "            107.27748960000001,\n",
       "            107.381208599,\n",
       "            107.50906799900001,\n",
       "            107.6404784,\n",
       "            107.7010195,\n",
       "            107.80699859900001,\n",
       "            107.92796879900001,\n",
       "            108.0607166,\n",
       "            108.183244399,\n",
       "            108.37857650000001,\n",
       "            108.510558699,\n",
       "            108.64851200000001,\n",
       "            108.7770263,\n",
       "            108.83577220000001,\n",
       "            108.98201820000001,\n",
       "            109.120123899,\n",
       "            109.27961230000001,\n",
       "            109.47314580000001,\n",
       "            109.61442570000001,\n",
       "            109.77785739900001,\n",
       "            109.9151078,\n",
       "            109.9175611,\n",
       "            110.0412211,\n",
       "            110.20201300000001,\n",
       "            110.34034899900001,\n",
       "            110.49549199900001,\n",
       "            110.672542699,\n",
       "            110.8598219,\n",
       "            110.99110850000001,\n",
       "            111.1333984,\n",
       "            111.15187730000001,\n",
       "            111.29687719900001,\n",
       "            111.5317998,\n",
       "            111.6729061,\n",
       "            111.81300870000001,\n",
       "            111.9655453,\n",
       "            112.1097912,\n",
       "            112.230401399,\n",
       "            112.29628859900001,\n",
       "            112.40273250000001,\n",
       "            112.5082251,\n",
       "            112.6416494,\n",
       "            112.761759299,\n",
       "            112.8646264,\n",
       "            113.01206509900001,\n",
       "            113.14327530000001,\n",
       "            113.28914440000001,\n",
       "            113.29200920000001,\n",
       "            113.4249714,\n",
       "            113.54358249900001,\n",
       "            113.6850533,\n",
       "            113.8037764,\n",
       "            113.980180199,\n",
       "            114.1675599,\n",
       "            114.301893,\n",
       "            114.333316299,\n",
       "            114.47017840000001,\n",
       "            114.6139756,\n",
       "            114.73677180000001,\n",
       "            114.90056240000001,\n",
       "            115.09393370000001,\n",
       "            115.208248999,\n",
       "            115.351487699,\n",
       "            115.521176599,\n",
       "            115.556027399,\n",
       "            115.713798799,\n",
       "            115.8150224,\n",
       "            115.94136390000001,\n",
       "            116.04242749900001,\n",
       "            116.162405199,\n",
       "            116.2875322,\n",
       "            116.412614,\n",
       "            116.45074690000001,\n",
       "            116.5770846,\n",
       "            116.7162844,\n",
       "            116.8503,\n",
       "            117.05291930000001,\n",
       "            117.19432610000001,\n",
       "            117.36101279900001,\n",
       "            117.53026720000001,\n",
       "            117.6766484,\n",
       "            117.67981440000001,\n",
       "            117.79624500000001,\n",
       "            117.93106730000001,\n",
       "            118.1077279,\n",
       "            118.30936890000001,\n",
       "            118.4115022,\n",
       "            118.51383510000001,\n",
       "            118.61527729900001,\n",
       "            118.61774019900001,\n",
       "            118.71550880000001,\n",
       "            118.8321518,\n",
       "            118.991676999,\n",
       "            119.12454349900001,\n",
       "            119.263096699,\n",
       "            119.363421099,\n",
       "            119.54803430000001,\n",
       "            119.6968291,\n",
       "            119.6998734,\n",
       "            119.8360983,\n",
       "            120.03361020000001\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"IR\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"IR\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(195, 113, 210, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            0.0,\n",
       "            1.0,\n",
       "            2.0,\n",
       "            3.0,\n",
       "            4.0,\n",
       "            5.0,\n",
       "            6.0,\n",
       "            7.0,\n",
       "            8.0,\n",
       "            9.0,\n",
       "            10.0,\n",
       "            11.0,\n",
       "            12.0,\n",
       "            13.0,\n",
       "            14.0,\n",
       "            15.0,\n",
       "            16.0,\n",
       "            17.0,\n",
       "            18.0,\n",
       "            19.0,\n",
       "            20.0,\n",
       "            21.0,\n",
       "            22.0,\n",
       "            23.0,\n",
       "            24.0,\n",
       "            25.0,\n",
       "            26.0,\n",
       "            27.0,\n",
       "            28.0,\n",
       "            29.0,\n",
       "            30.0,\n",
       "            31.0,\n",
       "            32.0,\n",
       "            33.0,\n",
       "            34.0,\n",
       "            35.0,\n",
       "            36.0,\n",
       "            37.0,\n",
       "            38.0,\n",
       "            39.0,\n",
       "            40.0,\n",
       "            41.0,\n",
       "            42.0,\n",
       "            43.0,\n",
       "            44.0,\n",
       "            45.0,\n",
       "            46.0,\n",
       "            47.0,\n",
       "            48.0,\n",
       "            49.0,\n",
       "            50.0,\n",
       "            51.0,\n",
       "            52.0,\n",
       "            53.0,\n",
       "            54.0,\n",
       "            55.0,\n",
       "            56.0,\n",
       "            57.0,\n",
       "            58.0,\n",
       "            59.0,\n",
       "            60.0,\n",
       "            61.0,\n",
       "            62.0,\n",
       "            63.0,\n",
       "            64.0,\n",
       "            65.0,\n",
       "            66.0,\n",
       "            67.0,\n",
       "            68.0,\n",
       "            69.0,\n",
       "            70.0,\n",
       "            71.0,\n",
       "            72.0,\n",
       "            73.0,\n",
       "            74.0,\n",
       "            75.0,\n",
       "            76.0,\n",
       "            77.0,\n",
       "            78.0,\n",
       "            79.0,\n",
       "            80.0,\n",
       "            81.0,\n",
       "            82.0,\n",
       "            83.0,\n",
       "            84.0,\n",
       "            85.0,\n",
       "            86.0,\n",
       "            87.0,\n",
       "            88.0,\n",
       "            89.0,\n",
       "            90.0,\n",
       "            91.0,\n",
       "            92.0,\n",
       "            93.0,\n",
       "            94.0,\n",
       "            95.0,\n",
       "            96.0,\n",
       "            97.0,\n",
       "            98.0,\n",
       "            99.0,\n",
       "            100.0,\n",
       "            101.0,\n",
       "            102.0,\n",
       "            103.0,\n",
       "            104.0,\n",
       "            105.0,\n",
       "            106.0,\n",
       "            107.0,\n",
       "            108.0,\n",
       "            109.0,\n",
       "            110.0,\n",
       "            111.0,\n",
       "            112.0,\n",
       "            113.0,\n",
       "            114.0,\n",
       "            115.0,\n",
       "            116.0,\n",
       "            117.0,\n",
       "            118.0,\n",
       "            119.0,\n",
       "            120.0,\n",
       "            121.0,\n",
       "            122.0,\n",
       "            123.0,\n",
       "            124.0,\n",
       "            125.0,\n",
       "            126.0,\n",
       "            127.0,\n",
       "            128.0,\n",
       "            129.0,\n",
       "            130.0,\n",
       "            131.0,\n",
       "            132.0,\n",
       "            133.0,\n",
       "            134.0,\n",
       "            135.0,\n",
       "            136.0,\n",
       "            137.0,\n",
       "            138.0,\n",
       "            139.0,\n",
       "            140.0,\n",
       "            141.0,\n",
       "            142.0,\n",
       "            143.0,\n",
       "            144.0,\n",
       "            145.0,\n",
       "            146.0,\n",
       "            147.0,\n",
       "            148.0,\n",
       "            149.0,\n",
       "            150.0,\n",
       "            151.0,\n",
       "            152.0,\n",
       "            153.0,\n",
       "            154.0,\n",
       "            155.0,\n",
       "            156.0,\n",
       "            157.0,\n",
       "            158.0,\n",
       "            159.0,\n",
       "            160.0,\n",
       "            161.0,\n",
       "            162.0,\n",
       "            163.0,\n",
       "            164.0,\n",
       "            165.0,\n",
       "            166.0,\n",
       "            167.0,\n",
       "            168.0,\n",
       "            169.0,\n",
       "            170.0,\n",
       "            171.0,\n",
       "            172.0,\n",
       "            173.0,\n",
       "            174.0,\n",
       "            175.0,\n",
       "            176.0,\n",
       "            177.0,\n",
       "            178.0,\n",
       "            179.0,\n",
       "            180.0,\n",
       "            181.0,\n",
       "            182.0,\n",
       "            183.0,\n",
       "            184.0,\n",
       "            185.0,\n",
       "            186.0,\n",
       "            187.0,\n",
       "            188.0,\n",
       "            189.0,\n",
       "            190.0,\n",
       "            191.0,\n",
       "            192.0,\n",
       "            193.0,\n",
       "            194.0,\n",
       "            195.0,\n",
       "            196.0,\n",
       "            197.0,\n",
       "            198.0,\n",
       "            199.0,\n",
       "            200.0,\n",
       "            201.0,\n",
       "            202.0,\n",
       "            203.0,\n",
       "            204.0,\n",
       "            205.0,\n",
       "            206.0,\n",
       "            207.0,\n",
       "            208.0,\n",
       "            209.0,\n",
       "            210.0,\n",
       "            211.0,\n",
       "            212.0,\n",
       "            213.0,\n",
       "            214.0,\n",
       "            215.0,\n",
       "            216.0,\n",
       "            217.0,\n",
       "            218.0,\n",
       "            219.0,\n",
       "            220.0,\n",
       "            221.0,\n",
       "            222.0,\n",
       "            223.0,\n",
       "            224.0,\n",
       "            225.0,\n",
       "            226.0,\n",
       "            227.0,\n",
       "            228.0,\n",
       "            229.0,\n",
       "            230.0,\n",
       "            231.0,\n",
       "            232.0,\n",
       "            233.0,\n",
       "            234.0,\n",
       "            235.0,\n",
       "            236.0,\n",
       "            237.0,\n",
       "            238.0,\n",
       "            239.0,\n",
       "            240.0,\n",
       "            241.0,\n",
       "            242.0,\n",
       "            243.0,\n",
       "            244.0,\n",
       "            245.0,\n",
       "            246.0,\n",
       "            247.0,\n",
       "            248.0,\n",
       "            249.0,\n",
       "            250.0,\n",
       "            251.0,\n",
       "            252.0,\n",
       "            253.0,\n",
       "            254.0,\n",
       "            255.0,\n",
       "            256.0,\n",
       "            257.0,\n",
       "            258.0,\n",
       "            259.0,\n",
       "            260.0,\n",
       "            261.0,\n",
       "            262.0,\n",
       "            263.0,\n",
       "            264.0,\n",
       "            265.0,\n",
       "            266.0,\n",
       "            267.0,\n",
       "            268.0,\n",
       "            269.0,\n",
       "            270.0,\n",
       "            271.0,\n",
       "            272.0,\n",
       "            273.0,\n",
       "            274.0,\n",
       "            275.0,\n",
       "            276.0,\n",
       "            277.0,\n",
       "            278.0,\n",
       "            279.0,\n",
       "            280.0,\n",
       "            281.0,\n",
       "            282.0,\n",
       "            283.0,\n",
       "            284.0,\n",
       "            285.0,\n",
       "            286.0,\n",
       "            287.0,\n",
       "            288.0,\n",
       "            289.0,\n",
       "            290.0,\n",
       "            291.0,\n",
       "            292.0,\n",
       "            293.0,\n",
       "            294.0,\n",
       "            295.0,\n",
       "            296.0,\n",
       "            297.0,\n",
       "            298.0,\n",
       "            299.0,\n",
       "            300.0,\n",
       "            301.0,\n",
       "            302.0,\n",
       "            303.0,\n",
       "            304.0,\n",
       "            305.0,\n",
       "            306.0,\n",
       "            307.0,\n",
       "            308.0,\n",
       "            309.0,\n",
       "            310.0,\n",
       "            311.0,\n",
       "            312.0,\n",
       "            313.0,\n",
       "            314.0,\n",
       "            315.0,\n",
       "            316.0,\n",
       "            317.0,\n",
       "            318.0,\n",
       "            319.0,\n",
       "            320.0,\n",
       "            321.0,\n",
       "            322.0,\n",
       "            323.0,\n",
       "            324.0,\n",
       "            325.0,\n",
       "            326.0,\n",
       "            327.0,\n",
       "            328.0,\n",
       "            329.0,\n",
       "            330.0,\n",
       "            331.0,\n",
       "            332.0,\n",
       "            333.0,\n",
       "            334.0,\n",
       "            335.0,\n",
       "            336.0,\n",
       "            337.0,\n",
       "            338.0,\n",
       "            339.0,\n",
       "            340.0,\n",
       "            341.0,\n",
       "            342.0,\n",
       "            343.0,\n",
       "            344.0,\n",
       "            345.0,\n",
       "            346.0,\n",
       "            347.0,\n",
       "            348.0,\n",
       "            349.0,\n",
       "            350.0,\n",
       "            351.0,\n",
       "            352.0,\n",
       "            353.0,\n",
       "            354.0,\n",
       "            355.0,\n",
       "            356.0,\n",
       "            357.0,\n",
       "            358.0,\n",
       "            359.0,\n",
       "            360.0,\n",
       "            361.0,\n",
       "            362.0,\n",
       "            363.0,\n",
       "            364.0,\n",
       "            365.0,\n",
       "            366.0,\n",
       "            367.0,\n",
       "            368.0,\n",
       "            369.0,\n",
       "            370.0,\n",
       "            371.0,\n",
       "            372.0,\n",
       "            373.0,\n",
       "            374.0,\n",
       "            375.0,\n",
       "            376.0,\n",
       "            377.0,\n",
       "            378.0,\n",
       "            379.0,\n",
       "            380.0,\n",
       "            381.0,\n",
       "            382.0,\n",
       "            383.0,\n",
       "            384.0,\n",
       "            385.0,\n",
       "            386.0,\n",
       "            387.0,\n",
       "            388.0,\n",
       "            389.0,\n",
       "            390.0,\n",
       "            391.0,\n",
       "            392.0,\n",
       "            393.0,\n",
       "            394.0,\n",
       "            395.0,\n",
       "            396.0,\n",
       "            397.0,\n",
       "            398.0,\n",
       "            399.0,\n",
       "            400.0,\n",
       "            401.0,\n",
       "            402.0,\n",
       "            403.0,\n",
       "            404.0,\n",
       "            405.0,\n",
       "            406.0,\n",
       "            407.0,\n",
       "            408.0,\n",
       "            409.0,\n",
       "            410.0,\n",
       "            411.0,\n",
       "            412.0,\n",
       "            413.0,\n",
       "            414.0,\n",
       "            415.0,\n",
       "            416.0,\n",
       "            417.0,\n",
       "            418.0,\n",
       "            419.0,\n",
       "            420.0,\n",
       "            421.0,\n",
       "            422.0,\n",
       "            423.0,\n",
       "            424.0,\n",
       "            425.0,\n",
       "            426.0,\n",
       "            427.0,\n",
       "            428.0,\n",
       "            429.0,\n",
       "            430.0,\n",
       "            431.0,\n",
       "            432.0,\n",
       "            433.0,\n",
       "            434.0,\n",
       "            435.0,\n",
       "            436.0,\n",
       "            437.0,\n",
       "            438.0,\n",
       "            439.0,\n",
       "            440.0,\n",
       "            441.0,\n",
       "            442.0,\n",
       "            443.0,\n",
       "            444.0,\n",
       "            445.0,\n",
       "            446.0,\n",
       "            447.0,\n",
       "            448.0,\n",
       "            449.0,\n",
       "            450.0,\n",
       "            451.0,\n",
       "            452.0,\n",
       "            453.0,\n",
       "            454.0,\n",
       "            455.0,\n",
       "            456.0,\n",
       "            457.0,\n",
       "            458.0,\n",
       "            459.0,\n",
       "            460.0,\n",
       "            461.0,\n",
       "            462.0,\n",
       "            463.0,\n",
       "            464.0,\n",
       "            465.0,\n",
       "            466.0,\n",
       "            467.0,\n",
       "            468.0,\n",
       "            469.0,\n",
       "            470.0,\n",
       "            471.0,\n",
       "            472.0,\n",
       "            473.0,\n",
       "            474.0,\n",
       "            475.0,\n",
       "            476.0,\n",
       "            477.0,\n",
       "            478.0,\n",
       "            479.0,\n",
       "            480.0,\n",
       "            481.0,\n",
       "            482.0,\n",
       "            483.0,\n",
       "            484.0,\n",
       "            485.0,\n",
       "            486.0,\n",
       "            487.0,\n",
       "            488.0,\n",
       "            489.0,\n",
       "            490.0,\n",
       "            491.0,\n",
       "            492.0,\n",
       "            493.0,\n",
       "            494.0,\n",
       "            495.0,\n",
       "            496.0,\n",
       "            497.0,\n",
       "            498.0,\n",
       "            499.0,\n",
       "            500.0,\n",
       "            501.0,\n",
       "            502.0,\n",
       "            503.0,\n",
       "            504.0,\n",
       "            505.0,\n",
       "            506.0,\n",
       "            507.0,\n",
       "            508.0,\n",
       "            509.0,\n",
       "            510.0,\n",
       "            511.0,\n",
       "            512.0,\n",
       "            513.0,\n",
       "            514.0,\n",
       "            515.0,\n",
       "            516.0,\n",
       "            517.0,\n",
       "            518.0,\n",
       "            519.0,\n",
       "            520.0,\n",
       "            521.0,\n",
       "            522.0,\n",
       "            523.0,\n",
       "            524.0,\n",
       "            525.0,\n",
       "            526.0,\n",
       "            527.0,\n",
       "            528.0,\n",
       "            529.0,\n",
       "            530.0,\n",
       "            531.0,\n",
       "            532.0,\n",
       "            533.0,\n",
       "            534.0,\n",
       "            535.0,\n",
       "            536.0,\n",
       "            537.0,\n",
       "            538.0,\n",
       "            539.0,\n",
       "            540.0,\n",
       "            541.0,\n",
       "            542.0,\n",
       "            543.0,\n",
       "            544.0,\n",
       "            545.0,\n",
       "            546.0,\n",
       "            547.0,\n",
       "            548.0,\n",
       "            549.0,\n",
       "            550.0,\n",
       "            551.0,\n",
       "            552.0,\n",
       "            553.0,\n",
       "            554.0,\n",
       "            555.0,\n",
       "            556.0,\n",
       "            557.0,\n",
       "            558.0,\n",
       "            559.0,\n",
       "            560.0,\n",
       "            561.0,\n",
       "            562.0,\n",
       "            563.0,\n",
       "            564.0,\n",
       "            565.0,\n",
       "            566.0,\n",
       "            567.0,\n",
       "            568.0,\n",
       "            569.0,\n",
       "            570.0,\n",
       "            571.0,\n",
       "            572.0,\n",
       "            573.0,\n",
       "            574.0,\n",
       "            575.0,\n",
       "            576.0,\n",
       "            577.0,\n",
       "            578.0,\n",
       "            579.0,\n",
       "            580.0,\n",
       "            581.0,\n",
       "            582.0,\n",
       "            583.0,\n",
       "            584.0,\n",
       "            585.0,\n",
       "            586.0,\n",
       "            587.0,\n",
       "            588.0,\n",
       "            589.0,\n",
       "            590.0,\n",
       "            591.0,\n",
       "            592.0,\n",
       "            593.0,\n",
       "            594.0,\n",
       "            595.0,\n",
       "            596.0,\n",
       "            597.0,\n",
       "            598.0,\n",
       "            599.0,\n",
       "            600.0,\n",
       "            601.0,\n",
       "            602.0,\n",
       "            603.0,\n",
       "            604.0,\n",
       "            605.0,\n",
       "            606.0,\n",
       "            607.0,\n",
       "            608.0,\n",
       "            609.0,\n",
       "            610.0,\n",
       "            611.0,\n",
       "            612.0,\n",
       "            613.0,\n",
       "            614.0,\n",
       "            615.0,\n",
       "            616.0,\n",
       "            617.0,\n",
       "            618.0,\n",
       "            619.0,\n",
       "            620.0,\n",
       "            621.0,\n",
       "            622.0,\n",
       "            623.0,\n",
       "            624.0,\n",
       "            625.0,\n",
       "            626.0,\n",
       "            627.0,\n",
       "            628.0,\n",
       "            629.0,\n",
       "            630.0,\n",
       "            631.0,\n",
       "            632.0,\n",
       "            633.0,\n",
       "            634.0,\n",
       "            635.0,\n",
       "            636.0,\n",
       "            637.0,\n",
       "            638.0,\n",
       "            639.0,\n",
       "            640.0,\n",
       "            641.0,\n",
       "            642.0,\n",
       "            643.0,\n",
       "            644.0,\n",
       "            645.0,\n",
       "            646.0,\n",
       "            647.0,\n",
       "            648.0,\n",
       "            649.0,\n",
       "            650.0,\n",
       "            651.0,\n",
       "            652.0,\n",
       "            653.0,\n",
       "            654.0,\n",
       "            655.0,\n",
       "            656.0,\n",
       "            657.0,\n",
       "            658.0,\n",
       "            659.0,\n",
       "            660.0,\n",
       "            661.0,\n",
       "            662.0,\n",
       "            663.0,\n",
       "            664.0,\n",
       "            665.0,\n",
       "            666.0,\n",
       "            667.0,\n",
       "            668.0,\n",
       "            669.0,\n",
       "            670.0,\n",
       "            671.0,\n",
       "            672.0,\n",
       "            673.0,\n",
       "            674.0,\n",
       "            675.0,\n",
       "            676.0,\n",
       "            677.0,\n",
       "            678.0,\n",
       "            679.0,\n",
       "            680.0,\n",
       "            681.0,\n",
       "            682.0,\n",
       "            683.0,\n",
       "            684.0,\n",
       "            685.0,\n",
       "            686.0,\n",
       "            687.0,\n",
       "            688.0,\n",
       "            689.0,\n",
       "            690.0,\n",
       "            691.0,\n",
       "            692.0,\n",
       "            693.0,\n",
       "            694.0,\n",
       "            695.0,\n",
       "            696.0,\n",
       "            697.0,\n",
       "            698.0,\n",
       "            699.0,\n",
       "            700.0,\n",
       "            701.0,\n",
       "            702.0,\n",
       "            703.0,\n",
       "            704.0,\n",
       "            705.0,\n",
       "            706.0,\n",
       "            707.0,\n",
       "            708.0,\n",
       "            709.0,\n",
       "            710.0,\n",
       "            711.0,\n",
       "            712.0,\n",
       "            713.0,\n",
       "            714.0,\n",
       "            715.0,\n",
       "            716.0,\n",
       "            717.0,\n",
       "            718.0,\n",
       "            719.0,\n",
       "            720.0,\n",
       "            721.0,\n",
       "            722.0,\n",
       "            723.0,\n",
       "            724.0,\n",
       "            725.0,\n",
       "            726.0,\n",
       "            727.0,\n",
       "            728.0,\n",
       "            729.0,\n",
       "            730.0,\n",
       "            731.0,\n",
       "            732.0,\n",
       "            733.0,\n",
       "            734.0,\n",
       "            735.0,\n",
       "            736.0,\n",
       "            737.0,\n",
       "            738.0,\n",
       "            739.0,\n",
       "            740.0,\n",
       "            741.0,\n",
       "            742.0,\n",
       "            743.0,\n",
       "            744.0,\n",
       "            745.0,\n",
       "            746.0,\n",
       "            747.0,\n",
       "            748.0,\n",
       "            749.0,\n",
       "            750.0,\n",
       "            751.0,\n",
       "            752.0,\n",
       "            753.0,\n",
       "            754.0,\n",
       "            755.0,\n",
       "            756.0,\n",
       "            757.0,\n",
       "            758.0,\n",
       "            759.0,\n",
       "            760.0,\n",
       "            761.0,\n",
       "            762.0,\n",
       "            763.0,\n",
       "            764.0,\n",
       "            765.0,\n",
       "            766.0,\n",
       "            767.0,\n",
       "            768.0,\n",
       "            769.0,\n",
       "            770.0,\n",
       "            771.0,\n",
       "            772.0,\n",
       "            773.0,\n",
       "            774.0,\n",
       "            775.0,\n",
       "            776.0,\n",
       "            777.0,\n",
       "            778.0,\n",
       "            779.0,\n",
       "            780.0,\n",
       "            781.0,\n",
       "            782.0,\n",
       "            783.0,\n",
       "            784.0,\n",
       "            785.0,\n",
       "            786.0,\n",
       "            787.0,\n",
       "            788.0,\n",
       "            789.0,\n",
       "            790.0,\n",
       "            791.0,\n",
       "            792.0,\n",
       "            793.0,\n",
       "            794.0,\n",
       "            795.0,\n",
       "            796.0,\n",
       "            797.0,\n",
       "            798.0,\n",
       "            799.0,\n",
       "            800.0,\n",
       "            801.0,\n",
       "            802.0,\n",
       "            803.0,\n",
       "            804.0,\n",
       "            805.0,\n",
       "            806.0,\n",
       "            807.0,\n",
       "            808.0,\n",
       "            809.0,\n",
       "            810.0,\n",
       "            811.0,\n",
       "            812.0,\n",
       "            813.0,\n",
       "            814.0,\n",
       "            815.0,\n",
       "            816.0,\n",
       "            817.0,\n",
       "            818.0,\n",
       "            819.0,\n",
       "            820.0,\n",
       "            821.0,\n",
       "            822.0,\n",
       "            823.0,\n",
       "            824.0,\n",
       "            825.0,\n",
       "            826.0,\n",
       "            827.0,\n",
       "            828.0,\n",
       "            829.0,\n",
       "            830.0,\n",
       "            831.0,\n",
       "            832.0,\n",
       "            833.0,\n",
       "            834.0,\n",
       "            835.0,\n",
       "            836.0,\n",
       "            837.0,\n",
       "            838.0,\n",
       "            839.0,\n",
       "            840.0,\n",
       "            841.0,\n",
       "            842.0,\n",
       "            843.0,\n",
       "            844.0,\n",
       "            845.0,\n",
       "            846.0,\n",
       "            847.0,\n",
       "            848.0,\n",
       "            849.0,\n",
       "            850.0,\n",
       "            851.0,\n",
       "            852.0,\n",
       "            853.0,\n",
       "            854.0,\n",
       "            855.0,\n",
       "            856.0,\n",
       "            857.0,\n",
       "            858.0,\n",
       "            859.0,\n",
       "            860.0,\n",
       "            861.0,\n",
       "            862.0,\n",
       "            863.0,\n",
       "            864.0,\n",
       "            865.0,\n",
       "            866.0,\n",
       "            867.0,\n",
       "            868.0,\n",
       "            869.0,\n",
       "            870.0,\n",
       "            871.0,\n",
       "            872.0,\n",
       "            873.0,\n",
       "            874.0,\n",
       "            875.0,\n",
       "            876.0,\n",
       "            877.0,\n",
       "            878.0,\n",
       "            879.0,\n",
       "            880.0,\n",
       "            881.0,\n",
       "            882.0,\n",
       "            883.0,\n",
       "            884.0,\n",
       "            885.0,\n",
       "            886.0,\n",
       "            887.0,\n",
       "            888.0,\n",
       "            889.0,\n",
       "            890.0,\n",
       "            891.0,\n",
       "            892.0,\n",
       "            893.0,\n",
       "            894.0,\n",
       "            895.0,\n",
       "            896.0,\n",
       "            897.0,\n",
       "            898.0,\n",
       "            899.0,\n",
       "            900.0,\n",
       "            901.0,\n",
       "            902.0,\n",
       "            903.0,\n",
       "            904.0,\n",
       "            905.0,\n",
       "            906.0,\n",
       "            907.0,\n",
       "            908.0,\n",
       "            909.0,\n",
       "            910.0,\n",
       "            911.0,\n",
       "            912.0,\n",
       "            913.0,\n",
       "            914.0,\n",
       "            915.0,\n",
       "            916.0,\n",
       "            917.0,\n",
       "            918.0,\n",
       "            919.0,\n",
       "            920.0,\n",
       "            921.0,\n",
       "            922.0,\n",
       "            923.0,\n",
       "            924.0,\n",
       "            925.0,\n",
       "            926.0,\n",
       "            927.0,\n",
       "            928.0,\n",
       "            929.0,\n",
       "            930.0,\n",
       "            931.0,\n",
       "            932.0,\n",
       "            933.0,\n",
       "            934.0,\n",
       "            935.0,\n",
       "            936.0,\n",
       "            937.0,\n",
       "            938.0,\n",
       "            939.0,\n",
       "            940.0,\n",
       "            941.0,\n",
       "            942.0,\n",
       "            943.0,\n",
       "            944.0,\n",
       "            945.0,\n",
       "            946.0,\n",
       "            947.0,\n",
       "            948.0,\n",
       "            949.0,\n",
       "            950.0,\n",
       "            951.0,\n",
       "            952.0,\n",
       "            953.0\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    },\n",
       "    {\n",
       "        \"xaxis\": \"x1\",\n",
       "        \"colorbar\": {\n",
       "            \"title\": \"\"\n",
       "        },\n",
       "        \"yaxis\": \"y1\",\n",
       "        \"x\": [\n",
       "            0.0,\n",
       "            0.2729649,\n",
       "            0.304959099,\n",
       "            0.3194018,\n",
       "            0.33427850000000003,\n",
       "            0.34627470000000005,\n",
       "            0.359363099,\n",
       "            0.3767783,\n",
       "            0.4091014,\n",
       "            0.42943149900000005,\n",
       "            0.4427265,\n",
       "            0.46602730000000003,\n",
       "            0.48831509900000003,\n",
       "            0.5331612,\n",
       "            0.5529344,\n",
       "            0.5738894,\n",
       "            0.5965994,\n",
       "            0.6551052,\n",
       "            0.6777986,\n",
       "            0.7039433,\n",
       "            0.7429425000000001,\n",
       "            0.7565889,\n",
       "            0.7857541,\n",
       "            0.8111665990000001,\n",
       "            0.8256203990000001,\n",
       "            0.8753309,\n",
       "            0.902424399,\n",
       "            0.9221822000000001,\n",
       "            0.9589931,\n",
       "            0.973958399,\n",
       "            0.9933919990000001,\n",
       "            1.019137199,\n",
       "            1.043984,\n",
       "            1.0658192,\n",
       "            1.0933928000000002,\n",
       "            1.133321099,\n",
       "            1.1752859,\n",
       "            1.2013022990000002,\n",
       "            1.221937,\n",
       "            1.2444263,\n",
       "            1.2641703,\n",
       "            1.3202577,\n",
       "            1.361808399,\n",
       "            1.4263162,\n",
       "            1.4574507,\n",
       "            1.5140142,\n",
       "            1.567762499,\n",
       "            1.5850348,\n",
       "            1.6212102000000002,\n",
       "            1.6385900000000002,\n",
       "            1.6558362000000002,\n",
       "            1.6697205000000002,\n",
       "            1.6836781,\n",
       "            1.6999981000000002,\n",
       "            1.7195202,\n",
       "            1.7418885000000002,\n",
       "            1.7781621,\n",
       "            1.8225065,\n",
       "            1.8516314,\n",
       "            1.8890759990000001,\n",
       "            1.9147174,\n",
       "            1.948242999,\n",
       "            1.980441799,\n",
       "            2.0669386000000003,\n",
       "            2.0876887,\n",
       "            2.136725,\n",
       "            2.1610529,\n",
       "            2.2007700000000003,\n",
       "            2.2258724,\n",
       "            2.2412832000000003,\n",
       "            2.2610628,\n",
       "            2.277262899,\n",
       "            2.2920368,\n",
       "            2.3096402,\n",
       "            2.344273699,\n",
       "            2.3579934000000002,\n",
       "            2.3702986000000004,\n",
       "            2.384085499,\n",
       "            2.4079559,\n",
       "            2.4235719000000002,\n",
       "            2.463089799,\n",
       "            2.4795181,\n",
       "            2.5005876000000002,\n",
       "            2.5136324990000003,\n",
       "            2.531735899,\n",
       "            2.5480759,\n",
       "            2.563667,\n",
       "            2.5766337000000004,\n",
       "            2.5910982000000002,\n",
       "            2.630361599,\n",
       "            2.6681973,\n",
       "            2.6836828,\n",
       "            2.7004571000000004,\n",
       "            2.7147569000000003,\n",
       "            2.7319832,\n",
       "            2.7475564990000003,\n",
       "            2.762578999,\n",
       "            2.779281799,\n",
       "            2.794761899,\n",
       "            2.8088156,\n",
       "            2.8229179\n",
       "        ],\n",
       "        \"showlegend\": true,\n",
       "        \"mode\": \"lines\",\n",
       "        \"name\": \"Adam\",\n",
       "        \"zmin\": null,\n",
       "        \"legendgroup\": \"Adam\",\n",
       "        \"zmax\": null,\n",
       "        \"line\": {\n",
       "            \"color\": \"rgba(172, 142, 24, 1.000)\",\n",
       "            \"shape\": \"linear\",\n",
       "            \"dash\": \"solid\",\n",
       "            \"width\": 1\n",
       "        },\n",
       "        \"y\": [\n",
       "            0.0,\n",
       "            1.0,\n",
       "            2.0,\n",
       "            3.0,\n",
       "            4.0,\n",
       "            5.0,\n",
       "            6.0,\n",
       "            7.0,\n",
       "            8.0,\n",
       "            9.0,\n",
       "            10.0,\n",
       "            11.0,\n",
       "            12.0,\n",
       "            13.0,\n",
       "            14.0,\n",
       "            15.0,\n",
       "            16.0,\n",
       "            17.0,\n",
       "            18.0,\n",
       "            19.0,\n",
       "            20.0,\n",
       "            21.0,\n",
       "            22.0,\n",
       "            23.0,\n",
       "            24.0,\n",
       "            25.0,\n",
       "            26.0,\n",
       "            27.0,\n",
       "            28.0,\n",
       "            29.0,\n",
       "            30.0,\n",
       "            31.0,\n",
       "            32.0,\n",
       "            33.0,\n",
       "            34.0,\n",
       "            35.0,\n",
       "            36.0,\n",
       "            37.0,\n",
       "            38.0,\n",
       "            39.0,\n",
       "            40.0,\n",
       "            41.0,\n",
       "            42.0,\n",
       "            43.0,\n",
       "            44.0,\n",
       "            45.0,\n",
       "            46.0,\n",
       "            47.0,\n",
       "            48.0,\n",
       "            49.0,\n",
       "            50.0,\n",
       "            51.0,\n",
       "            52.0,\n",
       "            53.0,\n",
       "            54.0,\n",
       "            55.0,\n",
       "            56.0,\n",
       "            57.0,\n",
       "            58.0,\n",
       "            59.0,\n",
       "            60.0,\n",
       "            61.0,\n",
       "            62.0,\n",
       "            63.0,\n",
       "            64.0,\n",
       "            65.0,\n",
       "            66.0,\n",
       "            67.0,\n",
       "            68.0,\n",
       "            69.0,\n",
       "            70.0,\n",
       "            71.0,\n",
       "            72.0,\n",
       "            73.0,\n",
       "            74.0,\n",
       "            75.0,\n",
       "            76.0,\n",
       "            77.0,\n",
       "            78.0,\n",
       "            79.0,\n",
       "            80.0,\n",
       "            81.0,\n",
       "            82.0,\n",
       "            83.0,\n",
       "            84.0,\n",
       "            85.0,\n",
       "            86.0,\n",
       "            87.0,\n",
       "            88.0,\n",
       "            89.0,\n",
       "            90.0,\n",
       "            91.0,\n",
       "            92.0,\n",
       "            93.0,\n",
       "            94.0,\n",
       "            95.0,\n",
       "            96.0,\n",
       "            97.0,\n",
       "            98.0,\n",
       "            99.0,\n",
       "            100.0\n",
       "        ],\n",
       "        \"type\": \"scatter\"\n",
       "    }\n",
       "]\n",
       ", {\n",
       "    \"showlegend\": true,\n",
       "    \"xaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            0.0,\n",
       "            25.0,\n",
       "            50.0,\n",
       "            75.0,\n",
       "            100.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            -3.61237789197,\n",
       "            124.02497429097001\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.07646908719743364,\n",
       "            0.9934383202099737\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"time\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"0\",\n",
       "            \"25\",\n",
       "            \"50\",\n",
       "            \"75\",\n",
       "            \"100\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"y1\"\n",
       "    },\n",
       "    \"paper_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"annotations\": [],\n",
       "    \"height\": 400,\n",
       "    \"margin\": {\n",
       "        \"l\": 0,\n",
       "        \"b\": 20,\n",
       "        \"r\": 0,\n",
       "        \"t\": 20\n",
       "    },\n",
       "    \"plot_bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "    \"yaxis\": {\n",
       "        \"showticklabels\": true,\n",
       "        \"gridwidth\": 0.5,\n",
       "        \"tickvals\": [\n",
       "            0.0,\n",
       "            200.0,\n",
       "            400.0,\n",
       "            600.0,\n",
       "            800.0\n",
       "        ],\n",
       "        \"visible\": true,\n",
       "        \"ticks\": \"inside\",\n",
       "        \"range\": [\n",
       "            -28.59,\n",
       "            981.59\n",
       "        ],\n",
       "        \"domain\": [\n",
       "            0.07581474190726165,\n",
       "            0.9901574803149606\n",
       "        ],\n",
       "        \"tickmode\": \"array\",\n",
       "        \"linecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"showgrid\": true,\n",
       "        \"title\": \"Iter\",\n",
       "        \"mirror\": false,\n",
       "        \"tickangle\": 0,\n",
       "        \"showline\": true,\n",
       "        \"gridcolor\": \"rgba(0, 0, 0, 0.100)\",\n",
       "        \"titlefont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 15\n",
       "        },\n",
       "        \"tickcolor\": \"rgb(0, 0, 0)\",\n",
       "        \"ticktext\": [\n",
       "            \"0\",\n",
       "            \"200\",\n",
       "            \"400\",\n",
       "            \"600\",\n",
       "            \"800\"\n",
       "        ],\n",
       "        \"zeroline\": false,\n",
       "        \"type\": \"-\",\n",
       "        \"tickfont\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"zerolinecolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"anchor\": \"x1\"\n",
       "    },\n",
       "    \"legend\": {\n",
       "        \"tracegroupgap\": 0,\n",
       "        \"bordercolor\": \"rgba(0, 0, 0, 1.000)\",\n",
       "        \"bgcolor\": \"rgba(255, 255, 255, 1.000)\",\n",
       "        \"font\": {\n",
       "            \"color\": \"rgba(0, 0, 0, 1.000)\",\n",
       "            \"family\": \"sans-serif\",\n",
       "            \"size\": 11\n",
       "        },\n",
       "        \"y\": 1.0,\n",
       "        \"x\": 1.0\n",
       "    },\n",
       "    \"width\": 600\n",
       "}\n",
       ");\n",
       "    </script>\n",
       "\n",
       "    </body>\n",
       "</html>\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = plot(resultBHHHshs[:Times], resultBHHHshs[:IterAccumulator], xlabel=\"time\", ylabel = \"Iter\", label=\"BHHH sHs\")\n",
    "plot!(resultBHHHtv[:Times], resultBHHHtv[:IterAccumulator], label=\"BHHH tv\")\n",
    "plot!(resultHEStv[:Times], resultHEStv[:IterAccumulator], label=\"Hes tv\")\n",
    "plot!(resultIR[:Times], resultIR[:IterAccumulator], label=\"IR\")\n",
    "plot!(resultAdam[:Times], resultAdam[:IterAccumulator], label=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "resistant-tongue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9599639845400576"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_α = quantile(Normal(), 0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "infinite-blanket",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mBoundsError: attempt to access 21-element Array{Array{T,1} where T,1} at index [25]\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mBoundsError: attempt to access 21-element Array{Array{T,1} where T,1} at index [25]\u001b[39m",
      "",
      "Stacktrace:",
      " [1] getindex(::Array{Array{T,1} where T,1}, ::Int64) at .\\array.jl:809",
      " [2] top-level scope at In[41]:1",
      " [3] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "all_f = Amlet.Fs(paramHEStv[25], mo, sample=1:Nobs(mo))\n",
    "\n",
    "fH = mean(all_f)\n",
    "sigmaH = std(all_f, mean = fH, corrected = false)\n",
    "\n",
    "lH = fH - z_α*sigmaH/sqrt(Nobs(mo))\n",
    "sH = fH + z_α*sigmaH/sqrt(Nobs(mo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "above-arnold",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mBoundsError: attempt to access 213-element Array{Array{T,1} where T,1} at index [230]\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mBoundsError: attempt to access 213-element Array{Array{T,1} where T,1} at index [230]\u001b[39m",
      "",
      "Stacktrace:",
      " [1] getindex(::Array{Array{T,1} where T,1}, ::Int64) at .\\array.jl:809",
      " [2] top-level scope at In[42]:1",
      " [3] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "Amlet.F(paramBHHHshs[230], mo, sample=1:Nobs(mo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "desirable-secretariat",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mBoundsError: attempt to access 213-element Array{Array{T,1} where T,1} at index [230]\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mBoundsError: attempt to access 213-element Array{Array{T,1} where T,1} at index [230]\u001b[39m",
      "",
      "Stacktrace:",
      " [1] getindex(::Array{Array{T,1} where T,1}, ::Int64) at .\\array.jl:809",
      " [2] top-level scope at In[43]:1",
      " [3] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "all_f = Amlet.Fs(paramBHHHshs[230], mo, sample=1:Nobs(mo))\n",
    "\n",
    "fH = mean(all_f)\n",
    "sigmaH = std(all_f, mean = fH, corrected = false)\n",
    "\n",
    "lH = fH - z_α*sigmaH/sqrt(Nobs(mo))\n",
    "# sH = fH + z_α*sigmaH/sqrt(Nobs(mo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
